{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpeta=\"data/salida_prueba/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main index</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hipotesis</th>\n",
       "      <th>R_Text</th>\n",
       "      <th>R_Hip</th>\n",
       "      <th>M_Align</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold_label</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Idx</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[NULL{null,PROPN}, the{the,DET}, firemen{firem...</td>\n",
       "      <td>[NULL{null,PROPN}, the{the,DET}, firefighters{...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.004343943, 0.09742787, 0.0111...</td>\n",
       "      <td>[0.059179697, 0.5711551, 0.36966518]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1232</td>\n",
       "      <td>neutral</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, lone{lone,ADJ}, p...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, businessman{busin...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.014024382, 0.24962977, 0.1649...</td>\n",
       "      <td>[0.57295847, 0.39508477, 0.031956796]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1661</td>\n",
       "      <td>entailment</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[NULL{null,PROPN}, this{this,DET}, man{man,NOU...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, man{man,NOUN}, is...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.014024382, 0.1707767, 0.01616...</td>\n",
       "      <td>[0.0035327438, 0.9117529, 0.08471438]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>4864</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, girl{girl,NOUN}, ...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, girl{girl,NOUN}, ...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.014024382, 0.17582855, 0.0161...</td>\n",
       "      <td>[0.33920893, 0.6571335, 0.0036575892]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>3086</td>\n",
       "      <td>neutral</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, boy{boy,NOUN}, dr...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, boy{boy,NOUN}, al...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.014024382, 0.1816948, 0.20971...</td>\n",
       "      <td>[0.04164446, 0.030666724, 0.92768884]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>9396</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13633</th>\n",
       "      <td>13633</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, women{woman,NOU...</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, women{woman,NOU...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.08687423, 0.21101676, 0.01119...</td>\n",
       "      <td>[0.032039616, 0.9395012, 0.028459158]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>9812</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13634</th>\n",
       "      <td>13634</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, women{woman,NOU...</td>\n",
       "      <td>[NULL{null,ADJ}, there{there,ADV}, are{be,VERB...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.18873432, 0.011193112, 0.0868...</td>\n",
       "      <td>[0.015357581, 0.07603051, 0.90861195]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>9813</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13635</th>\n",
       "      <td>13635</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, women{woman,NOU...</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, girls{girl,NOUN...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.08687423, 0.21120092, 0.01119...</td>\n",
       "      <td>[0.72494733, 0.22226313, 0.052789498]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>9814</td>\n",
       "      <td>entailment</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13636</th>\n",
       "      <td>13636</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, man{man,NOUN}, in...</td>\n",
       "      <td>[NULL{null,PROPN}, someone{someone,NOUN}, is{b...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.19364926, 0.016168319, 0.2539...</td>\n",
       "      <td>[0.75493157, 0.24075505, 0.00431335]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>9816</td>\n",
       "      <td>entailment</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13637</th>\n",
       "      <td>13637</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, man{man,NOUN}, in...</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, teaching{teach,...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.08687423, 0.15585363, 0.24149...</td>\n",
       "      <td>[0.23783316, 0.65513325, 0.10703355]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>9817</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13638 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Main index                                               Text  \\\n",
       "0               0  [NULL{null,PROPN}, the{the,DET}, firemen{firem...   \n",
       "1               1  [NULL{null,PROPN}, a{a,DET}, lone{lone,ADJ}, p...   \n",
       "2               2  [NULL{null,PROPN}, this{this,DET}, man{man,NOU...   \n",
       "3               3  [NULL{null,PROPN}, a{a,DET}, girl{girl,NOUN}, ...   \n",
       "4               4  [NULL{null,PROPN}, a{a,DET}, boy{boy,NOUN}, dr...   \n",
       "...           ...                                                ...   \n",
       "13633       13633  [NULL{null,ADJ}, two{two,NUM}, women{woman,NOU...   \n",
       "13634       13634  [NULL{null,ADJ}, two{two,NUM}, women{woman,NOU...   \n",
       "13635       13635  [NULL{null,ADJ}, two{two,NUM}, women{woman,NOU...   \n",
       "13636       13636  [NULL{null,PROPN}, a{a,DET}, man{man,NOUN}, in...   \n",
       "13637       13637  [NULL{null,PROPN}, a{a,DET}, man{man,NOUN}, in...   \n",
       "\n",
       "                                               Hipotesis  \\\n",
       "0      [NULL{null,PROPN}, the{the,DET}, firefighters{...   \n",
       "1      [NULL{null,PROPN}, a{a,DET}, businessman{busin...   \n",
       "2      [NULL{null,PROPN}, a{a,DET}, man{man,NOUN}, is...   \n",
       "3      [NULL{null,PROPN}, a{a,DET}, girl{girl,NOUN}, ...   \n",
       "4      [NULL{null,PROPN}, a{a,DET}, boy{boy,NOUN}, al...   \n",
       "...                                                  ...   \n",
       "13633  [NULL{null,ADJ}, two{two,NUM}, women{woman,NOU...   \n",
       "13634  [NULL{null,ADJ}, there{there,ADV}, are{be,VERB...   \n",
       "13635  [NULL{null,ADJ}, two{two,NUM}, girls{girl,NOUN...   \n",
       "13636  [NULL{null,PROPN}, someone{someone,NOUN}, is{b...   \n",
       "13637  [NULL{null,ADJ}, two{two,NUM}, teaching{teach,...   \n",
       "\n",
       "                                                  R_Text  \\\n",
       "0      [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "1      [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "2      [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "3      [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "4      [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "...                                                  ...   \n",
       "13633  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13634  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13635  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13636  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13637  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                                   R_Hip  \\\n",
       "0      [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "1      [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "2      [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "3      [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "4      [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "...                                                  ...   \n",
       "13633  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13634  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13635  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13636  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13637  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                                 M_Align  \\\n",
       "0      [[0.085589595, 0.004343943, 0.09742787, 0.0111...   \n",
       "1      [[0.085589595, 0.014024382, 0.24962977, 0.1649...   \n",
       "2      [[0.085589595, 0.014024382, 0.1707767, 0.01616...   \n",
       "3      [[0.085589595, 0.014024382, 0.17582855, 0.0161...   \n",
       "4      [[0.085589595, 0.014024382, 0.1816948, 0.20971...   \n",
       "...                                                  ...   \n",
       "13633  [[0.085589595, 0.08687423, 0.21101676, 0.01119...   \n",
       "13634  [[0.085589595, 0.18873432, 0.011193112, 0.0868...   \n",
       "13635  [[0.085589595, 0.08687423, 0.21120092, 0.01119...   \n",
       "13636  [[0.085589595, 0.19364926, 0.016168319, 0.2539...   \n",
       "13637  [[0.085589595, 0.08687423, 0.15585363, 0.24149...   \n",
       "\n",
       "                                  Prediction       Gold_label  Paraphrase  \\\n",
       "0       [0.059179697, 0.5711551, 0.36966518]  [0.0, 0.0, 1.0]           0   \n",
       "1      [0.57295847, 0.39508477, 0.031956796]  [0.0, 1.0, 0.0]           0   \n",
       "2      [0.0035327438, 0.9117529, 0.08471438]  [0.0, 1.0, 0.0]           0   \n",
       "3      [0.33920893, 0.6571335, 0.0036575892]  [1.0, 0.0, 0.0]           0   \n",
       "4      [0.04164446, 0.030666724, 0.92768884]  [1.0, 0.0, 0.0]           0   \n",
       "...                                      ...              ...         ...   \n",
       "13633  [0.032039616, 0.9395012, 0.028459158]  [0.0, 1.0, 0.0]           1   \n",
       "13634  [0.015357581, 0.07603051, 0.90861195]  [0.0, 0.0, 1.0]           1   \n",
       "13635  [0.72494733, 0.22226313, 0.052789498]  [1.0, 0.0, 0.0]           1   \n",
       "13636   [0.75493157, 0.24075505, 0.00431335]  [1.0, 0.0, 0.0]           1   \n",
       "13637   [0.23783316, 0.65513325, 0.10703355]  [0.0, 1.0, 0.0]           1   \n",
       "\n",
       "        Idx predicted_label     gold_label  \n",
       "0      1232         neutral  contradiction  \n",
       "1      1661      entailment        neutral  \n",
       "2      4864         neutral        neutral  \n",
       "3      3086         neutral     entailment  \n",
       "4      9396   contradiction     entailment  \n",
       "...     ...             ...            ...  \n",
       "13633  9812         neutral        neutral  \n",
       "13634  9813   contradiction  contradiction  \n",
       "13635  9814      entailment     entailment  \n",
       "13636  9816      entailment     entailment  \n",
       "13637  9817         neutral        neutral  \n",
       "\n",
       "[13638 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_pickle(carpeta+\"pTEST_new_1_0.csv.pickle\")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividimos el corpus en las parafrasis y sin parafrasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main index</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hipotesis</th>\n",
       "      <th>R_Text</th>\n",
       "      <th>R_Hip</th>\n",
       "      <th>M_Align</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold_label</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Idx</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7590</th>\n",
       "      <td>7590</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, asian{asian,ADJ...</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, dogs{dog,NOUN},...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.08687423, 0.39624646, 0.22343...</td>\n",
       "      <td>[0.007730571, 0.8045993, 0.18767011]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1138</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Main index                                               Text  \\\n",
       "7590        7590  [NULL{null,ADJ}, two{two,NUM}, asian{asian,ADJ...   \n",
       "\n",
       "                                              Hipotesis  \\\n",
       "7590  [NULL{null,ADJ}, two{two,NUM}, dogs{dog,NOUN},...   \n",
       "\n",
       "                                                 R_Text  \\\n",
       "7590  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                                  R_Hip  \\\n",
       "7590  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                                M_Align  \\\n",
       "7590  [[0.085589595, 0.08687423, 0.39624646, 0.22343...   \n",
       "\n",
       "                                Prediction       Gold_label  Paraphrase   Idx  \\\n",
       "7590  [0.007730571, 0.8045993, 0.18767011]  [0.0, 1.0, 0.0]           1  1138   \n",
       "\n",
       "     predicted_label gold_label  \n",
       "7590         neutral    neutral  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_con_p=df[df[\"Paraphrase\"]==1]\n",
    "df_sin_p=df[df[\"Paraphrase\"]==0]\n",
    "df_con_p[df_con_p[\"Idx\"]==1138]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_con_p[df_con_p[\"Idx\"]==1138]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NULL{null,ADJ}', 'two{two,NUM}', 'dogs{dog,NOUN}', 'make{make,VERB}', 'hamburgers{hamburger,NOUN}', 'on{on,ADP}', 'the{the,DET}', 'grill{grill,NOUN}', '.{.,PUNCT}']\n"
     ]
    }
   ],
   "source": [
    "for index,strings in a.iterrows():\n",
    "    print(strings[\"Hipotesis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main index</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hipotesis</th>\n",
       "      <th>R_Text</th>\n",
       "      <th>R_Hip</th>\n",
       "      <th>M_Align</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold_label</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Idx</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>4754</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, asian{asian,ADJ...</td>\n",
       "      <td>[NULL{null,ADJ}, there{there,ADV}, are{be,VERB...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.18873432, 0.011193112, 0.2351...</td>\n",
       "      <td>[0.019746551, 0.874434, 0.105819434]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1138</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Main index                                               Text  \\\n",
       "4754        4754  [NULL{null,ADJ}, two{two,NUM}, asian{asian,ADJ...   \n",
       "\n",
       "                                              Hipotesis  \\\n",
       "4754  [NULL{null,ADJ}, there{there,ADV}, are{be,VERB...   \n",
       "\n",
       "                                                 R_Text  \\\n",
       "4754  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                                  R_Hip  \\\n",
       "4754  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                                M_Align  \\\n",
       "4754  [[0.085589595, 0.18873432, 0.011193112, 0.2351...   \n",
       "\n",
       "                                Prediction       Gold_label  Paraphrase   Idx  \\\n",
       "4754  [0.019746551, 0.874434, 0.105819434]  [0.0, 1.0, 0.0]           0  1138   \n",
       "\n",
       "     predicted_label gold_label  \n",
       "4754         neutral    neutral  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sin_p[df_sin_p[\"Idx\"]==1138]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correctos_p=set()\n",
    "indices_incorrectos_p=set()\n",
    "indices_correctos=set()\n",
    "indices_incorrectos=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,strings in df_con_p.iterrows():\n",
    "    if(strings[\"predicted_label\"]==strings[\"gold_label\"]):\n",
    "        indices_correctos_p.add(strings[\"Idx\"])\n",
    "    else:\n",
    "        indices_incorrectos_p.add(strings[\"Idx\"])\n",
    "for index,strings in df_sin_p.iterrows():\n",
    "    if(strings[\"predicted_label\"]==strings[\"gold_label\"]):\n",
    "        indices_correctos.add(strings[\"Idx\"])\n",
    "    else:\n",
    "        indices_incorrectos.add(strings[\"Idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctos con parafrÃ¡sis:  5493\n",
      "Incorrectos con parafrÃ¡sis:  1326\n"
     ]
    }
   ],
   "source": [
    "print(\"Correctos con parafrÃ¡sis: \",len(indices_correctos_p))\n",
    "print(\"Incorrectos con parafrÃ¡sis: \",len(indices_incorrectos_p))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy de los datos con parafrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.5543334799824"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5493/6819*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctos sin parafrÃ¡sis:  5785\n",
      "Incorrectos sin parafrÃ¡sis:  1034\n"
     ]
    }
   ],
   "source": [
    "print(\"Correctos sin parafrÃ¡sis: \",len(indices_correctos))\n",
    "print(\"Incorrectos sin parafrÃ¡sis: \",len(indices_incorrectos))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy de los datos sin parafraseo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.83648628831207"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5785/6819*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queremos identificar que par de <T,H> se infiriÃ³ correctamente a travÃ©s del parafraseo de la hipÃ³tesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parafraseo_correctos=indices_correctos_p.difference(indices_correctos)\n",
    "len(parafraseo_correctos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{85,\n",
       " 186,\n",
       " 312,\n",
       " 330,\n",
       " 347,\n",
       " 379,\n",
       " 395,\n",
       " 513,\n",
       " 668,\n",
       " 699,\n",
       " 700,\n",
       " 707,\n",
       " 875,\n",
       " 899,\n",
       " 946,\n",
       " 971,\n",
       " 1016,\n",
       " 1099,\n",
       " 1166,\n",
       " 1216,\n",
       " 1271,\n",
       " 1279,\n",
       " 1318,\n",
       " 1342,\n",
       " 1359,\n",
       " 1391,\n",
       " 1410,\n",
       " 1430,\n",
       " 1436,\n",
       " 1612,\n",
       " 1677,\n",
       " 1682,\n",
       " 1715,\n",
       " 1739,\n",
       " 1744,\n",
       " 1795,\n",
       " 1846,\n",
       " 1880,\n",
       " 1926,\n",
       " 2022,\n",
       " 2045,\n",
       " 2081,\n",
       " 2126,\n",
       " 2139,\n",
       " 2164,\n",
       " 2248,\n",
       " 2252,\n",
       " 2258,\n",
       " 2335,\n",
       " 2385,\n",
       " 2433,\n",
       " 2488,\n",
       " 2557,\n",
       " 2619,\n",
       " 2634,\n",
       " 2715,\n",
       " 2734,\n",
       " 2748,\n",
       " 2771,\n",
       " 2880,\n",
       " 2960,\n",
       " 3016,\n",
       " 3037,\n",
       " 3064,\n",
       " 3066,\n",
       " 3086,\n",
       " 3100,\n",
       " 3144,\n",
       " 3348,\n",
       " 3395,\n",
       " 3487,\n",
       " 3514,\n",
       " 3548,\n",
       " 3850,\n",
       " 3884,\n",
       " 3922,\n",
       " 4204,\n",
       " 4368,\n",
       " 4435,\n",
       " 4555,\n",
       " 4613,\n",
       " 4625,\n",
       " 4642,\n",
       " 4646,\n",
       " 4683,\n",
       " 4742,\n",
       " 4803,\n",
       " 4831,\n",
       " 4844,\n",
       " 4987,\n",
       " 5008,\n",
       " 5019,\n",
       " 5126,\n",
       " 5137,\n",
       " 5153,\n",
       " 5290,\n",
       " 5437,\n",
       " 5482,\n",
       " 5571,\n",
       " 5671,\n",
       " 5701,\n",
       " 5917,\n",
       " 6232,\n",
       " 6245,\n",
       " 6300,\n",
       " 6420,\n",
       " 6739,\n",
       " 6741,\n",
       " 6751,\n",
       " 6791,\n",
       " 6808,\n",
       " 6924,\n",
       " 6931,\n",
       " 6947,\n",
       " 6950,\n",
       " 6975,\n",
       " 7023,\n",
       " 7091,\n",
       " 7154,\n",
       " 7198,\n",
       " 7220,\n",
       " 7260,\n",
       " 7293,\n",
       " 7313,\n",
       " 7341,\n",
       " 7364,\n",
       " 7374,\n",
       " 7507,\n",
       " 7520,\n",
       " 7652,\n",
       " 7715,\n",
       " 7731,\n",
       " 7782,\n",
       " 7816,\n",
       " 7830,\n",
       " 7881,\n",
       " 7947,\n",
       " 7959,\n",
       " 8019,\n",
       " 8055,\n",
       " 8164,\n",
       " 8179,\n",
       " 8194,\n",
       " 8203,\n",
       " 8219,\n",
       " 8231,\n",
       " 8338,\n",
       " 8342,\n",
       " 8362,\n",
       " 8372,\n",
       " 8385,\n",
       " 8399,\n",
       " 8469,\n",
       " 8606,\n",
       " 8669,\n",
       " 8742,\n",
       " 8759,\n",
       " 8783,\n",
       " 8861,\n",
       " 8891,\n",
       " 8892,\n",
       " 8952,\n",
       " 9065,\n",
       " 9079,\n",
       " 9102,\n",
       " 9216,\n",
       " 9218,\n",
       " 9339,\n",
       " 9442,\n",
       " 9555,\n",
       " 9579,\n",
       " 9581,\n",
       " 9607,\n",
       " 9654,\n",
       " 9735,\n",
       " 9777,\n",
       " 9794}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parafraseo_correctos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main index</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hipotesis</th>\n",
       "      <th>R_Text</th>\n",
       "      <th>R_Hip</th>\n",
       "      <th>M_Align</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold_label</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Idx</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, girl{girl,NOUN}, ...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, girl{girl,NOUN}, ...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.014024382, 0.17582855, 0.0161...</td>\n",
       "      <td>[0.33920893, 0.6571335, 0.0036575892]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>3086</td>\n",
       "      <td>neutral</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>[NULL{null,ADJ}, woman{woman,NOUN}, running{ru...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.014024382, 0.17077179, 0.2678...</td>\n",
       "      <td>[0.463231, 0.47502768, 0.06174128]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>neutral</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>[NULL{null,PROPN}, an{an,DET}, old{old,ADJ}, w...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, young{young,ADJ},...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.014024382, 0.053287175, 0.170...</td>\n",
       "      <td>[0.3322924, 0.43128973, 0.23641777]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>6924</td>\n",
       "      <td>neutral</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>242</td>\n",
       "      <td>[NULL{null,ADJ}, baby{baby,NOUN}, in{in,ADP}, ...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, young{young,ADJ},...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.014024382, 0.053287175, 0.181...</td>\n",
       "      <td>[0.04414552, 0.5931632, 0.3626913]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1166</td>\n",
       "      <td>neutral</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>319</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.014024382, 0.17077179, 0.1088...</td>\n",
       "      <td>[0.5266995, 0.44589806, 0.027402503]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>6791</td>\n",
       "      <td>entailment</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501</th>\n",
       "      <td>13501</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, woman{woman,NOU...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.08687423, 0.17077179, 0.09413...</td>\n",
       "      <td>[0.019005693, 0.36005303, 0.6209412]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>9607</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13530</th>\n",
       "      <td>13530</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, golden{golden,ADJ...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, large{large,ADJ},...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.014024382, 0.084897816, 0.354...</td>\n",
       "      <td>[0.37810367, 0.39856178, 0.22333454]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>9654</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13586</th>\n",
       "      <td>13586</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, man{man,NOUN}, wi...</td>\n",
       "      <td>[NULL{null,PROPN}, the{the,DET}, family{family...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.004343943, 0.1738117, 0.13922...</td>\n",
       "      <td>[0.005763933, 0.31997502, 0.67426103]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>9735</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13616</th>\n",
       "      <td>13616</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, white{white,ADJ},...</td>\n",
       "      <td>[NULL{null,ADJ}, theck{theck,NOUN}, kept{keep,...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.12364106, 0.101227164, 0.1314...</td>\n",
       "      <td>[0.14241612, 0.28040645, 0.57717746]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>9777</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13627</th>\n",
       "      <td>13627</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, older{old,ADJ}, m...</td>\n",
       "      <td>[NULL{null,PROPN}, the{the,DET}, master{master...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.004343943, 0.15474764, 0.0161...</td>\n",
       "      <td>[0.04165754, 0.9556199, 0.0027225513]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>9794</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Main index                                               Text  \\\n",
       "3               3  [NULL{null,PROPN}, a{a,DET}, girl{girl,NOUN}, ...   \n",
       "44             44  [NULL{null,ADJ}, woman{woman,NOUN}, running{ru...   \n",
       "154           154  [NULL{null,PROPN}, an{an,DET}, old{old,ADJ}, w...   \n",
       "242           242  [NULL{null,ADJ}, baby{baby,NOUN}, in{in,ADP}, ...   \n",
       "319           319  [NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...   \n",
       "...           ...                                                ...   \n",
       "13501       13501  [NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...   \n",
       "13530       13530  [NULL{null,PROPN}, a{a,DET}, golden{golden,ADJ...   \n",
       "13586       13586  [NULL{null,PROPN}, a{a,DET}, man{man,NOUN}, wi...   \n",
       "13616       13616  [NULL{null,PROPN}, a{a,DET}, white{white,ADJ},...   \n",
       "13627       13627  [NULL{null,PROPN}, a{a,DET}, older{old,ADJ}, m...   \n",
       "\n",
       "                                               Hipotesis  \\\n",
       "3      [NULL{null,PROPN}, a{a,DET}, girl{girl,NOUN}, ...   \n",
       "44     [NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...   \n",
       "154    [NULL{null,PROPN}, a{a,DET}, young{young,ADJ},...   \n",
       "242    [NULL{null,PROPN}, a{a,DET}, young{young,ADJ},...   \n",
       "319    [NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...   \n",
       "...                                                  ...   \n",
       "13501  [NULL{null,ADJ}, two{two,NUM}, woman{woman,NOU...   \n",
       "13530  [NULL{null,PROPN}, a{a,DET}, large{large,ADJ},...   \n",
       "13586  [NULL{null,PROPN}, the{the,DET}, family{family...   \n",
       "13616  [NULL{null,ADJ}, theck{theck,NOUN}, kept{keep,...   \n",
       "13627  [NULL{null,PROPN}, the{the,DET}, master{master...   \n",
       "\n",
       "                                                  R_Text  \\\n",
       "3      [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "44     [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "154    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "242    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "319    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "...                                                  ...   \n",
       "13501  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13530  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13586  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13616  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13627  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                                   R_Hip  \\\n",
       "3      [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "44     [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "154    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "242    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "319    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "...                                                  ...   \n",
       "13501  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13530  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13586  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13616  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "13627  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                                 M_Align  \\\n",
       "3      [[0.085589595, 0.014024382, 0.17582855, 0.0161...   \n",
       "44     [[0.085589595, 0.014024382, 0.17077179, 0.2678...   \n",
       "154    [[0.085589595, 0.014024382, 0.053287175, 0.170...   \n",
       "242    [[0.085589595, 0.014024382, 0.053287175, 0.181...   \n",
       "319    [[0.085589595, 0.014024382, 0.17077179, 0.1088...   \n",
       "...                                                  ...   \n",
       "13501  [[0.085589595, 0.08687423, 0.17077179, 0.09413...   \n",
       "13530  [[0.085589595, 0.014024382, 0.084897816, 0.354...   \n",
       "13586  [[0.085589595, 0.004343943, 0.1738117, 0.13922...   \n",
       "13616  [[0.085589595, 0.12364106, 0.101227164, 0.1314...   \n",
       "13627  [[0.085589595, 0.004343943, 0.15474764, 0.0161...   \n",
       "\n",
       "                                  Prediction       Gold_label  Paraphrase  \\\n",
       "3      [0.33920893, 0.6571335, 0.0036575892]  [1.0, 0.0, 0.0]           0   \n",
       "44        [0.463231, 0.47502768, 0.06174128]  [1.0, 0.0, 0.0]           0   \n",
       "154      [0.3322924, 0.43128973, 0.23641777]  [0.0, 0.0, 1.0]           0   \n",
       "242       [0.04414552, 0.5931632, 0.3626913]  [0.0, 0.0, 1.0]           0   \n",
       "319     [0.5266995, 0.44589806, 0.027402503]  [0.0, 1.0, 0.0]           0   \n",
       "...                                      ...              ...         ...   \n",
       "13501   [0.019005693, 0.36005303, 0.6209412]  [0.0, 0.0, 1.0]           1   \n",
       "13530   [0.37810367, 0.39856178, 0.22333454]  [0.0, 1.0, 0.0]           1   \n",
       "13586  [0.005763933, 0.31997502, 0.67426103]  [0.0, 0.0, 1.0]           1   \n",
       "13616   [0.14241612, 0.28040645, 0.57717746]  [0.0, 0.0, 1.0]           1   \n",
       "13627  [0.04165754, 0.9556199, 0.0027225513]  [0.0, 1.0, 0.0]           1   \n",
       "\n",
       "        Idx predicted_label     gold_label  \n",
       "3      3086         neutral     entailment  \n",
       "44     2022         neutral     entailment  \n",
       "154    6924         neutral  contradiction  \n",
       "242    1166         neutral  contradiction  \n",
       "319    6791      entailment        neutral  \n",
       "...     ...             ...            ...  \n",
       "13501  9607   contradiction  contradiction  \n",
       "13530  9654         neutral        neutral  \n",
       "13586  9735   contradiction  contradiction  \n",
       "13616  9777   contradiction  contradiction  \n",
       "13627  9794         neutral        neutral  \n",
       "\n",
       "[354 rows x 12 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parafraseos_correctos=df[df[\"Idx\"].isin(parafraseo_correctos)]\n",
    "df_parafraseos_correctos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EstadÃ­stica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropia_f(X):\n",
    "    \"\"\"Devuelve el valor de entropia de una muestra de datos\"\"\" \n",
    "    probs = [np.mean(X == valor) for valor in set(X)]\n",
    "    return round(np.sum(-p * np.log2(p) for p in probs), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n",
      "/tmp/ipykernel_140408/521637173.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return round(np.sum(-p * np.log2(p) for p in probs), 3)\n"
     ]
    }
   ],
   "source": [
    "new_data = {'Idx' : [], 'Texto': [], 'Hipotesis': [],'M_Align':[],'ma_umbral':[],\n",
    "            'Paraphrase':[],'predicted_label':[],'gold_label':[],'entropia':[]}\n",
    "\n",
    "#sns.set(rc={'figure.figsize':(20,90)})\n",
    "#fig,  axes= plt.subplots(9, 2)\n",
    "\n",
    "for i in parafraseo_correctos:\n",
    "    j=0\n",
    "    l_entropia=[]\n",
    "    temp=df_parafraseos_correctos[df_parafraseos_correctos[\"Idx\"]==i]\n",
    "    #print(temp.index[0])\n",
    "    matrizPOS=[]\n",
    "    idx=temp.at[temp.index[0],\"Idx\"]\n",
    "    t=temp.at[temp.index[0],\"Text\"]\n",
    "    h=temp.at[temp.index[0],\"Hipotesis\"]\n",
    "    matriz=temp.at[temp.index[0],\"M_Align\"]\n",
    "    #matrizPOS=temp.at[temp.index[0],\"ma_umbral\"]\n",
    "    paraphrase=temp.at[temp.index[0],\"Paraphrase\"]\n",
    "    tn=len(t)-1\n",
    "    hn=len(h)-1\n",
    "    if(len(t)>41 & len(h)>41):\n",
    "        tn=41\n",
    "        hn=41\n",
    "        matriz_c=matriz[1:tn,1:hn]\n",
    "    elif(len(t)>41):\n",
    "        tn=41\n",
    "        matriz_c=matriz[1:tn,1:hn]\n",
    "    elif(len(h)>41):\n",
    "        hn=41\n",
    "        matriz_c=matriz[1:tn,1:hn]\n",
    "    else:\n",
    "        matriz_c=matriz[1:tn,1:hn]\n",
    "    df_matriz=pd.DataFrame(matriz_c,columns=h[1:hn],index=t[1:tn])\n",
    "    new_data['entropia'].append(np.array(entropia_f(stats.zscore(matriz_c.T).flatten())))\n",
    "#    sns.heatmap(ax=axes[j,0],data=df_matriz, center=0, cmap='Blues_r', annot=True)\n",
    "    #axes[j,0].set(title=\"Parafraseo: \"+str(paraphrase))\n",
    "    \n",
    "    predic=temp.at[temp.index[0],\"predicted_label\"]\n",
    "    gold=temp.at[temp.index[0],\"gold_label\"]\n",
    "    new_data['Idx'].append(idx)\n",
    "    new_data['Texto'].append(t)\n",
    "    new_data['Hipotesis'].append(h)\n",
    "    new_data['M_Align'].append(df_matriz)\n",
    "    new_data['ma_umbral'].append(matrizPOS)\n",
    "    new_data['Paraphrase'].append(paraphrase)\n",
    "    new_data['predicted_label'].append(predic)\n",
    "    new_data['gold_label'].append(gold)\n",
    "\n",
    "    idx=temp.at[temp.index[1],\"Idx\"]\n",
    "    t=temp.at[temp.index[1],\"Text\"]\n",
    "    h=temp.at[temp.index[1],\"Hipotesis\"]\n",
    "    matriz=temp.at[temp.index[1],\"M_Align\"]\n",
    "    #matrizPOS=temp.at[temp.index[1],\"ma_umbral\"]\n",
    "    paraphrase=temp.at[temp.index[1],\"Paraphrase\"]\n",
    "    tn=len(t)-1\n",
    "    hn=len(h)-1\n",
    "    if(len(t)>41 & len(h)>41):\n",
    "        tn=41\n",
    "        hn=41\n",
    "        matriz_c=matriz[1:tn,1:hn]\n",
    "    elif(len(t)>41):\n",
    "        tn=41\n",
    "        matriz_c=matriz[1:tn,1:hn]\n",
    "    elif(len(h)>41):\n",
    "        hn=41\n",
    "        matriz_c=matriz[1:tn,1:hn]\n",
    "    else:\n",
    "        matriz_c=matriz[1:tn,1:hn]\n",
    "    df_matriz=pd.DataFrame(matriz_c,columns=h[1:hn],index=t[1:tn])\n",
    "    new_data['entropia'].append(np.array(entropia_f(stats.zscore(matriz_c.T).flatten())))\n",
    "#    sns.heatmap(ax=axes[j,1],data=df_matriz, center=0, cmap='Blues_r', annot=True)\n",
    "    #axes[j,1].set(title=\"Parafraseo: \"+str(paraphrase))\n",
    "    predic=temp.at[temp.index[1],\"predicted_label\"]\n",
    "    gold=temp.at[temp.index[1],\"gold_label\"]\n",
    "    new_data['Idx'].append(idx)\n",
    "    new_data['Texto'].append(t)\n",
    "    new_data['Hipotesis'].append(h)\n",
    "    new_data['M_Align'].append(df_matriz)\n",
    "    new_data['ma_umbral'].append(matrizPOS)\n",
    "    new_data['Paraphrase'].append(paraphrase)\n",
    "    new_data['predicted_label'].append(predic)\n",
    "    new_data['gold_label'].append(gold)\n",
    "    j=j+1\n",
    "#plt.show()\n",
    "dfn=pd.DataFrame(new_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Idx</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Hipotesis</th>\n",
       "      <th>M_Align</th>\n",
       "      <th>ma_umbral</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>entropia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9216</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, little{little,A...</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, kids{kid,NOUN},...</td>\n",
       "      <td>two{two,NUM}  kids{kid,NO...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9216</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, little{little,A...</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, kids{kid,NOUN},...</td>\n",
       "      <td>two{two,NUM}  kids{kid,NO...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>513</td>\n",
       "      <td>[NULL{null,PROPN}, an{an,DET}, old{old,ADJ}, s...</td>\n",
       "      <td>[NULL{null,PROPN}, the{the,DET}, shoemaker{sho...</td>\n",
       "      <td>the{the,DET}  shoem...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>513</td>\n",
       "      <td>[NULL{null,PROPN}, an{an,DET}, old{old,ADJ}, s...</td>\n",
       "      <td>[NULL{null,PROPN}, the{the,DET}, hammerists{ha...</td>\n",
       "      <td>the{the,DET}  hamme...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8194</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, crowd{crowd,NOUN}...</td>\n",
       "      <td>[NULL{null,PROPN}, the{the,DET}, statue{statue...</td>\n",
       "      <td>the{the,DET}  statue{sta...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>6.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>3064</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, brown{brown,ADJ},...</td>\n",
       "      <td>[NULL{null,ADJ}, there{there,ADV}, is{be,VERB}...</td>\n",
       "      <td>there{there,ADV}  is{be,V...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>6.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>3066</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, brown{brown,ADJ},...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, brown{brown,ADJ},...</td>\n",
       "      <td>a{a,DET}  brown{brown,ADJ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>entailment</td>\n",
       "      <td>6.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>3066</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, brown{brown,ADJ},...</td>\n",
       "      <td>[NULL{null,ADJ}, one{one,NUM}, dog{dog,NOUN}, ...</td>\n",
       "      <td>one{one,NUM}  dog{dog,NOU...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>entailment</td>\n",
       "      <td>entailment</td>\n",
       "      <td>6.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>2557</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, blond{blond,ADJ},...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, blond{blond,ADJ},...</td>\n",
       "      <td>a{a,DET}  blond{blond...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>8.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2557</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, blond{blond,ADJ},...</td>\n",
       "      <td>[NULL{null,INTJ}, the{the,DET}, middle{middle,...</td>\n",
       "      <td>the{the,DET}  middle{...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>8.053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Idx                                              Texto  \\\n",
       "0    9216  [NULL{null,ADJ}, two{two,NUM}, little{little,A...   \n",
       "1    9216  [NULL{null,ADJ}, two{two,NUM}, little{little,A...   \n",
       "2     513  [NULL{null,PROPN}, an{an,DET}, old{old,ADJ}, s...   \n",
       "3     513  [NULL{null,PROPN}, an{an,DET}, old{old,ADJ}, s...   \n",
       "4    8194  [NULL{null,PROPN}, a{a,DET}, crowd{crowd,NOUN}...   \n",
       "..    ...                                                ...   \n",
       "349  3064  [NULL{null,PROPN}, a{a,DET}, brown{brown,ADJ},...   \n",
       "350  3066  [NULL{null,PROPN}, a{a,DET}, brown{brown,ADJ},...   \n",
       "351  3066  [NULL{null,PROPN}, a{a,DET}, brown{brown,ADJ},...   \n",
       "352  2557  [NULL{null,PROPN}, a{a,DET}, blond{blond,ADJ},...   \n",
       "353  2557  [NULL{null,PROPN}, a{a,DET}, blond{blond,ADJ},...   \n",
       "\n",
       "                                             Hipotesis  \\\n",
       "0    [NULL{null,ADJ}, two{two,NUM}, kids{kid,NOUN},...   \n",
       "1    [NULL{null,ADJ}, two{two,NUM}, kids{kid,NOUN},...   \n",
       "2    [NULL{null,PROPN}, the{the,DET}, shoemaker{sho...   \n",
       "3    [NULL{null,PROPN}, the{the,DET}, hammerists{ha...   \n",
       "4    [NULL{null,PROPN}, the{the,DET}, statue{statue...   \n",
       "..                                                 ...   \n",
       "349  [NULL{null,ADJ}, there{there,ADV}, is{be,VERB}...   \n",
       "350  [NULL{null,PROPN}, a{a,DET}, brown{brown,ADJ},...   \n",
       "351  [NULL{null,ADJ}, one{one,NUM}, dog{dog,NOUN}, ...   \n",
       "352  [NULL{null,PROPN}, a{a,DET}, blond{blond,ADJ},...   \n",
       "353  [NULL{null,INTJ}, the{the,DET}, middle{middle,...   \n",
       "\n",
       "                                               M_Align ma_umbral  Paraphrase  \\\n",
       "0                         two{two,NUM}  kids{kid,NO...        []           0   \n",
       "1                         two{two,NUM}  kids{kid,NO...        []           1   \n",
       "2                               the{the,DET}  shoem...        []           0   \n",
       "3                               the{the,DET}  hamme...        []           1   \n",
       "4                          the{the,DET}  statue{sta...        []           0   \n",
       "..                                                 ...       ...         ...   \n",
       "349                       there{there,ADV}  is{be,V...        []           1   \n",
       "350                       a{a,DET}  brown{brown,ADJ...        []           0   \n",
       "351                       one{one,NUM}  dog{dog,NOU...        []           1   \n",
       "352                           a{a,DET}  blond{blond...        []           0   \n",
       "353                           the{the,DET}  middle{...        []           1   \n",
       "\n",
       "    predicted_label     gold_label entropia  \n",
       "0     contradiction        neutral    5.392  \n",
       "1           neutral        neutral    5.543  \n",
       "2     contradiction        neutral    4.322  \n",
       "3           neutral        neutral    4.322  \n",
       "4           neutral  contradiction    6.407  \n",
       "..              ...            ...      ...  \n",
       "349   contradiction  contradiction    6.781  \n",
       "350   contradiction     entailment    6.072  \n",
       "351      entailment     entailment    6.129  \n",
       "352         neutral  contradiction    8.156  \n",
       "353   contradiction  contradiction    8.053  \n",
       "\n",
       "[354 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,strings in pre_df.iterrows():\n",
    "    sns.set(rc={'figure.figsize':(20,10)})\n",
    "    #fig,  axes= plt.subplots(2,2)\n",
    "    sns.heatmap(data=strings[\"M_Align\"], center=0, cmap='Blues', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener los parafraseos del GPT3.5 con la hipotesis original y crear el corpus para procesarlo con el modelo de inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A girl is displaying affection towards a cat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman is jogging in a park.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A young woman and an elderly man are engaged i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A young boy is playing with a basketball.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A woman has entered into marriage.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>A man and his wife sit outside with their chil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>The man organizes a concert outside.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>A woman holds her sleeping son while walking d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>People shop for veggies at a nice market.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>A moving truck is being disassembled.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0        A girl is displaying affection towards a cat.\n",
       "1                        A woman is jogging in a park.\n",
       "2    A young woman and an elderly man are engaged i...\n",
       "3            A young boy is playing with a basketball.\n",
       "4                   A woman has entered into marriage.\n",
       "..                                                 ...\n",
       "168  A man and his wife sit outside with their chil...\n",
       "169               The man organizes a concert outside.\n",
       "170  A woman holds her sleeping son while walking d...\n",
       "171          People shop for veggies at a nice market.\n",
       "172              A moving truck is being disassembled.\n",
       "\n",
       "[173 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parapf_GPT3=pd.read_csv(\"data/gpt3/gpt3/paraphrase.csv\",header=None)\n",
    "parapf_GPT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hipotesis_ori=pd.read_csv(\"data/gpt3/gpt3/hipotesis.txt\",sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A girl is showing affection towards a cat.</td>\n",
       "      <td>3086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A woman jogging in a park.</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A young woman and old man are playing poker.</td>\n",
       "      <td>6924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A young boy is playing with a basketball.</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A woman got married.</td>\n",
       "      <td>6791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>168</td>\n",
       "      <td>A man and wife sit outside with their children.</td>\n",
       "      <td>2335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>The man is throwing a concert outside</td>\n",
       "      <td>3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>A woman holding her sleeping son while walking...</td>\n",
       "      <td>1682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>People shopping for veggies at a nice market.</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>A moving truck being disassembled.</td>\n",
       "      <td>6931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1     2\n",
       "0      0         A girl is showing affection towards a cat.  3086\n",
       "1      1                         A woman jogging in a park.  2022\n",
       "2      2       A young woman and old man are playing poker.  6924\n",
       "3      3          A young boy is playing with a basketball.  1166\n",
       "4      4                               A woman got married.  6791\n",
       "..   ...                                                ...   ...\n",
       "168  168    A man and wife sit outside with their children.  2335\n",
       "169  169              The man is throwing a concert outside  3100\n",
       "170  170  A woman holding her sleeping son while walking...  1682\n",
       "171  171      People shopping for veggies at a nice market.  2252\n",
       "172  172                 A moving truck being disassembled.  6931\n",
       "\n",
       "[173 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hipotesis_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A girl is showing affection towards a cat.</td>\n",
       "      <td>3086</td>\n",
       "      <td>A girl is displaying affection towards a cat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A woman jogging in a park.</td>\n",
       "      <td>2022</td>\n",
       "      <td>A woman is jogging in a park.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A young woman and old man are playing poker.</td>\n",
       "      <td>6924</td>\n",
       "      <td>A young woman and an elderly man are engaged i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A young boy is playing with a basketball.</td>\n",
       "      <td>1166</td>\n",
       "      <td>A young boy is playing with a basketball.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A woman got married.</td>\n",
       "      <td>6791</td>\n",
       "      <td>A woman has entered into marriage.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>168</td>\n",
       "      <td>A man and wife sit outside with their children.</td>\n",
       "      <td>2335</td>\n",
       "      <td>A man and his wife sit outside with their chil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>The man is throwing a concert outside</td>\n",
       "      <td>3100</td>\n",
       "      <td>The man organizes a concert outside.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>A woman holding her sleeping son while walking...</td>\n",
       "      <td>1682</td>\n",
       "      <td>A woman holds her sleeping son while walking d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>People shopping for veggies at a nice market.</td>\n",
       "      <td>2252</td>\n",
       "      <td>People shop for veggies at a nice market.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>A moving truck being disassembled.</td>\n",
       "      <td>6931</td>\n",
       "      <td>A moving truck is being disassembled.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0_x                                                  1     2  \\\n",
       "0      0         A girl is showing affection towards a cat.  3086   \n",
       "1      1                         A woman jogging in a park.  2022   \n",
       "2      2       A young woman and old man are playing poker.  6924   \n",
       "3      3          A young boy is playing with a basketball.  1166   \n",
       "4      4                               A woman got married.  6791   \n",
       "..   ...                                                ...   ...   \n",
       "168  168    A man and wife sit outside with their children.  2335   \n",
       "169  169              The man is throwing a concert outside  3100   \n",
       "170  170  A woman holding her sleeping son while walking...  1682   \n",
       "171  171      People shopping for veggies at a nice market.  2252   \n",
       "172  172                 A moving truck being disassembled.  6931   \n",
       "\n",
       "                                                   0_y  \n",
       "0        A girl is displaying affection towards a cat.  \n",
       "1                        A woman is jogging in a park.  \n",
       "2    A young woman and an elderly man are engaged i...  \n",
       "3            A young boy is playing with a basketball.  \n",
       "4                   A woman has entered into marriage.  \n",
       "..                                                 ...  \n",
       "168  A man and his wife sit outside with their chil...  \n",
       "169               The man organizes a concert outside.  \n",
       "170  A woman holds her sleeping son while walking d...  \n",
       "171          People shop for veggies at a nice market.  \n",
       "172              A moving truck is being disassembled.  \n",
       "\n",
       "[173 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_join_origin_gp3 = pd.merge(hipotesis_ori, parapf_GPT3, how='left', on=None, left_on=None, right_on=None,\n",
    "         left_index=True, right_index=True)\n",
    "left_join_origin_gp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3086, 2022, 6924, 1166, 6791, 5290,  971, 2258, 5701, 7341, 9654,\n",
       "         67, 9339, 1099,  707, 8219, 4625,  347, 2126, 2164, 2045, 1279,\n",
       "       3922, 4646, 3548,  379, 2248, 8362, 2433, 8759, 1744, 9555, 8783,\n",
       "       4803, 7959, 5840, 6739, 8019, 7947, 2715, 3016, 2081, 5019, 9735,\n",
       "       9079, 7313, 5437, 7364, 9777, 7023, 4435, 5126,  395, 1795, 7507,\n",
       "       1016, 8399, 3144, 7260, 9065, 4368, 8203, 7293, 2619, 1410, 1436,\n",
       "       8892, 8469, 8338, 8179, 8055, 8164, 9607, 3514, 6950, 5137, 1715,\n",
       "       1359, 4555, 2488, 3037, 9581, 8385, 7198, 7220,   85, 2880, 4832,\n",
       "       1612, 1666, 4613, 9579, 7154, 4683, 8742, 5571,  312, 3348, 1677,\n",
       "       7731,  875,  186, 9218, 1430, 3487, 8372, 7816, 4987, 8861, 8194,\n",
       "       5153, 7830, 6751, 8342, 4204, 9794, 8669, 8952, 2748, 2139, 5917,\n",
       "       6532, 2836, 1880,  699, 7374, 1391, 1138, 2634, 7652, 8891, 6947,\n",
       "       9442, 7881, 3408, 3850, 4642,  330, 9102, 3066, 1318, 3395, 4844,\n",
       "       2557, 2734, 5671, 1846, 7782, 6245, 1342, 3064, 3884, 5482,  946,\n",
       "       6808, 2960,  700, 6300,  899, 4742, 6420, 7520, 5008, 1271, 1739,\n",
       "       1216, 2385, 6975, 2335, 3100, 1682, 2252, 6931])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idsx =left_join_origin_gp3[2].unique()\n",
    "idsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCorpus_test = pd.read_csv(\"data/salida_p/1/TEST_new_1_0.csv\")\n",
    "gpt2_paraphrase=dataCorpus_test[dataCorpus_test[\"Parafraseo\"]==1]\n",
    "tempHipotesisOriginales=dataCorpus_test[dataCorpus_test[\"Parafraseo\"]==0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HipÃ³tesis original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>SET</th>\n",
       "      <th>Parafraseo</th>\n",
       "      <th>Idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entailment</td>\n",
       "      <td>A girl reaches up to kiss a cat, which is sitt...</td>\n",
       "      <td>A girl is showing affection towards a cat.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>3086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>entailment</td>\n",
       "      <td>Woman running in a park while listening to music.</td>\n",
       "      <td>A woman jogging in a park.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>An old woman and a young man examine their bin...</td>\n",
       "      <td>A young woman and old man are playing poker.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>6924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>Baby in running in over-sized flip-flops.</td>\n",
       "      <td>A young boy is playing with a basketball.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A woman in a white wedding dress is being dres...</td>\n",
       "      <td>A woman got married.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>6791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A family with young children sits down outside.</td>\n",
       "      <td>A man and wife sit outside with their children.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>2335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6557</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Fireworks light up the night as a man stands o...</td>\n",
       "      <td>The man is throwing a concert outside</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6597</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A young middle eastern mother in high heels, h...</td>\n",
       "      <td>A woman holding her sleeping son while walking...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>1682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6642</th>\n",
       "      <td>neutral</td>\n",
       "      <td>People shopping for vegetables at an outdoor m...</td>\n",
       "      <td>People shopping for veggies at a nice market.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A moving truck with a ramp still attached.</td>\n",
       "      <td>A moving truck being disassembled.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>6931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gold_label                                          sentence1  \\\n",
       "3        entailment  A girl reaches up to kiss a cat, which is sitt...   \n",
       "44       entailment  Woman running in a park while listening to music.   \n",
       "154   contradiction  An old woman and a young man examine their bin...   \n",
       "242   contradiction          Baby in running in over-sized flip-flops.   \n",
       "319         neutral  A woman in a white wedding dress is being dres...   \n",
       "...             ...                                                ...   \n",
       "6517        neutral    A family with young children sits down outside.   \n",
       "6557        neutral  Fireworks light up the night as a man stands o...   \n",
       "6597  contradiction  A young middle eastern mother in high heels, h...   \n",
       "6642        neutral  People shopping for vegetables at an outdoor m...   \n",
       "6682  contradiction         A moving truck with a ramp still attached.   \n",
       "\n",
       "                                              sentence2   SET  Parafraseo  \\\n",
       "3            A girl is showing affection towards a cat.  TEST       False   \n",
       "44                           A woman jogging in a park.  TEST       False   \n",
       "154        A young woman and old man are playing poker.  TEST       False   \n",
       "242           A young boy is playing with a basketball.  TEST       False   \n",
       "319                                A woman got married.  TEST       False   \n",
       "...                                                 ...   ...         ...   \n",
       "6517    A man and wife sit outside with their children.  TEST       False   \n",
       "6557              The man is throwing a concert outside  TEST       False   \n",
       "6597  A woman holding her sleeping son while walking...  TEST       False   \n",
       "6642      People shopping for veggies at a nice market.  TEST       False   \n",
       "6682                 A moving truck being disassembled.  TEST       False   \n",
       "\n",
       "       Idx  \n",
       "3     3086  \n",
       "44    2022  \n",
       "154   6924  \n",
       "242   1166  \n",
       "319   6791  \n",
       "...    ...  \n",
       "6517  2335  \n",
       "6557  3100  \n",
       "6597  1682  \n",
       "6642  2252  \n",
       "6682  6931  \n",
       "\n",
       "[173 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempHipotesisOriginales = tempHipotesisOriginales[tempHipotesisOriginales[\"Idx\"].isin(idsx)]\n",
    "tempHipotesisOriginales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>SET</th>\n",
       "      <th>Parafraseo</th>\n",
       "      <th>Idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6869</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A snowboarder on a wide plain of snow</td>\n",
       "      <td>Anowmobile in a snowstorm</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6882</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A child wearing a red top is standing behind a...</td>\n",
       "      <td>A pretty blond child wearing a red top is stan...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6956</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A man and woman are taking a picture of themse...</td>\n",
       "      <td>Two woman having mug shots taken of her while ...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A man in an Alaska sweatshirt stands behind a ...</td>\n",
       "      <td>He is in Alaska.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7053</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>Island native fishermen reeling in their nets ...</td>\n",
       "      <td>They bothmale did not go to work today but ins...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A woman in black walks down the street in fron...</td>\n",
       "      <td>Two woman standing staring at a painted mural.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>9607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13530</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A golden dog bounds across the snow-covered hill.</td>\n",
       "      <td>A large animal bounds across a snow-covered pl...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>9654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13586</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A man with glasses sitting at a restaurant sta...</td>\n",
       "      <td>The family sits at home waiting for dinner</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>9735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13616</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A white duck is spreading its wings while sitt...</td>\n",
       "      <td>Theck kept it's wings intact as they dived int...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>9777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13627</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A older man in a hat is playing a accordion on...</td>\n",
       "      <td>The master is wearing a hat.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>9794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gold_label                                          sentence1  \\\n",
       "6869         neutral              A snowboarder on a wide plain of snow   \n",
       "6882         neutral  A child wearing a red top is standing behind a...   \n",
       "6956   contradiction  A man and woman are taking a picture of themse...   \n",
       "7038         neutral  A man in an Alaska sweatshirt stands behind a ...   \n",
       "7053   contradiction  Island native fishermen reeling in their nets ...   \n",
       "...              ...                                                ...   \n",
       "13501  contradiction  A woman in black walks down the street in fron...   \n",
       "13530        neutral  A golden dog bounds across the snow-covered hill.   \n",
       "13586  contradiction  A man with glasses sitting at a restaurant sta...   \n",
       "13616  contradiction  A white duck is spreading its wings while sitt...   \n",
       "13627        neutral  A older man in a hat is playing a accordion on...   \n",
       "\n",
       "                                               sentence2   SET  Parafraseo  \\\n",
       "6869                           Anowmobile in a snowstorm  TEST        True   \n",
       "6882   A pretty blond child wearing a red top is stan...  TEST        True   \n",
       "6956   Two woman having mug shots taken of her while ...  TEST        True   \n",
       "7038                                    He is in Alaska.  TEST        True   \n",
       "7053   They bothmale did not go to work today but ins...  TEST        True   \n",
       "...                                                  ...   ...         ...   \n",
       "13501     Two woman standing staring at a painted mural.  TEST        True   \n",
       "13530  A large animal bounds across a snow-covered pl...  TEST        True   \n",
       "13586         The family sits at home waiting for dinner  TEST        True   \n",
       "13616  Theck kept it's wings intact as they dived int...  TEST        True   \n",
       "13627                       The master is wearing a hat.  TEST        True   \n",
       "\n",
       "        Idx  \n",
       "6869     67  \n",
       "6882     85  \n",
       "6956    186  \n",
       "7038    312  \n",
       "7053    330  \n",
       "...     ...  \n",
       "13501  9607  \n",
       "13530  9654  \n",
       "13586  9735  \n",
       "13616  9777  \n",
       "13627  9794  \n",
       "\n",
       "[173 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_paraphrase=gpt2_paraphrase[gpt2_paraphrase[\"Idx\"].isin(idsx)]\n",
    "gpt2_paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_paraphrase.to_csv(\"data/gpt3/2/paraphraseGPT2.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>SET</th>\n",
       "      <th>Parafraseo</th>\n",
       "      <th>Idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entailment</td>\n",
       "      <td>A girl reaches up to kiss a cat, which is sitt...</td>\n",
       "      <td>A girl is displaying affection towards a cat.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>3086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>entailment</td>\n",
       "      <td>Woman running in a park while listening to music.</td>\n",
       "      <td>A woman is jogging in a park.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>An old woman and a young man examine their bin...</td>\n",
       "      <td>A young woman and an elderly man are engaged i...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>6924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>Baby in running in over-sized flip-flops.</td>\n",
       "      <td>A young boy is playing with a basketball.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A woman in a white wedding dress is being dres...</td>\n",
       "      <td>A woman has entered into marriage.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>6791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A family with young children sits down outside.</td>\n",
       "      <td>A man and his wife sit outside with their chil...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>2335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6557</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Fireworks light up the night as a man stands o...</td>\n",
       "      <td>The man organizes a concert outside.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6597</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A young middle eastern mother in high heels, h...</td>\n",
       "      <td>A woman holds her sleeping son while walking d...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>1682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6642</th>\n",
       "      <td>neutral</td>\n",
       "      <td>People shopping for vegetables at an outdoor m...</td>\n",
       "      <td>People shop for veggies at a nice market.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A moving truck with a ramp still attached.</td>\n",
       "      <td>A moving truck is being disassembled.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>6931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gold_label                                          sentence1  \\\n",
       "3        entailment  A girl reaches up to kiss a cat, which is sitt...   \n",
       "44       entailment  Woman running in a park while listening to music.   \n",
       "154   contradiction  An old woman and a young man examine their bin...   \n",
       "242   contradiction          Baby in running in over-sized flip-flops.   \n",
       "319         neutral  A woman in a white wedding dress is being dres...   \n",
       "...             ...                                                ...   \n",
       "6517        neutral    A family with young children sits down outside.   \n",
       "6557        neutral  Fireworks light up the night as a man stands o...   \n",
       "6597  contradiction  A young middle eastern mother in high heels, h...   \n",
       "6642        neutral  People shopping for vegetables at an outdoor m...   \n",
       "6682  contradiction         A moving truck with a ramp still attached.   \n",
       "\n",
       "                                              sentence2   SET  Parafraseo  \\\n",
       "3         A girl is displaying affection towards a cat.  TEST       False   \n",
       "44                        A woman is jogging in a park.  TEST       False   \n",
       "154   A young woman and an elderly man are engaged i...  TEST       False   \n",
       "242           A young boy is playing with a basketball.  TEST       False   \n",
       "319                  A woman has entered into marriage.  TEST       False   \n",
       "...                                                 ...   ...         ...   \n",
       "6517  A man and his wife sit outside with their chil...  TEST       False   \n",
       "6557               The man organizes a concert outside.  TEST       False   \n",
       "6597  A woman holds her sleeping son while walking d...  TEST       False   \n",
       "6642          People shop for veggies at a nice market.  TEST       False   \n",
       "6682              A moving truck is being disassembled.  TEST       False   \n",
       "\n",
       "       Idx  \n",
       "3     3086  \n",
       "44    2022  \n",
       "154   6924  \n",
       "242   1166  \n",
       "319   6791  \n",
       "...    ...  \n",
       "6517  2335  \n",
       "6557  3100  \n",
       "6597  1682  \n",
       "6642  2252  \n",
       "6682  6931  \n",
       "\n",
       "[173 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p=tempHipotesisOriginales.copy()\n",
    "for index,strings in tempHipotesisOriginales.iterrows():\n",
    "    temp5=left_join_origin_gp3[left_join_origin_gp3[2]==strings[\"Idx\"]]\n",
    "    #print(left_join[2][0],index,\"2\",temp5)\n",
    "    for index2,strings2 in temp5.iterrows():\n",
    "        df_p.at[index,\"sentence2\"]=strings2[\"0_y\"]\n",
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=[85,186,9777,1138]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The duck kept it's wings intact when it dived under the water to catch some fish. 9777\n",
      "- A child wearing a red top is standing behind a pretty blond headed child 85\n",
      "- A man and woman have mug shots taken because they have been arrested. 186\n",
      "- There are hot dogs and hamburgers on the grill. 1138\n"
     ]
    }
   ],
   "source": [
    "for i,s in tempHipotesisOriginales.iterrows():\n",
    "    if(s[\"Idx\"] in indices):\n",
    "        print(\"-\",s[\"sentence2\"],s[\"Idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- A pretty blond child wearing a red top is standing behind some pretty red headed children 85\n",
      "- Two woman having mug shots taken of her while she was arrested. 186\n",
      "- Two dogs make hamburgers on the grill. 1138\n",
      "- Theck kept it's wings intact as they dived into the water to catch fish. 9777\n"
     ]
    }
   ],
   "source": [
    "for i,s in gpt2_paraphrase.iterrows():\n",
    "    if(s[\"Idx\"] in indices):\n",
    "        print(\"-\",s[\"sentence2\"],s[\"Idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The duck retains its wings when diving underwater to catch fish. 9777\n",
      "- A child wearing a red top stands behind a pretty blonde child. 85\n",
      "- A man and woman have their mugshots taken after being arrested. 186\n",
      "- Hot dogs and hamburgers are grilling. 1138\n"
     ]
    }
   ],
   "source": [
    "for i,s in df_p.iterrows():\n",
    "    if(s[\"Idx\"] in indices):\n",
    "        print(\"-\",s[\"sentence2\"],s[\"Idx\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_p=df_p.reset_index()\n",
    "df_p.to_csv(\"data/gpt3/1/paraphraseGPT3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>SET</th>\n",
       "      <th>Parafraseo</th>\n",
       "      <th>Idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Two Asian people cooking on a grill in a park.</td>\n",
       "      <td>Hot dogs and hamburgers are grilling.</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gold_label                                       sentence1  \\\n",
       "4754    neutral  Two Asian people cooking on a grill in a park.   \n",
       "\n",
       "                                  sentence2   SET  Parafraseo   Idx  \n",
       "4754  Hot dogs and hamburgers are grilling.  TEST       False  1138  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p[df_p[\"Idx\"]==1138]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizar la inferencia de GPT2 y GPT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main index</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hipotesis</th>\n",
       "      <th>R_Text</th>\n",
       "      <th>R_Hip</th>\n",
       "      <th>M_Align</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold_label</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, asian{asian,ADJ...</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, dogs{dog,NOUN},...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.003047054, 0.103406005, 0.89354694]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Main index                                               Text  \\\n",
       "17          17  [NULL{null,ADJ}, two{two,NUM}, asian{asian,ADJ...   \n",
       "\n",
       "                                            Hipotesis  \\\n",
       "17  [NULL{null,ADJ}, two{two,NUM}, dogs{dog,NOUN},...   \n",
       "\n",
       "                                               R_Text  \\\n",
       "17  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                                R_Hip  \\\n",
       "17  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                              M_Align  \\\n",
       "17  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                Prediction       Gold_label  Paraphrase   Idx  \n",
       "17  [0.003047054, 0.103406005, 0.89354694]  [0.0, 1.0, 0.0]           1  1138  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parGPT2=pd.read_pickle(\"data/gpt3_salida/pparaphraseGPT2.csv.pickle\")\n",
    "parGPT2[parGPT2[\"Idx\"]==1138]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=parGPT2[parGPT2[\"Idx\"]==1138]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "parGPT2[parGPT2[\"Idx\"]==1138].to_csv(\"check_gpt2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main index</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hipotesis</th>\n",
       "      <th>R_Text</th>\n",
       "      <th>R_Hip</th>\n",
       "      <th>M_Align</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold_label</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, girl{girl,NOUN}, ...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, girl{girl,NOUN}, ...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.77742785, 0.21776639, 0.0048058643]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>3086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[NULL{null,ADJ}, woman{woman,NOUN}, running{ru...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.45201063, 0.469083, 0.078906424]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[NULL{null,PROPN}, an{an,DET}, old{old,ADJ}, w...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, young{young,ADJ},...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.43721685, 0.47757116, 0.08521201]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>6924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[NULL{null,ADJ}, baby{baby,NOUN}, in{in,ADP}, ...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, young{young,ADJ},...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.044145536, 0.59316313, 0.3626913]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.45174822, 0.4727486, 0.07550324]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>6791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>168</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, family{family,NOU...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, man{man,NOUN}, an...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.03300249, 0.45249602, 0.51450145]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>[NULL{null,ADJ}, fireworks{firework,NOUN}, lig...</td>\n",
       "      <td>[NULL{null,PROPN}, the{the,DET}, man{man,NOUN}...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.033464465, 0.24933177, 0.71720374]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, young{young,ADJ},...</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.10142954, 0.6582279, 0.24034259]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>[NULL{null,ADJ}, people{people,NOUN}, shopping...</td>\n",
       "      <td>[NULL{null,ADJ}, people{people,NOUN}, shop{sho...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.5551234, 0.43663794, 0.008238697]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>[NULL{null,ADV}, a{a,DET}, moving{move,VERB}, ...</td>\n",
       "      <td>[NULL{null,ADV}, a{a,DET}, moving{move,VERB}, ...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.18191874, 0.52287734, 0.29520398]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>6931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Main index                                               Text  \\\n",
       "0             0  [NULL{null,PROPN}, a{a,DET}, girl{girl,NOUN}, ...   \n",
       "1             1  [NULL{null,ADJ}, woman{woman,NOUN}, running{ru...   \n",
       "2             2  [NULL{null,PROPN}, an{an,DET}, old{old,ADJ}, w...   \n",
       "3             3  [NULL{null,ADJ}, baby{baby,NOUN}, in{in,ADP}, ...   \n",
       "4             4  [NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...   \n",
       "..          ...                                                ...   \n",
       "168         168  [NULL{null,PROPN}, a{a,DET}, family{family,NOU...   \n",
       "169         169  [NULL{null,ADJ}, fireworks{firework,NOUN}, lig...   \n",
       "170         170  [NULL{null,PROPN}, a{a,DET}, young{young,ADJ},...   \n",
       "171         171  [NULL{null,ADJ}, people{people,NOUN}, shopping...   \n",
       "172         172  [NULL{null,ADV}, a{a,DET}, moving{move,VERB}, ...   \n",
       "\n",
       "                                             Hipotesis  \\\n",
       "0    [NULL{null,PROPN}, a{a,DET}, girl{girl,NOUN}, ...   \n",
       "1    [NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...   \n",
       "2    [NULL{null,PROPN}, a{a,DET}, young{young,ADJ},...   \n",
       "3    [NULL{null,PROPN}, a{a,DET}, young{young,ADJ},...   \n",
       "4    [NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...   \n",
       "..                                                 ...   \n",
       "168  [NULL{null,PROPN}, a{a,DET}, man{man,NOUN}, an...   \n",
       "169  [NULL{null,PROPN}, the{the,DET}, man{man,NOUN}...   \n",
       "170  [NULL{null,PROPN}, a{a,DET}, woman{woman,NOUN}...   \n",
       "171  [NULL{null,ADJ}, people{people,NOUN}, shop{sho...   \n",
       "172  [NULL{null,ADV}, a{a,DET}, moving{move,VERB}, ...   \n",
       "\n",
       "                                                R_Text  \\\n",
       "0    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "1    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "2    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "3    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "4    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "..                                                 ...   \n",
       "168  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "169  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "170  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "171  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "172  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                                 R_Hip  \\\n",
       "0    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "1    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "2    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "3    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "4    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "..                                                 ...   \n",
       "168  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "169  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "170  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "171  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "172  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                               M_Align  \\\n",
       "0    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "1    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "2    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "3    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "4    [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "..                                                 ...   \n",
       "168  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "169  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "170  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "171  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "172  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                 Prediction       Gold_label  Paraphrase   Idx  \n",
       "0    [0.77742785, 0.21776639, 0.0048058643]  [1.0, 0.0, 0.0]           0  3086  \n",
       "1       [0.45201063, 0.469083, 0.078906424]  [1.0, 0.0, 0.0]           0  2022  \n",
       "2      [0.43721685, 0.47757116, 0.08521201]  [0.0, 0.0, 1.0]           0  6924  \n",
       "3      [0.044145536, 0.59316313, 0.3626913]  [0.0, 0.0, 1.0]           0  1166  \n",
       "4       [0.45174822, 0.4727486, 0.07550324]  [0.0, 1.0, 0.0]           0  6791  \n",
       "..                                      ...              ...         ...   ...  \n",
       "168    [0.03300249, 0.45249602, 0.51450145]  [0.0, 1.0, 0.0]           0  2335  \n",
       "169   [0.033464465, 0.24933177, 0.71720374]  [0.0, 1.0, 0.0]           0  3100  \n",
       "170     [0.10142954, 0.6582279, 0.24034259]  [0.0, 0.0, 1.0]           0  1682  \n",
       "171    [0.5551234, 0.43663794, 0.008238697]  [0.0, 1.0, 0.0]           0  2252  \n",
       "172    [0.18191874, 0.52287734, 0.29520398]  [0.0, 0.0, 1.0]           0  6931  \n",
       "\n",
       "[173 rows x 10 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parGPT3=pd.read_pickle(\"data/gpt3_salida/pparaphraseGPT3.csv.pickle\")\n",
    "parGPT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main index</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hipotesis</th>\n",
       "      <th>R_Text</th>\n",
       "      <th>R_Hip</th>\n",
       "      <th>M_Align</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold_label</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, asian{asian,ADJ...</td>\n",
       "      <td>[NULL{null,PROPN}, hot{hot,ADJ}, dogs{dog,NOUN...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.008804821, 0.94698316, 0.044212036]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Main index                                               Text  \\\n",
       "127         127  [NULL{null,ADJ}, two{two,NUM}, asian{asian,ADJ...   \n",
       "\n",
       "                                             Hipotesis  \\\n",
       "127  [NULL{null,PROPN}, hot{hot,ADJ}, dogs{dog,NOUN...   \n",
       "\n",
       "                                                R_Text  \\\n",
       "127  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                                 R_Hip  \\\n",
       "127  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                               M_Align  \\\n",
       "127  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                 Prediction       Gold_label  Paraphrase   Idx  \n",
       "127  [0.008804821, 0.94698316, 0.044212036]  [0.0, 1.0, 0.0]           0  1138  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parGPT3[parGPT3[\"Idx\"]==1138]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ma_umbral'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8900\\531017176.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predicted_label\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gold_label\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ma_umbral\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"target_prediction\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ninja\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ninja\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4955\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4956\u001b[0m         \"\"\"\n\u001b[1;32m-> 4957\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4958\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4959\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ninja\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4267\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ninja\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4311\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4312\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ninja\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6659\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6660\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6661\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6662\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6663\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['ma_umbral'] not found in axis\""
     ]
    }
   ],
   "source": [
    "a=a.drop(\"predicted_label\",axis=1)\n",
    "a=a.drop(\"gold_label\",axis=1)\n",
    "a=a.drop(\"ma_umbral\",axis=1)\n",
    "a=a.drop(\"target_prediction\",axis=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main index</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hipotesis</th>\n",
       "      <th>R_Text</th>\n",
       "      <th>R_Hip</th>\n",
       "      <th>M_Align</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold_label</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, asian{asian,ADJ...</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, dogs{dog,NOUN},...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.003047054, 0.103406005, 0.89354694]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Main index                                               Text  \\\n",
       "17          17  [NULL{null,ADJ}, two{two,NUM}, asian{asian,ADJ...   \n",
       "\n",
       "                                            Hipotesis  \\\n",
       "17  [NULL{null,ADJ}, two{two,NUM}, dogs{dog,NOUN},...   \n",
       "\n",
       "                                               R_Text  \\\n",
       "17  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                                R_Hip  \\\n",
       "17  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                              M_Align  \\\n",
       "17  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                Prediction       Gold_label  Paraphrase   Idx  \n",
       "17  [0.003047054, 0.103406005, 0.89354694]  [0.0, 1.0, 0.0]           1  1138  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main index</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hipotesis</th>\n",
       "      <th>R_Text</th>\n",
       "      <th>R_Hip</th>\n",
       "      <th>M_Align</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold_label</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, asian{asian,ADJ...</td>\n",
       "      <td>[NULL{null,ADJ}, two{two,NUM}, dogs{dog,NOUN},...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[0.003047054, 0.103406005, 0.89354694]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Main index                                               Text  \\\n",
       "17          17  [NULL{null,ADJ}, two{two,NUM}, asian{asian,ADJ...   \n",
       "\n",
       "                                            Hipotesis  \\\n",
       "17  [NULL{null,ADJ}, two{two,NUM}, dogs{dog,NOUN},...   \n",
       "\n",
       "                                               R_Text  \\\n",
       "17  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                                R_Hip  \\\n",
       "17  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                              M_Align  \\\n",
       "17  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                Prediction       Gold_label  Paraphrase   Idx  \n",
       "17  [0.003047054, 0.103406005, 0.89354694]  [0.0, 1.0, 0.0]           1  1138  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=pd.concat([a,b])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(a.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main index</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hipotesis</th>\n",
       "      <th>R_Text</th>\n",
       "      <th>R_Hip</th>\n",
       "      <th>M_Align</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold_label</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Main index, Text, Hipotesis, R_Text, R_Hip, M_Align, Prediction, Gold_label, Paraphrase, Idx]\n",
       "Index: []"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8900\\2994678773.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Ninja\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ninja\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1523\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1525\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ninja\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1453\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1455\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1457\u001b[0m     \u001b[1;31m# -------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "ab=a.iloc[0][4]==b.iloc[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8900\\350414009.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Ninja\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ninja\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1523\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1525\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ninja\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1453\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1455\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1457\u001b[0m     \u001b[1;31m# -------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "ma=a.iloc[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb=b.iloc[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.60825551e-02  7.71607757e-02 -1.34218372e-02  1.83293805e-03\n",
      "  5.99548183e-02  6.82326034e-02  9.99246910e-03  9.68500823e-02\n",
      " -1.53730297e-03 -3.25198704e-03 -4.23940867e-02 -6.30294159e-02\n",
      " -1.11158825e-02 -4.82476614e-02  1.41313627e-01  8.24230909e-02\n",
      " -6.88238740e-02  2.86174845e-02  5.55794127e-03  9.75596160e-03\n",
      "  2.80262157e-02 -2.47151013e-02  9.10556316e-02  1.06428657e-03\n",
      "  5.78853674e-02 -8.25413465e-02 -5.62298112e-02  4.13889269e-04\n",
      "  7.54460990e-02 -1.37174716e-02 -3.19877267e-02 -1.88615248e-02\n",
      " -8.31917375e-02  8.98139700e-02  7.38496631e-02  8.73897597e-02\n",
      " -5.91270365e-02  5.45742512e-02 -8.12996775e-02 -7.29036406e-02\n",
      "  4.05611470e-02 -8.69167410e-03  2.87357401e-02 -5.32143284e-04\n",
      " -4.82476614e-02  3.87282073e-02 -3.79595570e-02  8.72715041e-02\n",
      " -1.34691387e-01 -3.76639217e-02  5.59933037e-02 -8.66802335e-02\n",
      " -4.55278158e-03  9.58449244e-02 -3.01547870e-02  2.03397013e-02\n",
      "  8.86905531e-04  3.39980461e-02  8.09449106e-02  2.62524039e-02\n",
      "  9.59040523e-02  2.36508134e-03  9.64361951e-02  5.09083793e-02\n",
      " -5.25048077e-02  3.55944745e-02 -4.90163118e-02  5.32143302e-02\n",
      "  1.77381109e-04  5.75306043e-02  2.86766123e-02  3.35841589e-02\n",
      "  1.12577878e-01  9.46032535e-03 -1.76198576e-02 -2.74940711e-02\n",
      "  2.82627214e-02  9.87421498e-02 -1.04004450e-01  4.43452783e-03\n",
      " -1.21801691e-02  1.21033035e-01  3.18103433e-02 -2.32369248e-02\n",
      " -5.49881421e-02 -4.37540077e-02 -1.12932637e-01  1.87491834e-01\n",
      "  1.79746188e-02 -2.71984376e-02 -1.76789835e-02 -6.66952953e-02\n",
      "  9.05234963e-02  3.18103433e-02 -1.10981442e-01 -3.14555839e-02\n",
      "  4.53504361e-02  7.16028363e-02  6.13738634e-02 -1.14706457e-02\n",
      "  1.44388214e-01  6.61040246e-02  1.54912835e-02  4.55278158e-02\n",
      "  2.62524039e-02 -5.26230643e-03  6.44484675e-03 -2.51881164e-02\n",
      " -1.86131909e-01 -9.90377814e-02 -1.42082274e-01  7.34357759e-02\n",
      "  4.99032177e-02 -6.23790212e-02  1.25349313e-01 -2.78488323e-02\n",
      " -3.21651101e-02 -5.13222665e-02 -3.92603502e-02  6.58675134e-02\n",
      "  3.66587639e-02 -7.33175222e-03  2.15813685e-02 -7.62738707e-03\n",
      "  5.51655255e-02 -2.16404945e-02  3.32885236e-02 -1.14706457e-02\n",
      "  9.27703232e-02 -2.33551804e-02  6.77595884e-02  3.79595570e-02\n",
      "  1.71468407e-02  5.14405221e-02 -4.13297974e-02 -1.30670751e-02\n",
      "  6.44484675e-03 -1.83293805e-03  1.61062047e-01  7.75155425e-02\n",
      "  2.69619282e-02  4.07385267e-02  4.45817858e-02  3.34658995e-02\n",
      " -7.11889490e-02 -7.12480843e-02  1.04063582e-02 -5.43968752e-03\n",
      " -4.74198833e-02 -1.05305254e-01 -9.10556316e-03  1.50182676e-02\n",
      " -3.25198704e-03 -1.21210422e-02 -4.60008346e-02  3.47075723e-02\n",
      "  2.28821617e-02 -4.29853536e-02  2.68436745e-02 -2.18770024e-03\n",
      "  3.16920914e-02 -2.53654979e-02 -1.06428666e-02  5.22091724e-02\n",
      " -9.36572254e-02  6.69317991e-02  6.14921190e-03 -1.81520004e-02\n",
      "  1.54912835e-02  6.26155287e-02 -2.80262157e-02 -1.20619154e-02\n",
      "  3.92603502e-02  2.32960526e-02  9.87421442e-03 -1.37174726e-01\n",
      "  2.66662929e-02  4.07385267e-02  1.17603675e-01 -1.83885079e-02\n",
      "  8.49655494e-02  5.59933037e-02  1.24698915e-01  8.27778503e-02\n",
      "  1.88023970e-02  9.19425413e-02 -6.04278296e-02 -8.86905566e-03\n",
      " -7.53278434e-02  5.32143330e-03 -3.39389183e-02  3.04504223e-02\n",
      "  7.09524425e-03  2.15813685e-02  3.12782004e-02 -3.72500322e-03\n",
      " -5.09675033e-02  3.60083655e-02 -7.37314150e-02  9.69683379e-03\n",
      "  2.53063720e-02  5.87131456e-02 -3.95559892e-02  8.49064216e-02\n",
      "  4.47591692e-02  5.01988530e-02 -4.30444814e-02 -9.16469097e-03\n",
      " -2.40055751e-02 -1.13642164e-01 -4.44635302e-02  8.51429254e-03\n",
      "  6.83508515e-02  4.18619402e-02 -2.99774092e-02  6.42119572e-02\n",
      " -3.94968577e-02 -9.93334223e-03 -6.30294159e-02 -4.46409136e-02\n",
      "  9.10556316e-03 -4.22758274e-02 -2.25865282e-02 -2.12857313e-03\n",
      " -6.91786315e-03  7.92302284e-03  1.42496154e-02 -6.66952953e-02\n",
      "  2.28230357e-02 -7.50913378e-03 -4.44044024e-02  2.46559735e-02\n",
      "  1.83885079e-02  4.43452783e-03 -7.08933175e-02  4.13297974e-02\n",
      "  5.87131456e-02 -1.77381109e-04  5.45151271e-02  4.59417067e-02\n",
      " -1.31853297e-02  3.83734442e-02 -2.05762070e-02  4.83067855e-02\n",
      "  2.63115298e-02  8.79810303e-02 -2.38873232e-02 -6.58675134e-02\n",
      "  2.04579532e-02 -7.05976784e-02 -8.69167410e-03 -3.31111401e-02\n",
      " -7.47365803e-02  3.66587639e-02 -1.17662800e-02  8.73306319e-02\n",
      "  1.09385019e-02 -1.78563632e-02 -6.80552199e-02  3.39389183e-02\n",
      "  5.27413189e-02  4.04428951e-02  4.94302027e-02 -9.78552401e-02\n",
      " -2.90905032e-02 -8.92818160e-03 -8.30734819e-02  7.33766556e-02\n",
      "  5.48107624e-02 -1.17662800e-02  4.29853536e-02  8.04718956e-02\n",
      " -3.22242342e-02  8.40786472e-02 -5.91270346e-03 -2.38281954e-02\n",
      " -4.96667102e-02  1.01166353e-01 -5.65254427e-02  2.25865282e-02\n",
      " -4.99032177e-02  1.30670756e-01 -7.22532347e-02 -3.66587639e-02\n",
      "  5.78853674e-02 -3.80778089e-02  6.34433031e-02 -8.14179257e-02\n",
      "  6.48623556e-02 -7.76337981e-02 -6.22607656e-02 -1.40131079e-02\n",
      " -8.01171362e-02 -2.65480392e-02 -8.70350003e-02 -2.82035954e-02\n",
      " -2.09900979e-02  8.75080097e-03  1.30670751e-02  1.58460457e-02]\n",
      "[ 3.63372266e-02 -6.42727837e-02 -6.99139014e-02 -2.87757237e-02\n",
      "  4.88159619e-02 -4.73869257e-02 -4.47651558e-02 -1.49071524e-02\n",
      "  7.46154636e-02  4.76607293e-01  5.73901646e-02  7.59019703e-03\n",
      "  4.17495519e-02 -5.49109243e-02 -1.45198870e-02 -2.27951594e-02\n",
      " -2.96365190e-03  2.15874195e-01 -1.16333142e-02 -2.13248674e-02\n",
      " -8.60964954e-02  1.29025672e-02  9.07155481e-05  1.23688355e-02\n",
      "  2.36803349e-02 -4.57215942e-02 -7.02777281e-02 -2.44286098e-02\n",
      "  6.22830093e-02  3.26221138e-02 -3.11480695e-03  9.65273231e-02\n",
      "  4.78463918e-02 -1.19496894e-03  4.65129986e-02 -1.87274739e-02\n",
      "  7.83080794e-03 -6.12628087e-02 -8.96784570e-03 -5.90142384e-02\n",
      " -1.42151406e-02  3.10730562e-02 -2.35190541e-02 -1.66700035e-02\n",
      " -5.28611382e-03 -3.10224225e-03 -1.23168873e-02  4.02305014e-02\n",
      "  5.80671756e-03  8.32740625e-04 -4.33492474e-02  6.85486346e-02\n",
      " -2.07303744e-02  5.12670726e-03 -7.85031095e-02  1.61527749e-02\n",
      " -1.65801719e-02  7.09078535e-02  1.77100841e-02  6.14390932e-02\n",
      "  1.05206549e-01  6.97845081e-03  3.11818272e-02  1.04287617e-01\n",
      " -2.88863704e-02  2.60114223e-02  4.08868827e-02  5.41964024e-02\n",
      "  5.90611249e-03  8.63740593e-02  8.70435610e-02 -3.48706841e-02\n",
      "  5.31274416e-02  4.78445180e-02 -6.42596558e-03 -1.10570118e-02\n",
      " -6.00363128e-03 -3.37473378e-02  3.16487961e-02 -2.07960121e-02\n",
      " -2.83575151e-02  1.57671981e-02 -5.66531420e-02 -3.01822536e-02\n",
      " -3.90658937e-02 -3.38129769e-03 -9.61466208e-02 -1.51972729e-03\n",
      "  1.29125053e-02  2.15499103e-03 -2.55257003e-02  1.79460067e-02\n",
      "  1.71712902e-03 -7.09659904e-02  4.89191059e-03  3.47937979e-02\n",
      "  6.35638908e-02 -7.31357955e-04 -9.49820224e-03 -4.49058041e-02\n",
      " -3.39423753e-02  6.40196055e-02  1.86087638e-02 -6.03401288e-03\n",
      " -2.16211751e-02 -2.05822185e-01  7.96864741e-03  2.66565513e-02\n",
      "  4.07124721e-02  2.20918935e-02  3.65922786e-02 -7.33627155e-02\n",
      "  3.46887745e-02  6.51204512e-02  3.01972553e-02  4.42963094e-03\n",
      " -5.24916947e-02  1.60575062e-01 -9.46538243e-03  8.70641917e-02\n",
      "  2.73054317e-02 -8.48756358e-02  4.87747043e-02 -1.38318148e-02\n",
      " -4.52114921e-03  4.01686132e-03 -5.19515853e-03 -1.47499973e-02\n",
      " -9.92672518e-03  4.91704084e-02 -3.95628698e-02  1.15082271e-01\n",
      "  6.84548691e-02 -5.13214571e-03  4.64454889e-02  4.84071299e-02\n",
      "  8.24826509e-02  3.19938622e-02  5.36656715e-02  4.13576001e-03\n",
      " -2.59195298e-01 -3.53320278e-02  6.78022346e-03  1.35163758e-02\n",
      "  2.34402884e-02  2.42054388e-02 -1.15823045e-01 -2.99159512e-02\n",
      "  8.16893764e-03 -4.34730239e-02 -2.99290791e-02  9.45581775e-03\n",
      " -3.52270057e-04  5.30017950e-02 -2.94414815e-02 -4.75950912e-02\n",
      " -5.72420098e-02  7.74960369e-02 -4.44200858e-02 -3.98310497e-02\n",
      " -4.49358113e-02  1.39212683e-02 -9.99029912e-03 -6.77309707e-02\n",
      " -4.92472947e-02 -4.13463488e-02 -2.14861482e-02 -1.95620153e-02\n",
      "  3.15794088e-02  1.14988498e-02 -3.03754173e-02  2.76580006e-02\n",
      "  1.22683151e-02  6.11165315e-02 -8.31071585e-02 -4.69855927e-02\n",
      " -2.74273288e-02 -5.34781348e-03  3.87058221e-02 -4.26516086e-02\n",
      "  2.90926616e-03  2.45767646e-02 -3.33666354e-02 -2.28776764e-02\n",
      " -6.40833750e-02  2.48955768e-02 -1.55762851e-03 -4.08456251e-02\n",
      " -3.89027372e-02  4.30379361e-02  1.41243712e-04  3.34360227e-02\n",
      " -1.40407300e-02  1.77460928e-02 -3.43999676e-02  1.50125485e-03\n",
      " -7.26725832e-02 -1.31199218e-03 -7.76479468e-02 -3.08967698e-02\n",
      " -6.51279539e-02 -4.38087136e-02  2.15236563e-02  2.79805660e-02\n",
      "  7.65902326e-02 -3.30722034e-02 -2.74310820e-02  1.51357614e-03\n",
      "  1.58859091e-03  5.18896952e-02 -2.08466463e-02  5.69531992e-02\n",
      " -3.40230167e-02 -9.26865637e-02 -7.76273161e-02  1.68689806e-03\n",
      " -5.99650554e-02 -2.52500214e-02  2.15067770e-02  5.45996102e-03\n",
      " -4.86452989e-02 -1.10146287e-03  7.82424398e-03  3.33160013e-02\n",
      "  2.40516588e-02 -1.39610274e-02  1.17128296e-02  2.76336204e-02\n",
      " -9.44737904e-03  5.42526692e-02 -2.12048441e-02 -1.10163167e-02\n",
      "  2.05015782e-02  7.51705766e-02  2.36653332e-02 -8.22257325e-02\n",
      "  3.75412144e-02  4.13238443e-02  1.39272697e-02  9.25346538e-02\n",
      "  2.51618796e-03  1.53052937e-02 -4.17608060e-02  9.27578285e-02\n",
      "  2.40479093e-02 -3.62528339e-02 -5.04175238e-02 -4.11213003e-03\n",
      " -3.43099497e-02  4.98867966e-02 -2.74742153e-02 -1.36956610e-02\n",
      " -3.33741400e-03 -2.73466911e-02  1.59721766e-02  6.37945607e-02\n",
      "  1.90837961e-02  3.97279039e-02 -3.85839269e-02  2.25419831e-03\n",
      "  1.16983898e-01 -1.32256933e-02 -1.18092239e-01  1.81262307e-02\n",
      " -3.18569615e-02  2.89201271e-02  5.72682656e-02  4.64004800e-02\n",
      " -4.29722993e-03 -1.07290089e-01 -7.39515806e-03 -4.96298708e-02\n",
      " -3.07636186e-02 -6.99007735e-02  6.02032233e-04  1.45684602e-02\n",
      "  4.33323681e-02  3.41692977e-02  5.40857576e-02  3.44993621e-02\n",
      "  4.23590504e-02  9.65085700e-02 -1.23829007e-01 -1.72678716e-02\n",
      "  1.22489985e-02  3.87883373e-02  3.85801755e-02 -2.91545484e-02\n",
      " -1.02522899e-03  6.09439984e-02 -5.94324470e-02 -1.82096846e-02\n",
      "  2.26019956e-02  4.59503895e-03 -6.61256537e-02  1.99952256e-03\n",
      "  1.90894231e-02 -9.60678607e-02  5.37969470e-02 -7.26125687e-02]\n",
      "[-7.59130418e-02  3.58315632e-02  1.30625200e-02 -8.22621733e-02\n",
      " -2.61876006e-02  2.94893757e-02 -2.31888928e-02 -1.14116315e-02\n",
      "  5.01953326e-02  3.13133448e-01 -3.94364111e-02  7.27377683e-02\n",
      " -7.54584298e-02  4.18748558e-02 -3.01358271e-02  1.28482869e-02\n",
      "  6.74021021e-02  1.47043720e-01  9.40582063e-03 -3.30247097e-02\n",
      " -7.49009624e-02 -2.63168896e-03  1.37510961e-02 -9.57973748e-02\n",
      "  3.59483436e-02 -3.11048124e-02 -2.41300724e-02 -6.19023889e-02\n",
      "  2.23936867e-02 -4.91776913e-02 -4.32261564e-02 -3.56369332e-04\n",
      " -1.77781526e-02  4.35834378e-02  4.85743359e-02  6.90620244e-02\n",
      "  8.90784338e-02 -1.24082819e-01  2.77682836e-03  9.25706699e-02\n",
      "  1.33842174e-02  2.36490555e-02 -1.84579697e-02 -3.44774909e-02\n",
      " -2.11202446e-02 -3.15135382e-02 -5.91553077e-02  2.43886542e-02\n",
      "  3.66323330e-02  1.94394658e-03 -3.41104716e-02  4.97810468e-02\n",
      "  6.35762140e-03  3.49237509e-02 -2.26355847e-02  1.15922220e-01\n",
      " -7.76063232e-03  1.49490498e-02 -7.68792406e-02  1.32567346e-01\n",
      "  5.23696393e-02 -1.93115640e-02  1.83689948e-02  5.31565063e-02\n",
      "  1.30978320e-02 -5.70185408e-02  8.75366777e-02  1.47363462e-03\n",
      " -2.16735508e-02  1.92059092e-02 -1.08516505e-02  2.14260910e-02\n",
      "  5.72882406e-02 -5.84685383e-03  7.54542649e-02 -2.72719730e-02\n",
      "  3.22378444e-04 -4.32108641e-02  8.38581547e-02 -4.28063050e-02\n",
      " -8.39415658e-03  2.29678471e-02 -6.73548356e-02 -5.07208370e-02\n",
      " -9.43946466e-03 -7.86726326e-02  9.58877355e-02  4.74635512e-02\n",
      "  1.09623127e-01 -2.27912888e-02  2.81644948e-02  2.50559598e-02\n",
      "  6.31285608e-02 -1.51700955e-02 -2.93461829e-02 -1.40231624e-02\n",
      " -2.40869764e-02 -7.88283348e-02  2.14316510e-02 -6.70225769e-02\n",
      "  1.55371139e-02  9.91144404e-02  3.33041437e-02  5.65889617e-03\n",
      "  9.49465558e-02 -1.10537887e-01  4.76456657e-02 -2.99064424e-02\n",
      "  3.78140225e-03 -2.99551012e-03  6.41003326e-02  1.04593309e-02\n",
      "  6.54961094e-02 -9.39164013e-02  2.09353436e-02 -1.61849573e-04\n",
      " -1.43540353e-02 -1.27308127e-02 -1.36795007e-02 -6.25001825e-03\n",
      "  4.78833914e-03  2.91487724e-02  8.14919919e-02 -1.34477511e-01\n",
      " -7.51609262e-03 -4.16510329e-02  5.04080355e-02 -8.51454958e-03\n",
      " -5.78943789e-02 -6.61439542e-03 -1.39230667e-02  6.06053090e-03\n",
      " -3.18805575e-02  4.28633019e-02  2.50545684e-02 -4.37113419e-02\n",
      " -1.67243630e-02  2.85662673e-02  1.02131225e-01  2.49503017e-03\n",
      " -2.80546665e-01 -1.12049066e-01  7.24221915e-02  9.39553306e-02\n",
      "  8.92452598e-02 -2.90222596e-02 -2.01165043e-02  7.25695565e-02\n",
      "  1.88096948e-02  1.10865980e-02  2.11577788e-02 -1.68230683e-02\n",
      " -4.30593267e-02  6.31202199e-03 -5.41449524e-02  2.03444995e-02\n",
      " -3.66059169e-02  5.01286015e-02 -3.62333395e-02 -8.90645310e-02\n",
      "  4.78833951e-02 -1.83676053e-02 -2.68688090e-02 -7.35315904e-02\n",
      " -3.26674228e-04  3.38129662e-02 -8.02213326e-03 -6.26614466e-02\n",
      " -3.25186662e-02 -4.41006012e-02  1.06282428e-01  5.30383326e-02\n",
      "  1.95757076e-02 -1.18063157e-02  2.41676085e-02  8.84931535e-02\n",
      " -4.71465811e-02  7.90229589e-02  2.68729776e-02  1.07728258e-01\n",
      "  2.67714933e-02 -4.36793640e-02 -5.24641760e-02 -1.54217258e-02\n",
      " -8.04270878e-02 -8.09984654e-03  5.29076532e-02  6.59034448e-03\n",
      " -2.03806441e-02 -6.71198890e-02 -2.89847255e-02  8.66010599e-03\n",
      " -4.13062572e-02 -1.00159891e-01 -5.63442819e-02  8.85084495e-02\n",
      "  1.11745996e-02 -8.89672115e-02  1.19155876e-01 -3.40048149e-02\n",
      " -1.00727096e-01 -5.72256802e-04 -2.05127168e-02  2.10604630e-03\n",
      "  5.59411198e-02  4.03595157e-02  7.54653886e-02 -2.32125260e-02\n",
      "  8.00962150e-02  2.50643007e-02 -1.42761832e-02  2.24993434e-02\n",
      " -2.13816036e-02  4.83004600e-02 -6.36804774e-02 -6.33301437e-02\n",
      "  2.98591759e-02  6.62954897e-02 -1.00329500e-02  4.01495919e-02\n",
      "  5.14103882e-02  3.25311795e-02  1.25724664e-02 -9.33728218e-02\n",
      " -1.07943736e-01 -5.62886707e-03 -4.35778797e-02  4.91790809e-02\n",
      "  2.86357794e-02  1.98885072e-02 -7.11445734e-02  1.37716718e-02\n",
      " -4.83060218e-02 -4.98644598e-02  9.76421982e-02  4.41867970e-02\n",
      "  1.18862540e-02 -3.71286422e-02  8.01949203e-02 -7.33828321e-02\n",
      " -9.43279117e-02 -2.01929640e-02 -8.16602111e-02 -1.47196641e-02\n",
      " -1.03638219e-02  3.46331932e-02 -6.13045916e-02  1.21499794e-02\n",
      " -6.42337874e-02  4.41158935e-03 -1.50046591e-02  3.17192897e-02\n",
      "  9.86167416e-03  6.22290894e-02 -3.93293612e-03  2.88498737e-02\n",
      " -8.60129949e-03  4.11102362e-02 -6.41837390e-03 -1.97008271e-02\n",
      "  4.63611037e-02 -8.30671117e-02 -6.99086711e-02 -5.83587103e-02\n",
      " -1.87207218e-02  8.18339884e-02  4.57633063e-02 -1.96327064e-02\n",
      " -4.57341112e-02  4.97337803e-02 -4.26436476e-02  1.13948099e-01\n",
      " -2.02110391e-02  1.54703837e-02  1.88694745e-02  5.72354160e-02\n",
      " -2.18431596e-02  4.47289832e-02 -2.42885575e-02  2.76570637e-02\n",
      "  5.04302792e-03  5.42255826e-02 -1.58568658e-02 -6.58978820e-02\n",
      "  4.78945151e-02  8.91020671e-02  4.95752916e-02 -4.75288890e-02\n",
      "  3.62736546e-02  2.76598446e-02 -1.51200471e-02 -8.37330297e-02\n",
      " -4.91596200e-02 -8.94913357e-03 -5.42714596e-02  1.16382383e-01\n",
      "  4.42298949e-02 -1.44054741e-02  3.44357826e-03 -2.77224053e-02]\n",
      "[-4.65418510e-02  2.99322680e-02 -8.95332247e-02  9.02531575e-03\n",
      "  1.78401582e-02 -1.96230728e-02  1.68153383e-02  1.62403751e-02\n",
      "  1.03379134e-02  4.72047418e-01 -8.22296441e-02  4.37270338e-03\n",
      "  2.57857721e-02  4.61366437e-02 -2.17100908e-03 -4.97795828e-02\n",
      " -6.30117804e-02  2.55634993e-01 -6.85588047e-02  1.59461070e-02\n",
      "  5.01041412e-02 -1.84851477e-03  1.81684550e-02 -4.98799011e-02\n",
      " -6.97724568e-03  5.87531626e-02  7.53273442e-03 -1.12480566e-01\n",
      "  6.45480305e-02 -1.45440102e-01 -6.39598863e-03  1.68377627e-02\n",
      " -3.56956609e-02 -9.25486791e-04  7.46408552e-02 -6.92118481e-02\n",
      "  3.04810703e-02  2.74400450e-02  1.54785449e-02  1.59248635e-02\n",
      " -5.29071577e-02  1.88350808e-02  1.14459405e-03 -5.20436317e-02\n",
      " -2.43891813e-02 -2.00754888e-02  1.47533007e-02  2.37538330e-02\n",
      " -3.40846628e-02  2.33053491e-02 -2.03725100e-02  1.00621358e-02\n",
      "  2.24732962e-02 -4.26648408e-02  6.71877787e-02 -2.14130688e-03\n",
      "  8.68777372e-03  8.48103873e-03  2.38128435e-02  9.50900745e-03\n",
      "  2.40449514e-02  7.79474247e-03 -5.41680194e-02  1.16143174e-01\n",
      "  9.51392502e-02  6.65839016e-03  6.13398035e-04  8.79950076e-02\n",
      "  7.46506825e-02 -3.02666631e-02  7.69835785e-02 -2.37971079e-02\n",
      "  3.97438034e-02 -3.70588116e-02  2.79042609e-02  2.97788400e-02\n",
      "  3.23792510e-02 -6.38162941e-02  1.26098311e-02  1.38236838e-03\n",
      " -5.33320345e-02  6.12453907e-04 -4.26746756e-02  1.33846430e-02\n",
      " -9.02216807e-02 -2.14170031e-02 -1.77121051e-02  4.37526091e-04\n",
      "  8.01957399e-02 -3.62051204e-02 -4.58750315e-02  1.12364516e-02\n",
      " -5.09361923e-02  1.45251267e-02 -2.20130123e-02  9.19054523e-02\n",
      "  1.20687010e-02 -6.61963969e-02 -4.92524169e-03  2.74793822e-02\n",
      " -2.67181429e-03  1.13466056e-02 -1.10672871e-02 -4.03673537e-02\n",
      "  6.40916824e-02 -2.09645852e-01  6.41487241e-02 -1.35886241e-02\n",
      "  3.22041847e-02  4.58278209e-02 -2.90530064e-04 -3.93621996e-02\n",
      " -5.62550360e-03 -5.46283089e-02  3.12187038e-02 -3.99523079e-02\n",
      "  1.19074052e-02 -1.31446663e-02 -4.61976230e-02  4.41125743e-02\n",
      "  1.46317398e-02 -7.25951418e-02 -1.26442537e-02  2.62283534e-02\n",
      "  4.09456566e-02  2.00243481e-02  2.55064536e-02  9.59378667e-04\n",
      "  2.60375515e-02  1.45316171e-02 -8.71413108e-03  2.13835631e-02\n",
      " -2.17395946e-02  9.86739993e-03 -1.38278147e-02  2.82858666e-02\n",
      "  3.38053443e-02 -6.56613708e-02 -3.43738161e-02 -3.99621464e-02\n",
      " -3.75407308e-01  8.41789693e-02  3.04712337e-02  6.29724422e-03\n",
      " -3.27549526e-03 -8.75976607e-02 -1.69439800e-02 -7.34488340e-03\n",
      "  3.55225615e-02 -2.22529899e-02  5.89813367e-02  2.03666110e-02\n",
      " -2.66217603e-03 -1.46468857e-03 -3.85655537e-02 -2.83173379e-02\n",
      " -7.54158571e-03 -4.77279723e-02 -1.77561659e-02  1.73515491e-02\n",
      " -2.15428937e-02  3.78338210e-02 -2.86064912e-02 -1.44002195e-02\n",
      "  3.48714739e-02 -6.60449341e-02  5.04936166e-02 -4.55347337e-02\n",
      "  7.02819228e-02  5.32041788e-02  3.15629342e-03 -3.77905462e-03\n",
      "  6.31789789e-02 -2.46330928e-02 -6.49709394e-03  2.49596196e-03\n",
      "  2.11317837e-02 -1.79333948e-02  1.67146251e-02  6.45165592e-02\n",
      "  7.93617219e-03  4.75902818e-02  1.32664246e-03 -4.62566316e-02\n",
      "  3.57743399e-03  1.50723532e-02 -7.15073757e-03 -2.91906968e-02\n",
      " -1.55479806e-02  5.26966825e-02  3.66595038e-03  5.41365519e-02\n",
      "  5.39516471e-03 -4.50449437e-02  6.26675487e-02  3.77866104e-02\n",
      " -1.88494415e-03  3.87779921e-02  5.34244850e-02  8.06579888e-02\n",
      " -1.20289670e-02  2.71626911e-03  4.76807654e-02 -6.55374452e-02\n",
      "  5.01887202e-02 -3.53888050e-03 -1.88602600e-02  1.54313361e-02\n",
      "  2.33859979e-02  6.18886091e-02  5.08653838e-03 -3.17537375e-02\n",
      " -2.24634632e-03 -6.05352893e-02 -2.82170195e-02  8.33311826e-02\n",
      "  1.28326947e-02 -1.18299043e-02 -6.83581606e-02 -1.70441028e-02\n",
      " -1.18485903e-02 -1.25032179e-02 -2.46134233e-02  3.97634722e-04\n",
      "  1.59130618e-02  5.52361161e-02 -5.41404858e-02  2.93165874e-02\n",
      " -7.57541880e-02 -1.73226334e-02 -3.75013910e-02 -2.91218515e-02\n",
      "  3.39174666e-03  3.00325844e-02  8.79812334e-03 -2.67201103e-02\n",
      "  3.41377743e-02 -3.15826051e-02 -3.19681428e-02  3.84986773e-02\n",
      "  3.83668840e-02  1.30561495e-03 -3.88507731e-02  6.45991741e-03\n",
      "  1.08871080e-01 -5.98487966e-02 -6.00199327e-02 -7.09526688e-02\n",
      " -3.86048965e-02  6.62200078e-02  1.14136804e-02  1.76247694e-02\n",
      " -9.19979066e-02  1.62879769e-02 -1.05599901e-02  1.04258396e-01\n",
      "  2.56362781e-02  1.17101120e-02  2.26739347e-02 -3.98500264e-03\n",
      " -9.75685287e-03  5.73939458e-02  7.30180517e-02  3.97733087e-03\n",
      "  5.21734580e-02 -4.19409759e-02 -3.52629125e-02  1.65688694e-02\n",
      "  9.79953706e-02  6.68553486e-02  5.85721955e-02 -1.08876973e-02\n",
      "  6.33028969e-02 -1.33974282e-02 -2.53333561e-02  1.43646169e-02\n",
      "  1.19288461e-02  1.06020859e-02  5.17859496e-02  7.25813722e-03\n",
      "  8.53985269e-03  5.14889285e-02 -1.89129766e-02 -5.36054512e-03\n",
      " -3.72299440e-02 -1.28773469e-02  4.59497795e-02  1.32434107e-02\n",
      "  4.55189981e-02 -3.52511145e-02 -7.30298534e-02  8.91634151e-02\n",
      " -2.04984006e-02 -2.51484551e-02 -2.69030454e-03 -1.87949534e-03\n",
      " -3.90533768e-02 -2.66827364e-02  4.41027358e-02  7.94010609e-02]\n",
      "[ 4.57213214e-03  2.88017490e-03  6.80361614e-02 -5.42645401e-04\n",
      "  2.45844107e-02  4.43843612e-03 -2.82754768e-02  3.85231674e-02\n",
      " -1.34746388e-01  2.98638344e-02  1.29553014e-02  1.32304654e-02\n",
      "  1.23873137e-01 -1.24952577e-01  3.30400057e-02  1.33932754e-02\n",
      "  2.75685843e-02 -8.69743079e-02  8.83482769e-02  9.74663906e-03\n",
      " -5.19252084e-02  6.76136911e-02 -1.46117946e-02  4.23923209e-02\n",
      " -7.90768415e-02 -8.90248641e-02  1.06771857e-01  4.36983630e-02\n",
      "  2.97535434e-02  4.54507731e-02  7.99300596e-02 -5.17500304e-02\n",
      " -6.10772185e-02 -5.43328263e-02 -1.47164995e-02  4.07613115e-03\n",
      "  7.91177303e-02  2.67509744e-02 -7.96307921e-02 -1.38958748e-02\n",
      "  7.11139143e-02 -5.99391945e-02 -5.21170683e-02 -1.36382934e-02\n",
      " -8.67844820e-02  8.26985836e-02  1.46695515e-02  8.41063857e-02\n",
      "  5.81773333e-02  1.37507617e-02 -1.19976848e-02  4.37315889e-02\n",
      " -3.83716635e-02  1.08813882e-01 -4.77299392e-02 -4.11950201e-02\n",
      "  7.41303861e-02  7.91763514e-03 -3.12454980e-02 -3.33448648e-02\n",
      " -2.79618166e-02 -2.31937971e-02  1.12840198e-02  4.12954800e-02\n",
      "  4.05713990e-02 -8.28475878e-02  3.46570574e-02 -8.43113102e-03\n",
      " -2.20991690e-02 -1.28800618e-02 -8.12952965e-02  1.55559313e-02\n",
      "  6.98058903e-02  5.38519993e-02 -8.22883397e-02 -1.36999786e-01\n",
      "  7.64759444e-03 -6.64918125e-02  7.50720352e-02 -8.88553783e-02\n",
      " -3.21629941e-02  2.01439429e-02  8.54361355e-02  3.28102149e-02\n",
      "  1.03110224e-01 -4.72578183e-02 -2.64566559e-02 -3.14253271e-02\n",
      " -3.15969884e-02 -6.59671277e-02 -3.98261286e-02  3.91800925e-02\n",
      "  2.66326461e-02 -4.39977683e-02 -5.27783595e-02  4.94731627e-02\n",
      " -6.95594400e-02  6.80870563e-02 -3.05077527e-02 -9.16936621e-02\n",
      "  1.41281215e-02 -4.26275320e-02  1.66421253e-02  5.79117164e-02\n",
      "  2.37314813e-02  2.66966950e-02  5.06890081e-02  3.02199293e-02\n",
      " -6.68909401e-02  3.22767673e-03 -2.66573634e-02  7.26623237e-02\n",
      "  5.49046276e-03  8.89749229e-02 -1.38702393e-01 -1.22696124e-01\n",
      " -3.35704652e-03 -6.87844260e-03 -4.53903638e-02 -4.55797873e-02\n",
      " -4.92221005e-02 -3.55875790e-02  4.09234948e-02 -2.53322273e-02\n",
      " -6.30538911e-02 -3.53617892e-02 -1.38354069e-02  2.90025081e-02\n",
      " -8.95633027e-02  6.05391823e-02  6.53932914e-02  2.20356248e-02\n",
      " -1.16562675e-04  7.45186284e-02 -3.33512984e-02  3.90653238e-02\n",
      "  5.19997217e-02  2.95821261e-02 -8.56398121e-02 -6.12304285e-02\n",
      "  1.35967508e-03  1.84339628e-01  7.92614371e-02 -1.19118802e-01\n",
      "  8.60617205e-04 -1.06379669e-02 -1.51980678e-02 -6.97761700e-02\n",
      " -9.52041373e-02 -2.41743941e-02  3.91663983e-02  1.49927251e-02\n",
      " -1.52818151e-02  3.20081078e-02  2.93412134e-02  3.57416682e-02\n",
      "  5.30141741e-02 -1.06647499e-02 -8.30101445e-02 -7.78606459e-02\n",
      " -6.70629367e-02 -5.24608567e-02 -5.09753227e-02 -3.45806256e-02\n",
      "  4.06597257e-02  6.00290596e-02 -5.32719009e-02  1.79656278e-02\n",
      "  2.24926118e-02  1.74563247e-05  4.91734296e-02  4.20678481e-02\n",
      "  2.81393733e-02 -5.22531867e-02  1.08053684e-02  1.87728014e-02\n",
      "  2.66991593e-02 -8.50726590e-02 -4.50065685e-03  2.07563061e-02\n",
      " -4.72464710e-02  2.43334379e-02 -5.05435327e-03 -3.83899286e-02\n",
      " -4.21681441e-02 -4.81184870e-02 -2.78116893e-02 -5.53868487e-02\n",
      "  3.84636149e-02 -1.29598513e-01  4.03444357e-02 -5.90433292e-02\n",
      " -4.33829650e-02 -7.54986927e-02 -3.26975323e-02 -4.93198410e-02\n",
      " -1.70227455e-03  1.45554975e-01 -3.43416147e-02  7.66630247e-02\n",
      "  6.50589839e-02 -7.78499804e-03  1.66902207e-02 -5.54522164e-02\n",
      " -1.75491453e-03 -1.62011525e-03  3.59089300e-02  5.83181046e-02\n",
      "  1.13638761e-02  3.62886116e-02 -4.11986895e-02  5.16741630e-03\n",
      " -4.06964310e-02  4.86614592e-02  6.50718436e-02  9.26265642e-02\n",
      " -1.44983262e-01 -3.51705477e-02  1.05595514e-02 -2.13910174e-03\n",
      " -1.65997148e-02 -1.36701083e-02 -5.05627841e-02  5.70352487e-02\n",
      "  2.13193577e-02  8.39425772e-02 -5.00362627e-02  6.57947436e-02\n",
      " -6.73703626e-02 -7.91676119e-02  1.26541197e-01 -9.21554267e-02\n",
      " -5.81130534e-02 -7.06911692e-03  6.83205435e-03  6.85034618e-02\n",
      " -6.28504204e-03 -2.36530174e-02  6.09366409e-02  9.39363763e-02\n",
      " -6.05163276e-02 -5.43660335e-02  1.76306814e-02 -2.24009324e-02\n",
      " -3.51660959e-02  1.18769100e-02 -2.63907318e-03 -4.57454734e-02\n",
      " -6.31572157e-02  2.76137167e-03 -1.48522230e-02 -6.49226829e-03\n",
      " -7.42960572e-02 -3.12275346e-02  3.99510637e-02  9.37438942e-03\n",
      " -3.30914520e-02 -1.96003225e-02  5.83672822e-02 -4.98609878e-02\n",
      "  1.80555340e-02  8.26802552e-02 -4.32652831e-02 -9.19122323e-02\n",
      " -1.33019447e-01 -3.61300558e-02  7.68314376e-02 -9.49024484e-02\n",
      " -4.39596828e-03  1.90932639e-02 -1.91559881e-01 -9.83705297e-02\n",
      " -7.44423568e-02  9.93413292e-03  2.82100216e-02  2.25991905e-02\n",
      " -3.17654051e-02  2.37310529e-02  5.06458059e-02  5.04144840e-02\n",
      " -3.39763351e-02  1.53415967e-02 -4.81285378e-02 -2.54123146e-03\n",
      " -1.06350280e-01  1.16998022e-02 -2.38102395e-02 -6.05171509e-02\n",
      " -4.37398814e-02  9.40680727e-02 -2.68557779e-02 -3.01374048e-02\n",
      "  1.72990318e-02 -1.02494389e-01  6.29047900e-02  5.11199459e-02\n",
      " -1.07148886e-01  6.14290684e-02 -1.86716281e-02  1.89374294e-02]\n",
      "[-0.01345044  0.02927108 -0.06340598  0.02224748 -0.0332227  -0.0227285\n",
      " -0.04988962 -0.04931279 -0.04872254  0.41670188 -0.1121726   0.03685236\n",
      " -0.04199214 -0.02708256 -0.0581014   0.05258983  0.01029816  0.25537938\n",
      " -0.06508284  0.02538271 -0.0022397   0.05625015  0.03030594  0.07346901\n",
      "  0.06419554 -0.01804137  0.00485635  0.0072277  -0.00093848  0.06973011\n",
      "  0.00784421 -0.00980966 -0.02789702 -0.02889547 -0.05732142  0.02025251\n",
      " -0.08271563  0.04557772 -0.07825808  0.01284064 -0.06316644  0.03158418\n",
      " -0.11729897  0.02082168  0.09850676  0.01793711  0.00769185 -0.01447878\n",
      " -0.01181518  0.04618714  0.03950082  0.06814141 -0.05159905  0.02585606\n",
      " -0.05098197 -0.0082135  -0.0670414  -0.03716473 -0.02663795 -0.04731015\n",
      "  0.07322753  0.02950488  0.02159974  0.07517459  0.07140887 -0.00572448\n",
      " -0.01501461  0.02593463  0.03842955 -0.00785494  0.09919857 -0.0320422\n",
      "  0.02079102 -0.01269864  0.06427412 -0.03899681 -0.00116285 -0.04795023\n",
      " -0.02193702  0.01764927  0.01980599  0.03475582 -0.01583195  0.00299112\n",
      "  0.02610711  0.07167142  0.01635225 -0.01145738  0.09756006  0.08450937\n",
      " -0.02627383 -0.04014665 -0.03801753  0.03272252  0.00339356 -0.0116197\n",
      "  0.00331748 -0.01871843  0.02835696 -0.06207409  0.01362292  0.04525002\n",
      " -0.05020966 -0.02304662 -0.01497283 -0.01323906 -0.01006915  0.00514898\n",
      "  0.06441785 -0.06520548 -0.03636176 -0.08105219  0.04518103  0.01428235\n",
      "  0.07530683 -0.06931809  0.02356021 -0.04273379  0.07547738 -0.01594061\n",
      "  0.06921651  0.06995049  0.0100335  -0.0295183   0.02944931 -0.02604578\n",
      " -0.0996336   0.02779162  0.03642692 -0.11020254  0.07675946 -0.09306035\n",
      " -0.03229516 -0.04551257 -0.07645859 -0.00654163  0.07209494  0.06761248\n",
      " -0.01159632 -0.01028397 -0.17451307 -0.05670051  0.02504542 -0.00437246\n",
      " -0.00603378 -0.00361529  0.01585361 -0.02506267  0.01828111 -0.01697987\n",
      " -0.06293072  0.04461378  0.04074265 -0.09078559 -0.13339289 -0.00489142\n",
      "  0.05208965  0.08830768 -0.04917289  0.02807908 -0.05198808 -0.02214399\n",
      " -0.00822442 -0.01654217  0.03326678 -0.0179856  -0.03774732  0.0324044\n",
      "  0.09051729  0.02370011  0.02892422  0.00192541  0.00332361  0.02803884\n",
      "  0.00577871  0.0886718   0.02798326  0.00090755  0.01044189  0.02306961\n",
      " -0.0126674   0.06198018  0.03895465 -0.01851874  0.00227285 -0.02764406\n",
      "  0.06460948  0.00248193 -0.02261543 -0.03780864 -0.02623551  0.02272466\n",
      " -0.0407139  -0.01537144 -0.05860924  0.11633886 -0.01373483  0.09892836\n",
      " -0.07165034  0.06050648 -0.04073307 -0.01684841 -0.01586146  0.1842503\n",
      "  0.0802933  -0.02926533 -0.04928979 -0.08058267 -0.04132523  0.00944842\n",
      "  0.02784912 -0.00321246 -0.05236562 -0.02316735 -0.02278024  0.09482919\n",
      " -0.09407796  0.00526397 -0.04880877  0.00384736  0.02719754  0.00082992\n",
      " -0.1522541  -0.03574276  0.05427051 -0.13914017 -0.01461465 -0.01751244\n",
      "  0.1073222   0.06920118 -0.0182401   0.00145771  0.00638928  0.07014021\n",
      " -0.00203886 -0.07607339  0.00585939  0.00662921  0.02757507  0.00405357\n",
      "  0.0443244   0.06016152 -0.03748094 -0.05590712 -0.01763145 -0.13218747\n",
      " -0.01161166 -0.03354082 -0.04599167 -0.00299744 -0.03343734 -0.03733721\n",
      " -0.01618591 -0.05143616  0.00113863  0.04313815 -0.01245295 -0.00523867\n",
      "  0.00856151 -0.06715447  0.0492438   0.05687873  0.04299825  0.00571949\n",
      "  0.03399309 -0.01703181  0.00774724  0.01979449  0.02045373 -0.03035002\n",
      "  0.00305819 -0.04102436  0.01934988  0.00881678  0.00402041 -0.04634237\n",
      " -0.01150549  0.03218018 -0.00186318  0.11925944  0.02834738 -0.03105717\n",
      " -0.00179189 -0.04156287 -0.01765502  0.02058788  0.03577534 -0.00984684\n",
      " -0.07097001  0.01945529 -0.04974206 -0.0648452   0.06351522 -0.0654278\n",
      " -0.01323887 -0.01420684  0.07634169 -0.02632174  0.03018329  0.11796013]\n",
      "[ 5.77659346e-02 -1.31716682e-02 -4.00055200e-02  4.93167853e-03\n",
      " -3.85573367e-03  1.42677862e-03 -2.94669103e-02  3.76017913e-02\n",
      "  3.76039147e-02  5.49587548e-01 -7.47003332e-02 -3.67609113e-02\n",
      "  9.19128954e-02 -2.27377433e-02  3.18642706e-02 -4.24304828e-02\n",
      " -4.05427478e-02  2.52073020e-01 -3.44145149e-02 -4.99814190e-02\n",
      "  7.78026646e-04 -4.06765267e-02 -1.81897711e-02  8.32365360e-03\n",
      " -1.41100148e-02 -8.93753860e-03 -4.06043306e-02  2.47995998e-03\n",
      " -7.88601413e-02  4.64735031e-02  2.42559996e-04  9.17111635e-02\n",
      " -3.01633980e-02  8.08158219e-02  6.50917888e-02  4.28233203e-03\n",
      " -3.88928428e-02 -1.38418248e-03 -1.71040581e-03 -2.56149992e-02\n",
      "  5.84093342e-03  6.33611828e-02 -4.86181751e-02 -4.85884435e-02\n",
      "  3.11529171e-02 -1.62020233e-02 -2.69251596e-02 -1.41529075e-03\n",
      " -1.12106763e-02  3.02759409e-02  3.31468247e-02  1.17871892e-02\n",
      " -3.42913531e-02  2.04465576e-02 -1.62512865e-02 -1.06110182e-02\n",
      " -2.16484233e-03 -1.01162586e-02 -3.54167745e-02 -5.08350395e-02\n",
      "  1.06471172e-03 -1.04419934e-02  2.83223786e-03  8.90207812e-02\n",
      " -2.14551892e-02  3.20872315e-03 -1.65003669e-02 -2.86047962e-02\n",
      "  2.52688807e-02  2.29373481e-02  4.47216704e-02 -1.10214781e-02\n",
      "  3.93408835e-02  3.79160605e-02  8.76830053e-03 -3.05456156e-03\n",
      " -1.75325684e-02 -7.53458496e-03 -1.61748435e-02 -9.63338837e-03\n",
      "  1.89582426e-02  7.15003088e-02 -4.69257943e-02 -1.42854103e-03\n",
      "  5.09263463e-02 -4.91511561e-02 -1.88119367e-01  1.93863269e-02\n",
      " -2.57424056e-03  2.80994200e-03 -5.47825061e-02 -6.31084992e-03\n",
      "  3.55760334e-03  2.90698302e-03  6.87504634e-02  8.39733705e-03\n",
      "  8.94263573e-03 -1.87378302e-02  6.43783137e-02  1.86325070e-02\n",
      "  3.47096734e-02 -8.59672800e-02 -9.31020174e-03 -8.64174496e-03\n",
      "  4.44562398e-02 -1.65192649e-01  6.36393502e-02  4.95609790e-02\n",
      "  3.16200741e-02 -8.28925446e-02 -1.12724686e-02  1.33610796e-02\n",
      "  1.39431134e-02 -2.95284912e-02  2.00012736e-02  2.19648145e-02\n",
      " -5.93924858e-02  6.13778979e-02 -6.82917982e-02  4.39275056e-03\n",
      "  1.34315770e-02 -4.93847355e-02 -9.24119055e-02 -3.62024456e-03\n",
      " -6.95297644e-02 -9.99373570e-03 -1.59574039e-02 -3.98950987e-02\n",
      " -3.18876281e-03  6.23058341e-03 -7.48935565e-02 -9.40214656e-03\n",
      " -2.86812391e-02 -2.47252788e-02 -2.21474301e-02  2.95582190e-02\n",
      "  8.32365360e-04  7.98475370e-02  1.42730949e-02 -8.06735530e-02\n",
      " -2.38695353e-01 -1.21793868e-02 -3.57289203e-02  8.36845767e-03\n",
      "  5.52942529e-02 -5.06779039e-03  3.81432660e-02  2.87789162e-02\n",
      "  4.54202816e-02  1.11762760e-02 -5.31559549e-02 -2.40096822e-02\n",
      "  4.72124591e-02  1.41414413e-02 -2.36996617e-02  1.32583054e-02\n",
      " -5.93967326e-02  4.22096476e-02 -7.70000070e-02 -2.12470923e-06\n",
      " -3.66547406e-02  6.19321130e-02 -3.33867744e-02  1.15291914e-02\n",
      "  1.29550779e-02 -8.31643417e-02  5.87342195e-02  1.22768525e-02\n",
      "  8.43194872e-02  5.35721472e-03  5.23893945e-02 -1.89091917e-02\n",
      "  3.33018340e-02 -4.45072018e-02 -4.71317656e-02  1.11255264e-02\n",
      " -2.41222233e-03  1.07057234e-02 -2.97769327e-02 -9.09361150e-03\n",
      " -6.78034127e-03 -4.53056134e-02 -4.33223248e-02 -4.94165868e-02\n",
      "  1.58174690e-02  1.87291242e-02 -2.34915633e-02 -7.11902902e-02\n",
      " -2.97875493e-03 -6.24905787e-02 -1.84549876e-02 -2.80505791e-02\n",
      " -9.26157534e-02  4.35580276e-02  1.68520072e-03  1.02997229e-01\n",
      "  1.36403106e-02  3.02823093e-02 -9.28174779e-02  2.71438733e-02\n",
      " -2.78403591e-02  5.23915179e-02 -5.83859794e-02  3.37541252e-02\n",
      "  9.19744745e-02  1.91716477e-02  5.23681603e-02  1.41129876e-02\n",
      " -4.26789261e-02  2.33790223e-02  7.73779815e-03  3.68607119e-02\n",
      " -3.33145782e-02 -1.83311924e-02 -3.67694050e-02  7.85140172e-02\n",
      " -8.56105387e-02 -1.37628336e-02 -7.25492882e-03 -2.92460737e-03\n",
      "  1.33466395e-02 -3.64869870e-02 -2.62583997e-02 -7.36046350e-03\n",
      " -4.83994596e-02 -4.92042415e-02  5.07500991e-02  5.83371371e-02\n",
      "  3.25565077e-02  2.26379428e-02 -1.29491324e-02 -5.26718097e-03\n",
      " -2.86196619e-02  3.80774401e-02 -7.93612674e-02 -6.14309777e-03\n",
      " -2.36593150e-02 -1.78134982e-02 -1.18767982e-02  1.44476406e-02\n",
      " -2.28970032e-02  3.11083272e-02  2.00913083e-02 -1.79544948e-02\n",
      "  1.43181114e-02 -6.98822588e-02  7.23709166e-03 -3.55611704e-02\n",
      " -5.52029498e-02 -4.86627631e-02  4.28063329e-03 -5.85643435e-03\n",
      "  3.42637487e-02 -3.93642411e-02  7.99791887e-03  1.22316241e-01\n",
      "  4.39211316e-02  5.93309067e-02  3.49878445e-02 -3.98547575e-03\n",
      "  2.56128758e-02  1.47893010e-02  1.25329392e-02 -4.91660200e-02\n",
      "  5.11641726e-02 -7.37044364e-02  1.03071546e-02 -1.19978338e-02\n",
      "  8.82627070e-02 -9.17196572e-02  1.02413282e-01 -1.09906886e-02\n",
      " -5.79379313e-02 -5.49821071e-02  3.51534709e-02 -3.88800986e-02\n",
      " -1.42992130e-02  9.01546925e-02  2.19690613e-03  3.02313473e-02\n",
      "  5.50797842e-02  3.63595821e-02 -2.93479990e-02 -1.41943153e-02\n",
      "  3.39346193e-03 -6.41128793e-02  9.25371889e-03 -9.15243011e-03\n",
      "  7.43733197e-02 -4.17913310e-02 -9.09042582e-02  3.58839333e-02\n",
      "  4.78006490e-02 -6.06389381e-02 -2.18289141e-02 -3.85785731e-03\n",
      "  2.42220256e-02  2.76365113e-02 -3.88949662e-02  2.80930493e-02]\n",
      "[ 9.38158482e-02 -3.92131917e-02  1.48762479e-01 -2.63044871e-02\n",
      "  6.56607747e-02  8.80508125e-02  4.19539884e-02  4.21686284e-02\n",
      "  9.41240508e-03  9.79022756e-02 -5.16293291e-03  2.32664943e-02\n",
      " -7.05988780e-02 -5.74645288e-02 -7.56456926e-02 -2.36765128e-02\n",
      "  1.27801988e-02  2.38209829e-01 -4.64449301e-02  3.94415930e-02\n",
      " -7.87689816e-03 -3.88485789e-02  1.93960853e-02 -1.01161778e-01\n",
      "  3.50332037e-02 -5.24947681e-02 -8.43675286e-02  1.79362539e-02\n",
      " -4.41843271e-02 -6.31483793e-02  5.34579009e-02  3.95158939e-02\n",
      " -1.77683923e-02 -7.22692311e-02  3.33036967e-02  7.74852699e-03\n",
      "  1.36237647e-02  1.08565509e-01  6.04805052e-02  4.48254943e-02\n",
      " -3.24726515e-02  1.85870528e-02  8.73532370e-02 -2.33779419e-02\n",
      " -6.87620509e-03  5.11450097e-02  9.79834516e-03 -7.79902264e-02\n",
      " -5.36959339e-03  2.12136507e-02 -9.82022192e-03  5.29350601e-02\n",
      "  7.90414140e-02  3.35678719e-02 -4.12481502e-02 -6.67711273e-02\n",
      "  2.81880945e-02  9.48477723e-03  2.16057822e-02  1.31393090e-01\n",
      "  7.62084359e-03 -6.78443303e-03  3.89902964e-02  2.47758590e-02\n",
      "  4.54955585e-02 -1.14951067e-01 -5.46604395e-04  2.85458285e-02\n",
      "  5.02066463e-02 -9.82476212e-03  1.21563654e-02  4.52135019e-02\n",
      " -7.80067369e-02  4.32225689e-02 -5.03318524e-03  2.44704075e-02\n",
      "  2.08848082e-02 -6.09152913e-02 -4.20640633e-02 -1.97276771e-02\n",
      " -6.36904836e-02 -4.92710322e-02  2.41057947e-02  1.88966311e-04\n",
      " -5.39559778e-03  7.47995153e-02  1.27306670e-01  1.64213851e-01\n",
      "  5.17765468e-04  6.48820121e-03  1.46671105e-02 -1.46285847e-01\n",
      "  5.75402007e-02 -1.22524034e-02  1.24959378e-02 -6.66720569e-02\n",
      " -4.13128212e-02  5.84221520e-02  8.68138820e-02  4.71053645e-02\n",
      " -2.36737616e-02 -1.66773028e-03  7.68537372e-02 -7.40799159e-02\n",
      "  4.45516920e-03 -1.10431232e-01  1.69607386e-01  2.32582390e-02\n",
      "  3.93879339e-02 -8.57104082e-03  8.57062861e-02 -4.02010884e-03\n",
      " -6.35515142e-04 -4.57693636e-02  4.40150909e-02 -3.38678174e-02\n",
      "  7.46839345e-02  4.86835241e-02 -3.22428765e-03  2.05490906e-02\n",
      " -7.17821568e-02 -2.46286374e-02  2.46479008e-02 -3.84880938e-02\n",
      " -4.40426096e-02 -1.08005516e-01 -3.41182314e-02 -7.43950009e-02\n",
      " -3.17736939e-02 -3.28111239e-02 -2.04376429e-02 -7.46990666e-02\n",
      "  1.75207295e-03 -6.66789385e-03  1.97634497e-03 -4.21012118e-02\n",
      " -2.10801866e-02 -7.80204907e-02  1.82155613e-02 -5.75113073e-02\n",
      " -2.68053144e-01 -1.26248598e-02  1.01431467e-01  7.90180266e-02\n",
      " -3.30381468e-02 -4.01928350e-02 -3.29473391e-02  9.99771282e-02\n",
      "  5.83905093e-02  7.12455530e-03  1.10242737e-03 -7.80425146e-02\n",
      " -6.39491528e-03 -1.01476861e-02  5.02493009e-02  6.92147315e-02\n",
      "  2.27298923e-02  6.82089431e-03 -2.31440403e-02  7.49811307e-02\n",
      " -5.47347404e-02  2.83559542e-02 -1.07129076e-02 -6.08946532e-02\n",
      "  3.23240533e-02 -3.78964543e-02  9.04861614e-02  3.18356082e-02\n",
      "  1.84467118e-02 -9.59622487e-03  1.66442804e-02 -1.20973391e-02\n",
      " -3.14641162e-03 -8.08589756e-02 -7.45422170e-02 -3.08628450e-03\n",
      "  9.61163566e-02  4.87990975e-02  8.39010999e-02 -4.31001186e-03\n",
      " -1.01652980e-01 -2.69057546e-02 -5.15825488e-02 -8.92492309e-02\n",
      "  1.16511341e-03  5.52520808e-03 -2.39902195e-02 -4.39077690e-02\n",
      "  6.99604675e-03  2.67901793e-02 -3.71479653e-02  4.08477662e-03\n",
      " -7.68482238e-02 -4.92366329e-02 -6.83121383e-02  2.63320021e-02\n",
      " -4.67682723e-03  5.02424203e-02  7.41679687e-03  1.04055302e-02\n",
      " -4.25992869e-02  1.28334463e-02  6.14216216e-02  3.34027619e-03\n",
      "  7.42298886e-02  5.17283939e-02 -1.35735432e-02 -1.40231885e-02\n",
      "  5.63789420e-02  1.59824714e-02 -5.45847639e-02  8.08397159e-02\n",
      " -1.85361449e-02 -3.21850888e-02  3.43301184e-02  6.32144213e-02\n",
      "  3.60458679e-02 -2.69208886e-02 -6.47746921e-02  4.39669332e-03\n",
      " -2.60898452e-02  2.65851691e-02 -5.18756136e-02  3.06069292e-02\n",
      "  6.86038211e-02 -3.86022925e-02 -3.77684981e-02 -4.98667993e-02\n",
      " -1.36503195e-02 -3.04445717e-02 -1.09668985e-01  1.56302415e-02\n",
      " -9.72115714e-03  2.24423297e-02  1.44510940e-02 -1.46079464e-02\n",
      "  1.38608320e-02  1.63952436e-03  4.02286090e-02  3.10692340e-02\n",
      "  1.31171569e-01 -1.11152204e-02 -1.06357187e-02 -2.73295324e-02\n",
      " -8.26600343e-02  1.11536086e-02  6.15371973e-04 -3.19126621e-02\n",
      " -8.20422545e-02 -2.28798669e-02 -7.89382160e-02 -1.20663814e-01\n",
      "  1.56495045e-03 -1.66291464e-03  2.07045674e-02  1.14971705e-01\n",
      "  5.82212731e-02 -2.80298665e-02 -6.14670254e-02 -1.91841945e-02\n",
      "  5.93962939e-03 -3.01859044e-02 -6.49948418e-02 -8.25499594e-02\n",
      " -3.72016244e-02  5.88404313e-02 -7.89781287e-02  5.37908711e-02\n",
      " -1.73762605e-01  5.97815439e-02  7.04007521e-02 -3.79336067e-02\n",
      "  1.60402600e-02  5.52603342e-02 -1.02276262e-03 -8.47582880e-04\n",
      "  4.94609075e-03 -8.19019135e-03 -5.76874195e-03 -8.94528627e-02\n",
      "  3.60155962e-02  3.66815366e-02  8.29035696e-03  1.11031123e-02\n",
      " -3.70599069e-02  5.85363582e-02  6.19155690e-02  1.15355588e-01\n",
      " -4.69553918e-02  2.53757518e-02  2.61944141e-02 -5.01694977e-02\n",
      " -7.14092851e-02 -4.34014387e-03 -1.92942675e-02 -6.92518726e-02\n",
      "  7.84029951e-04 -5.19788079e-02  7.33837066e-03  3.17599364e-02]\n",
      "[ 0.00243347  0.04207732 -0.02550473 -0.12029478  0.02539725  0.0323929\n",
      "  0.02787716 -0.06723327 -0.02776767  0.3628208  -0.09549367  0.14282078\n",
      "  0.05408551 -0.01824162 -0.0368397   0.01363158  0.0108173   0.3162237\n",
      " -0.05152449  0.0077891  -0.00285706  0.01151221  0.00475177  0.00487506\n",
      "  0.06428497  0.03857747 -0.07604983  0.00721931  0.02394743  0.00243976\n",
      " -0.00761735 -0.10231899 -0.00998878  0.01872624  0.02236784 -0.01481496\n",
      "  0.06893048  0.05726092  0.02719788  0.01422003 -0.00448107 -0.05698515\n",
      "  0.10058935 -0.09873601 -0.018445   -0.03118641 -0.07707585 -0.00288505\n",
      " -0.03932164 -0.02244286 -0.00285666 -0.03630844  0.04969751 -0.03422394\n",
      " -0.03112761 -0.02799883  0.00436164  0.0277778   0.00138009 -0.03024352\n",
      " -0.07739623  0.02580686  0.08923409  0.06626199 -0.09351259  0.01392783\n",
      "  0.07045735  0.03817598 -0.06455668  0.09017293 -0.04248084 -0.05472222\n",
      "  0.099247    0.03120263  0.0107368  -0.01010436  0.02272471  0.03017457\n",
      " -0.07503191  0.06240729 -0.0686689   0.00915498 -0.03850041  0.05400642\n",
      " -0.05353397 -0.09643049  0.13865785 -0.06215585  0.0498942   0.06409841\n",
      " -0.01441672  0.00616773  0.01786811  0.00912983  0.04080797 -0.04383536\n",
      " -0.07375038 -0.05261541 -0.08597148 -0.02900661 -0.02069902  0.04359203\n",
      " -0.04445584 -0.03636725  0.04368936  0.02798463  0.04968737 -0.05188948\n",
      "  0.01111497  0.04320474  0.05199087 -0.05205778  0.03641997 -0.09659676\n",
      " -0.05106014 -0.00185533 -0.01102312 -0.04259642  0.02554325 -0.08272104\n",
      " -0.00429148  0.04174072  0.0383747  -0.00105231 -0.10421289  0.0585242\n",
      " -0.01576516 -0.05611932  0.09442507 -0.02884439 -0.03625369 -0.08834797\n",
      " -0.06586254  0.03048482 -0.01183522  0.1006806   0.04151158  0.00402828\n",
      "  0.02702146  0.02600152 -0.20636156  0.05881822  0.05879389  0.00608196\n",
      " -0.0218244   0.05812474 -0.04945013  0.04644504 -0.05322575 -0.01404585\n",
      " -0.03627397  0.04448017  0.03071192  0.00926062 -0.0102394   0.01449458\n",
      " -0.02082474 -0.01636476  0.06143196  0.00634719  0.05396384 -0.00123592\n",
      "  0.02091193 -0.08108264 -0.00891084 -0.01168477  0.01764526 -0.01990253\n",
      "  0.0463031  -0.00105665  0.00772056  0.00322611 -0.04181574  0.00443119\n",
      "  0.00081973 -0.00873199 -0.00046516 -0.05291754 -0.05231936 -0.05709668\n",
      " -0.04687694 -0.00210964 -0.06103858 -0.08196064  0.00297123 -0.02117959\n",
      "  0.0615962  -0.04249503  0.06324474  0.01384368  0.02043947  0.0021135\n",
      "  0.10951945  0.060558    0.0256568   0.00279035  0.04407869 -0.08013771\n",
      "  0.01351134  0.10204931  0.03023946 -0.02342833  0.00203624  0.01940492\n",
      "  0.03367443 -0.03813745  0.01115634  0.00541707 -0.06415722 -0.00944575\n",
      " -0.01046124  0.00476008 -0.02231917  0.01736584  0.05757522  0.00821168\n",
      "  0.01459678  0.0287065  -0.00429857  0.0906758   0.04073294 -0.02628743\n",
      " -0.01362287  0.0965481   0.02715935 -0.03505328 -0.0756828  -0.03504923\n",
      "  0.00544039 -0.02668486  0.01848474 -0.09426285  0.02583322 -0.01828177\n",
      " -0.02139655  0.01378975 -0.02713299  0.03458488  0.01814996 -0.04690736\n",
      " -0.05590843  0.0124774  -0.01047239  0.05754075  0.05127306 -0.04894725\n",
      " -0.04036186  0.02443206 -0.0205003   0.05554344  0.05645795  0.0536313\n",
      " -0.03709114 -0.00992794  0.03892826  0.03486065  0.06825119 -0.0409276\n",
      " -0.0695611  -0.04978673 -0.03122494  0.07999375  0.04631121 -0.05222\n",
      " -0.05206183 -0.07569903 -0.04843018 -0.00989854  0.1588175   0.03822464\n",
      " -0.05368807  0.01958093  0.01270532 -0.06218627 -0.08786944  0.02028942\n",
      "  0.04285799  0.0080012  -0.02246111  0.04951907  0.12357362 -0.09458525\n",
      "  0.0175165  -0.08050474 -0.04737374  0.00432047 -0.02185482 -0.04625241\n",
      "  0.10301451  0.02345469  0.03277817 -0.01353243 -0.05993144  0.00458509\n",
      " -0.05705004  0.01287605  0.02842668  0.02812657 -0.07309745 -0.00709704]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for a in ma:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.60825551e-02  7.71607757e-02 -1.34218372e-02  1.83293805e-03\n",
      "  5.99548183e-02  6.82326034e-02  9.99246910e-03  9.68500823e-02\n",
      " -1.53730297e-03 -3.25198704e-03 -4.23940867e-02 -6.30294159e-02\n",
      " -1.11158825e-02 -4.82476614e-02  1.41313627e-01  8.24230909e-02\n",
      " -6.88238740e-02  2.86174845e-02  5.55794127e-03  9.75596160e-03\n",
      "  2.80262157e-02 -2.47151013e-02  9.10556316e-02  1.06428657e-03\n",
      "  5.78853674e-02 -8.25413465e-02 -5.62298112e-02  4.13889269e-04\n",
      "  7.54460990e-02 -1.37174716e-02 -3.19877267e-02 -1.88615248e-02\n",
      " -8.31917375e-02  8.98139700e-02  7.38496631e-02  8.73897597e-02\n",
      " -5.91270365e-02  5.45742512e-02 -8.12996775e-02 -7.29036406e-02\n",
      "  4.05611470e-02 -8.69167410e-03  2.87357401e-02 -5.32143284e-04\n",
      " -4.82476614e-02  3.87282073e-02 -3.79595570e-02  8.72715041e-02\n",
      " -1.34691387e-01 -3.76639217e-02  5.59933037e-02 -8.66802335e-02\n",
      " -4.55278158e-03  9.58449244e-02 -3.01547870e-02  2.03397013e-02\n",
      "  8.86905531e-04  3.39980461e-02  8.09449106e-02  2.62524039e-02\n",
      "  9.59040523e-02  2.36508134e-03  9.64361951e-02  5.09083793e-02\n",
      " -5.25048077e-02  3.55944745e-02 -4.90163118e-02  5.32143302e-02\n",
      "  1.77381109e-04  5.75306043e-02  2.86766123e-02  3.35841589e-02\n",
      "  1.12577878e-01  9.46032535e-03 -1.76198576e-02 -2.74940711e-02\n",
      "  2.82627214e-02  9.87421498e-02 -1.04004450e-01  4.43452783e-03\n",
      " -1.21801691e-02  1.21033035e-01  3.18103433e-02 -2.32369248e-02\n",
      " -5.49881421e-02 -4.37540077e-02 -1.12932637e-01  1.87491834e-01\n",
      "  1.79746188e-02 -2.71984376e-02 -1.76789835e-02 -6.66952953e-02\n",
      "  9.05234963e-02  3.18103433e-02 -1.10981442e-01 -3.14555839e-02\n",
      "  4.53504361e-02  7.16028363e-02  6.13738634e-02 -1.14706457e-02\n",
      "  1.44388214e-01  6.61040246e-02  1.54912835e-02  4.55278158e-02\n",
      "  2.62524039e-02 -5.26230643e-03  6.44484675e-03 -2.51881164e-02\n",
      " -1.86131909e-01 -9.90377814e-02 -1.42082274e-01  7.34357759e-02\n",
      "  4.99032177e-02 -6.23790212e-02  1.25349313e-01 -2.78488323e-02\n",
      " -3.21651101e-02 -5.13222665e-02 -3.92603502e-02  6.58675134e-02\n",
      "  3.66587639e-02 -7.33175222e-03  2.15813685e-02 -7.62738707e-03\n",
      "  5.51655255e-02 -2.16404945e-02  3.32885236e-02 -1.14706457e-02\n",
      "  9.27703232e-02 -2.33551804e-02  6.77595884e-02  3.79595570e-02\n",
      "  1.71468407e-02  5.14405221e-02 -4.13297974e-02 -1.30670751e-02\n",
      "  6.44484675e-03 -1.83293805e-03  1.61062047e-01  7.75155425e-02\n",
      "  2.69619282e-02  4.07385267e-02  4.45817858e-02  3.34658995e-02\n",
      " -7.11889490e-02 -7.12480843e-02  1.04063582e-02 -5.43968752e-03\n",
      " -4.74198833e-02 -1.05305254e-01 -9.10556316e-03  1.50182676e-02\n",
      " -3.25198704e-03 -1.21210422e-02 -4.60008346e-02  3.47075723e-02\n",
      "  2.28821617e-02 -4.29853536e-02  2.68436745e-02 -2.18770024e-03\n",
      "  3.16920914e-02 -2.53654979e-02 -1.06428666e-02  5.22091724e-02\n",
      " -9.36572254e-02  6.69317991e-02  6.14921190e-03 -1.81520004e-02\n",
      "  1.54912835e-02  6.26155287e-02 -2.80262157e-02 -1.20619154e-02\n",
      "  3.92603502e-02  2.32960526e-02  9.87421442e-03 -1.37174726e-01\n",
      "  2.66662929e-02  4.07385267e-02  1.17603675e-01 -1.83885079e-02\n",
      "  8.49655494e-02  5.59933037e-02  1.24698915e-01  8.27778503e-02\n",
      "  1.88023970e-02  9.19425413e-02 -6.04278296e-02 -8.86905566e-03\n",
      " -7.53278434e-02  5.32143330e-03 -3.39389183e-02  3.04504223e-02\n",
      "  7.09524425e-03  2.15813685e-02  3.12782004e-02 -3.72500322e-03\n",
      " -5.09675033e-02  3.60083655e-02 -7.37314150e-02  9.69683379e-03\n",
      "  2.53063720e-02  5.87131456e-02 -3.95559892e-02  8.49064216e-02\n",
      "  4.47591692e-02  5.01988530e-02 -4.30444814e-02 -9.16469097e-03\n",
      " -2.40055751e-02 -1.13642164e-01 -4.44635302e-02  8.51429254e-03\n",
      "  6.83508515e-02  4.18619402e-02 -2.99774092e-02  6.42119572e-02\n",
      " -3.94968577e-02 -9.93334223e-03 -6.30294159e-02 -4.46409136e-02\n",
      "  9.10556316e-03 -4.22758274e-02 -2.25865282e-02 -2.12857313e-03\n",
      " -6.91786315e-03  7.92302284e-03  1.42496154e-02 -6.66952953e-02\n",
      "  2.28230357e-02 -7.50913378e-03 -4.44044024e-02  2.46559735e-02\n",
      "  1.83885079e-02  4.43452783e-03 -7.08933175e-02  4.13297974e-02\n",
      "  5.87131456e-02 -1.77381109e-04  5.45151271e-02  4.59417067e-02\n",
      " -1.31853297e-02  3.83734442e-02 -2.05762070e-02  4.83067855e-02\n",
      "  2.63115298e-02  8.79810303e-02 -2.38873232e-02 -6.58675134e-02\n",
      "  2.04579532e-02 -7.05976784e-02 -8.69167410e-03 -3.31111401e-02\n",
      " -7.47365803e-02  3.66587639e-02 -1.17662800e-02  8.73306319e-02\n",
      "  1.09385019e-02 -1.78563632e-02 -6.80552199e-02  3.39389183e-02\n",
      "  5.27413189e-02  4.04428951e-02  4.94302027e-02 -9.78552401e-02\n",
      " -2.90905032e-02 -8.92818160e-03 -8.30734819e-02  7.33766556e-02\n",
      "  5.48107624e-02 -1.17662800e-02  4.29853536e-02  8.04718956e-02\n",
      " -3.22242342e-02  8.40786472e-02 -5.91270346e-03 -2.38281954e-02\n",
      " -4.96667102e-02  1.01166353e-01 -5.65254427e-02  2.25865282e-02\n",
      " -4.99032177e-02  1.30670756e-01 -7.22532347e-02 -3.66587639e-02\n",
      "  5.78853674e-02 -3.80778089e-02  6.34433031e-02 -8.14179257e-02\n",
      "  6.48623556e-02 -7.76337981e-02 -6.22607656e-02 -1.40131079e-02\n",
      " -8.01171362e-02 -2.65480392e-02 -8.70350003e-02 -2.82035954e-02\n",
      " -2.09900979e-02  8.75080097e-03  1.30670751e-02  1.58460457e-02]\n",
      "[ 3.63372266e-02 -6.42727837e-02 -6.99139014e-02 -2.87757237e-02\n",
      "  4.88159619e-02 -4.73869257e-02 -4.47651558e-02 -1.49071524e-02\n",
      "  7.46154636e-02  4.76607293e-01  5.73901646e-02  7.59019703e-03\n",
      "  4.17495519e-02 -5.49109243e-02 -1.45198870e-02 -2.27951594e-02\n",
      " -2.96365190e-03  2.15874195e-01 -1.16333142e-02 -2.13248674e-02\n",
      " -8.60964954e-02  1.29025672e-02  9.07155481e-05  1.23688355e-02\n",
      "  2.36803349e-02 -4.57215942e-02 -7.02777281e-02 -2.44286098e-02\n",
      "  6.22830093e-02  3.26221138e-02 -3.11480695e-03  9.65273231e-02\n",
      "  4.78463918e-02 -1.19496894e-03  4.65129986e-02 -1.87274739e-02\n",
      "  7.83080794e-03 -6.12628087e-02 -8.96784570e-03 -5.90142384e-02\n",
      " -1.42151406e-02  3.10730562e-02 -2.35190541e-02 -1.66700035e-02\n",
      " -5.28611382e-03 -3.10224225e-03 -1.23168873e-02  4.02305014e-02\n",
      "  5.80671756e-03  8.32740625e-04 -4.33492474e-02  6.85486346e-02\n",
      " -2.07303744e-02  5.12670726e-03 -7.85031095e-02  1.61527749e-02\n",
      " -1.65801719e-02  7.09078535e-02  1.77100841e-02  6.14390932e-02\n",
      "  1.05206549e-01  6.97845081e-03  3.11818272e-02  1.04287617e-01\n",
      " -2.88863704e-02  2.60114223e-02  4.08868827e-02  5.41964024e-02\n",
      "  5.90611249e-03  8.63740593e-02  8.70435610e-02 -3.48706841e-02\n",
      "  5.31274416e-02  4.78445180e-02 -6.42596558e-03 -1.10570118e-02\n",
      " -6.00363128e-03 -3.37473378e-02  3.16487961e-02 -2.07960121e-02\n",
      " -2.83575151e-02  1.57671981e-02 -5.66531420e-02 -3.01822536e-02\n",
      " -3.90658937e-02 -3.38129769e-03 -9.61466208e-02 -1.51972729e-03\n",
      "  1.29125053e-02  2.15499103e-03 -2.55257003e-02  1.79460067e-02\n",
      "  1.71712902e-03 -7.09659904e-02  4.89191059e-03  3.47937979e-02\n",
      "  6.35638908e-02 -7.31357955e-04 -9.49820224e-03 -4.49058041e-02\n",
      " -3.39423753e-02  6.40196055e-02  1.86087638e-02 -6.03401288e-03\n",
      " -2.16211751e-02 -2.05822185e-01  7.96864741e-03  2.66565513e-02\n",
      "  4.07124721e-02  2.20918935e-02  3.65922786e-02 -7.33627155e-02\n",
      "  3.46887745e-02  6.51204512e-02  3.01972553e-02  4.42963094e-03\n",
      " -5.24916947e-02  1.60575062e-01 -9.46538243e-03  8.70641917e-02\n",
      "  2.73054317e-02 -8.48756358e-02  4.87747043e-02 -1.38318148e-02\n",
      " -4.52114921e-03  4.01686132e-03 -5.19515853e-03 -1.47499973e-02\n",
      " -9.92672518e-03  4.91704084e-02 -3.95628698e-02  1.15082271e-01\n",
      "  6.84548691e-02 -5.13214571e-03  4.64454889e-02  4.84071299e-02\n",
      "  8.24826509e-02  3.19938622e-02  5.36656715e-02  4.13576001e-03\n",
      " -2.59195298e-01 -3.53320278e-02  6.78022346e-03  1.35163758e-02\n",
      "  2.34402884e-02  2.42054388e-02 -1.15823045e-01 -2.99159512e-02\n",
      "  8.16893764e-03 -4.34730239e-02 -2.99290791e-02  9.45581775e-03\n",
      " -3.52270057e-04  5.30017950e-02 -2.94414815e-02 -4.75950912e-02\n",
      " -5.72420098e-02  7.74960369e-02 -4.44200858e-02 -3.98310497e-02\n",
      " -4.49358113e-02  1.39212683e-02 -9.99029912e-03 -6.77309707e-02\n",
      " -4.92472947e-02 -4.13463488e-02 -2.14861482e-02 -1.95620153e-02\n",
      "  3.15794088e-02  1.14988498e-02 -3.03754173e-02  2.76580006e-02\n",
      "  1.22683151e-02  6.11165315e-02 -8.31071585e-02 -4.69855927e-02\n",
      " -2.74273288e-02 -5.34781348e-03  3.87058221e-02 -4.26516086e-02\n",
      "  2.90926616e-03  2.45767646e-02 -3.33666354e-02 -2.28776764e-02\n",
      " -6.40833750e-02  2.48955768e-02 -1.55762851e-03 -4.08456251e-02\n",
      " -3.89027372e-02  4.30379361e-02  1.41243712e-04  3.34360227e-02\n",
      " -1.40407300e-02  1.77460928e-02 -3.43999676e-02  1.50125485e-03\n",
      " -7.26725832e-02 -1.31199218e-03 -7.76479468e-02 -3.08967698e-02\n",
      " -6.51279539e-02 -4.38087136e-02  2.15236563e-02  2.79805660e-02\n",
      "  7.65902326e-02 -3.30722034e-02 -2.74310820e-02  1.51357614e-03\n",
      "  1.58859091e-03  5.18896952e-02 -2.08466463e-02  5.69531992e-02\n",
      " -3.40230167e-02 -9.26865637e-02 -7.76273161e-02  1.68689806e-03\n",
      " -5.99650554e-02 -2.52500214e-02  2.15067770e-02  5.45996102e-03\n",
      " -4.86452989e-02 -1.10146287e-03  7.82424398e-03  3.33160013e-02\n",
      "  2.40516588e-02 -1.39610274e-02  1.17128296e-02  2.76336204e-02\n",
      " -9.44737904e-03  5.42526692e-02 -2.12048441e-02 -1.10163167e-02\n",
      "  2.05015782e-02  7.51705766e-02  2.36653332e-02 -8.22257325e-02\n",
      "  3.75412144e-02  4.13238443e-02  1.39272697e-02  9.25346538e-02\n",
      "  2.51618796e-03  1.53052937e-02 -4.17608060e-02  9.27578285e-02\n",
      "  2.40479093e-02 -3.62528339e-02 -5.04175238e-02 -4.11213003e-03\n",
      " -3.43099497e-02  4.98867966e-02 -2.74742153e-02 -1.36956610e-02\n",
      " -3.33741400e-03 -2.73466911e-02  1.59721766e-02  6.37945607e-02\n",
      "  1.90837961e-02  3.97279039e-02 -3.85839269e-02  2.25419831e-03\n",
      "  1.16983898e-01 -1.32256933e-02 -1.18092239e-01  1.81262307e-02\n",
      " -3.18569615e-02  2.89201271e-02  5.72682656e-02  4.64004800e-02\n",
      " -4.29722993e-03 -1.07290089e-01 -7.39515806e-03 -4.96298708e-02\n",
      " -3.07636186e-02 -6.99007735e-02  6.02032233e-04  1.45684602e-02\n",
      "  4.33323681e-02  3.41692977e-02  5.40857576e-02  3.44993621e-02\n",
      "  4.23590504e-02  9.65085700e-02 -1.23829007e-01 -1.72678716e-02\n",
      "  1.22489985e-02  3.87883373e-02  3.85801755e-02 -2.91545484e-02\n",
      " -1.02522899e-03  6.09439984e-02 -5.94324470e-02 -1.82096846e-02\n",
      "  2.26019956e-02  4.59503895e-03 -6.61256537e-02  1.99952256e-03\n",
      "  1.90894231e-02 -9.60678607e-02  5.37969470e-02 -7.26125687e-02]\n",
      "[-7.59130418e-02  3.58315632e-02  1.30625200e-02 -8.22621733e-02\n",
      " -2.61876006e-02  2.94893757e-02 -2.31888928e-02 -1.14116315e-02\n",
      "  5.01953326e-02  3.13133448e-01 -3.94364111e-02  7.27377683e-02\n",
      " -7.54584298e-02  4.18748558e-02 -3.01358271e-02  1.28482869e-02\n",
      "  6.74021021e-02  1.47043720e-01  9.40582063e-03 -3.30247097e-02\n",
      " -7.49009624e-02 -2.63168896e-03  1.37510961e-02 -9.57973748e-02\n",
      "  3.59483436e-02 -3.11048124e-02 -2.41300724e-02 -6.19023889e-02\n",
      "  2.23936867e-02 -4.91776913e-02 -4.32261564e-02 -3.56369332e-04\n",
      " -1.77781526e-02  4.35834378e-02  4.85743359e-02  6.90620244e-02\n",
      "  8.90784338e-02 -1.24082819e-01  2.77682836e-03  9.25706699e-02\n",
      "  1.33842174e-02  2.36490555e-02 -1.84579697e-02 -3.44774909e-02\n",
      " -2.11202446e-02 -3.15135382e-02 -5.91553077e-02  2.43886542e-02\n",
      "  3.66323330e-02  1.94394658e-03 -3.41104716e-02  4.97810468e-02\n",
      "  6.35762140e-03  3.49237509e-02 -2.26355847e-02  1.15922220e-01\n",
      " -7.76063232e-03  1.49490498e-02 -7.68792406e-02  1.32567346e-01\n",
      "  5.23696393e-02 -1.93115640e-02  1.83689948e-02  5.31565063e-02\n",
      "  1.30978320e-02 -5.70185408e-02  8.75366777e-02  1.47363462e-03\n",
      " -2.16735508e-02  1.92059092e-02 -1.08516505e-02  2.14260910e-02\n",
      "  5.72882406e-02 -5.84685383e-03  7.54542649e-02 -2.72719730e-02\n",
      "  3.22378444e-04 -4.32108641e-02  8.38581547e-02 -4.28063050e-02\n",
      " -8.39415658e-03  2.29678471e-02 -6.73548356e-02 -5.07208370e-02\n",
      " -9.43946466e-03 -7.86726326e-02  9.58877355e-02  4.74635512e-02\n",
      "  1.09623127e-01 -2.27912888e-02  2.81644948e-02  2.50559598e-02\n",
      "  6.31285608e-02 -1.51700955e-02 -2.93461829e-02 -1.40231624e-02\n",
      " -2.40869764e-02 -7.88283348e-02  2.14316510e-02 -6.70225769e-02\n",
      "  1.55371139e-02  9.91144404e-02  3.33041437e-02  5.65889617e-03\n",
      "  9.49465558e-02 -1.10537887e-01  4.76456657e-02 -2.99064424e-02\n",
      "  3.78140225e-03 -2.99551012e-03  6.41003326e-02  1.04593309e-02\n",
      "  6.54961094e-02 -9.39164013e-02  2.09353436e-02 -1.61849573e-04\n",
      " -1.43540353e-02 -1.27308127e-02 -1.36795007e-02 -6.25001825e-03\n",
      "  4.78833914e-03  2.91487724e-02  8.14919919e-02 -1.34477511e-01\n",
      " -7.51609262e-03 -4.16510329e-02  5.04080355e-02 -8.51454958e-03\n",
      " -5.78943789e-02 -6.61439542e-03 -1.39230667e-02  6.06053090e-03\n",
      " -3.18805575e-02  4.28633019e-02  2.50545684e-02 -4.37113419e-02\n",
      " -1.67243630e-02  2.85662673e-02  1.02131225e-01  2.49503017e-03\n",
      " -2.80546665e-01 -1.12049066e-01  7.24221915e-02  9.39553306e-02\n",
      "  8.92452598e-02 -2.90222596e-02 -2.01165043e-02  7.25695565e-02\n",
      "  1.88096948e-02  1.10865980e-02  2.11577788e-02 -1.68230683e-02\n",
      " -4.30593267e-02  6.31202199e-03 -5.41449524e-02  2.03444995e-02\n",
      " -3.66059169e-02  5.01286015e-02 -3.62333395e-02 -8.90645310e-02\n",
      "  4.78833951e-02 -1.83676053e-02 -2.68688090e-02 -7.35315904e-02\n",
      " -3.26674228e-04  3.38129662e-02 -8.02213326e-03 -6.26614466e-02\n",
      " -3.25186662e-02 -4.41006012e-02  1.06282428e-01  5.30383326e-02\n",
      "  1.95757076e-02 -1.18063157e-02  2.41676085e-02  8.84931535e-02\n",
      " -4.71465811e-02  7.90229589e-02  2.68729776e-02  1.07728258e-01\n",
      "  2.67714933e-02 -4.36793640e-02 -5.24641760e-02 -1.54217258e-02\n",
      " -8.04270878e-02 -8.09984654e-03  5.29076532e-02  6.59034448e-03\n",
      " -2.03806441e-02 -6.71198890e-02 -2.89847255e-02  8.66010599e-03\n",
      " -4.13062572e-02 -1.00159891e-01 -5.63442819e-02  8.85084495e-02\n",
      "  1.11745996e-02 -8.89672115e-02  1.19155876e-01 -3.40048149e-02\n",
      " -1.00727096e-01 -5.72256802e-04 -2.05127168e-02  2.10604630e-03\n",
      "  5.59411198e-02  4.03595157e-02  7.54653886e-02 -2.32125260e-02\n",
      "  8.00962150e-02  2.50643007e-02 -1.42761832e-02  2.24993434e-02\n",
      " -2.13816036e-02  4.83004600e-02 -6.36804774e-02 -6.33301437e-02\n",
      "  2.98591759e-02  6.62954897e-02 -1.00329500e-02  4.01495919e-02\n",
      "  5.14103882e-02  3.25311795e-02  1.25724664e-02 -9.33728218e-02\n",
      " -1.07943736e-01 -5.62886707e-03 -4.35778797e-02  4.91790809e-02\n",
      "  2.86357794e-02  1.98885072e-02 -7.11445734e-02  1.37716718e-02\n",
      " -4.83060218e-02 -4.98644598e-02  9.76421982e-02  4.41867970e-02\n",
      "  1.18862540e-02 -3.71286422e-02  8.01949203e-02 -7.33828321e-02\n",
      " -9.43279117e-02 -2.01929640e-02 -8.16602111e-02 -1.47196641e-02\n",
      " -1.03638219e-02  3.46331932e-02 -6.13045916e-02  1.21499794e-02\n",
      " -6.42337874e-02  4.41158935e-03 -1.50046591e-02  3.17192897e-02\n",
      "  9.86167416e-03  6.22290894e-02 -3.93293612e-03  2.88498737e-02\n",
      " -8.60129949e-03  4.11102362e-02 -6.41837390e-03 -1.97008271e-02\n",
      "  4.63611037e-02 -8.30671117e-02 -6.99086711e-02 -5.83587103e-02\n",
      " -1.87207218e-02  8.18339884e-02  4.57633063e-02 -1.96327064e-02\n",
      " -4.57341112e-02  4.97337803e-02 -4.26436476e-02  1.13948099e-01\n",
      " -2.02110391e-02  1.54703837e-02  1.88694745e-02  5.72354160e-02\n",
      " -2.18431596e-02  4.47289832e-02 -2.42885575e-02  2.76570637e-02\n",
      "  5.04302792e-03  5.42255826e-02 -1.58568658e-02 -6.58978820e-02\n",
      "  4.78945151e-02  8.91020671e-02  4.95752916e-02 -4.75288890e-02\n",
      "  3.62736546e-02  2.76598446e-02 -1.51200471e-02 -8.37330297e-02\n",
      " -4.91596200e-02 -8.94913357e-03 -5.42714596e-02  1.16382383e-01\n",
      "  4.42298949e-02 -1.44054741e-02  3.44357826e-03 -2.77224053e-02]\n",
      "[-4.65418510e-02  2.99322680e-02 -8.95332247e-02  9.02531575e-03\n",
      "  1.78401582e-02 -1.96230728e-02  1.68153383e-02  1.62403751e-02\n",
      "  1.03379134e-02  4.72047418e-01 -8.22296441e-02  4.37270338e-03\n",
      "  2.57857721e-02  4.61366437e-02 -2.17100908e-03 -4.97795828e-02\n",
      " -6.30117804e-02  2.55634993e-01 -6.85588047e-02  1.59461070e-02\n",
      "  5.01041412e-02 -1.84851477e-03  1.81684550e-02 -4.98799011e-02\n",
      " -6.97724568e-03  5.87531626e-02  7.53273442e-03 -1.12480566e-01\n",
      "  6.45480305e-02 -1.45440102e-01 -6.39598863e-03  1.68377627e-02\n",
      " -3.56956609e-02 -9.25486791e-04  7.46408552e-02 -6.92118481e-02\n",
      "  3.04810703e-02  2.74400450e-02  1.54785449e-02  1.59248635e-02\n",
      " -5.29071577e-02  1.88350808e-02  1.14459405e-03 -5.20436317e-02\n",
      " -2.43891813e-02 -2.00754888e-02  1.47533007e-02  2.37538330e-02\n",
      " -3.40846628e-02  2.33053491e-02 -2.03725100e-02  1.00621358e-02\n",
      "  2.24732962e-02 -4.26648408e-02  6.71877787e-02 -2.14130688e-03\n",
      "  8.68777372e-03  8.48103873e-03  2.38128435e-02  9.50900745e-03\n",
      "  2.40449514e-02  7.79474247e-03 -5.41680194e-02  1.16143174e-01\n",
      "  9.51392502e-02  6.65839016e-03  6.13398035e-04  8.79950076e-02\n",
      "  7.46506825e-02 -3.02666631e-02  7.69835785e-02 -2.37971079e-02\n",
      "  3.97438034e-02 -3.70588116e-02  2.79042609e-02  2.97788400e-02\n",
      "  3.23792510e-02 -6.38162941e-02  1.26098311e-02  1.38236838e-03\n",
      " -5.33320345e-02  6.12453907e-04 -4.26746756e-02  1.33846430e-02\n",
      " -9.02216807e-02 -2.14170031e-02 -1.77121051e-02  4.37526091e-04\n",
      "  8.01957399e-02 -3.62051204e-02 -4.58750315e-02  1.12364516e-02\n",
      " -5.09361923e-02  1.45251267e-02 -2.20130123e-02  9.19054523e-02\n",
      "  1.20687010e-02 -6.61963969e-02 -4.92524169e-03  2.74793822e-02\n",
      " -2.67181429e-03  1.13466056e-02 -1.10672871e-02 -4.03673537e-02\n",
      "  6.40916824e-02 -2.09645852e-01  6.41487241e-02 -1.35886241e-02\n",
      "  3.22041847e-02  4.58278209e-02 -2.90530064e-04 -3.93621996e-02\n",
      " -5.62550360e-03 -5.46283089e-02  3.12187038e-02 -3.99523079e-02\n",
      "  1.19074052e-02 -1.31446663e-02 -4.61976230e-02  4.41125743e-02\n",
      "  1.46317398e-02 -7.25951418e-02 -1.26442537e-02  2.62283534e-02\n",
      "  4.09456566e-02  2.00243481e-02  2.55064536e-02  9.59378667e-04\n",
      "  2.60375515e-02  1.45316171e-02 -8.71413108e-03  2.13835631e-02\n",
      " -2.17395946e-02  9.86739993e-03 -1.38278147e-02  2.82858666e-02\n",
      "  3.38053443e-02 -6.56613708e-02 -3.43738161e-02 -3.99621464e-02\n",
      " -3.75407308e-01  8.41789693e-02  3.04712337e-02  6.29724422e-03\n",
      " -3.27549526e-03 -8.75976607e-02 -1.69439800e-02 -7.34488340e-03\n",
      "  3.55225615e-02 -2.22529899e-02  5.89813367e-02  2.03666110e-02\n",
      " -2.66217603e-03 -1.46468857e-03 -3.85655537e-02 -2.83173379e-02\n",
      " -7.54158571e-03 -4.77279723e-02 -1.77561659e-02  1.73515491e-02\n",
      " -2.15428937e-02  3.78338210e-02 -2.86064912e-02 -1.44002195e-02\n",
      "  3.48714739e-02 -6.60449341e-02  5.04936166e-02 -4.55347337e-02\n",
      "  7.02819228e-02  5.32041788e-02  3.15629342e-03 -3.77905462e-03\n",
      "  6.31789789e-02 -2.46330928e-02 -6.49709394e-03  2.49596196e-03\n",
      "  2.11317837e-02 -1.79333948e-02  1.67146251e-02  6.45165592e-02\n",
      "  7.93617219e-03  4.75902818e-02  1.32664246e-03 -4.62566316e-02\n",
      "  3.57743399e-03  1.50723532e-02 -7.15073757e-03 -2.91906968e-02\n",
      " -1.55479806e-02  5.26966825e-02  3.66595038e-03  5.41365519e-02\n",
      "  5.39516471e-03 -4.50449437e-02  6.26675487e-02  3.77866104e-02\n",
      " -1.88494415e-03  3.87779921e-02  5.34244850e-02  8.06579888e-02\n",
      " -1.20289670e-02  2.71626911e-03  4.76807654e-02 -6.55374452e-02\n",
      "  5.01887202e-02 -3.53888050e-03 -1.88602600e-02  1.54313361e-02\n",
      "  2.33859979e-02  6.18886091e-02  5.08653838e-03 -3.17537375e-02\n",
      " -2.24634632e-03 -6.05352893e-02 -2.82170195e-02  8.33311826e-02\n",
      "  1.28326947e-02 -1.18299043e-02 -6.83581606e-02 -1.70441028e-02\n",
      " -1.18485903e-02 -1.25032179e-02 -2.46134233e-02  3.97634722e-04\n",
      "  1.59130618e-02  5.52361161e-02 -5.41404858e-02  2.93165874e-02\n",
      " -7.57541880e-02 -1.73226334e-02 -3.75013910e-02 -2.91218515e-02\n",
      "  3.39174666e-03  3.00325844e-02  8.79812334e-03 -2.67201103e-02\n",
      "  3.41377743e-02 -3.15826051e-02 -3.19681428e-02  3.84986773e-02\n",
      "  3.83668840e-02  1.30561495e-03 -3.88507731e-02  6.45991741e-03\n",
      "  1.08871080e-01 -5.98487966e-02 -6.00199327e-02 -7.09526688e-02\n",
      " -3.86048965e-02  6.62200078e-02  1.14136804e-02  1.76247694e-02\n",
      " -9.19979066e-02  1.62879769e-02 -1.05599901e-02  1.04258396e-01\n",
      "  2.56362781e-02  1.17101120e-02  2.26739347e-02 -3.98500264e-03\n",
      " -9.75685287e-03  5.73939458e-02  7.30180517e-02  3.97733087e-03\n",
      "  5.21734580e-02 -4.19409759e-02 -3.52629125e-02  1.65688694e-02\n",
      "  9.79953706e-02  6.68553486e-02  5.85721955e-02 -1.08876973e-02\n",
      "  6.33028969e-02 -1.33974282e-02 -2.53333561e-02  1.43646169e-02\n",
      "  1.19288461e-02  1.06020859e-02  5.17859496e-02  7.25813722e-03\n",
      "  8.53985269e-03  5.14889285e-02 -1.89129766e-02 -5.36054512e-03\n",
      " -3.72299440e-02 -1.28773469e-02  4.59497795e-02  1.32434107e-02\n",
      "  4.55189981e-02 -3.52511145e-02 -7.30298534e-02  8.91634151e-02\n",
      " -2.04984006e-02 -2.51484551e-02 -2.69030454e-03 -1.87949534e-03\n",
      " -3.90533768e-02 -2.66827364e-02  4.41027358e-02  7.94010609e-02]\n",
      "[-0.04929442  0.07125278 -0.0548929  -0.0510379   0.01157641 -0.10518142\n",
      " -0.02827024  0.07570326  0.03932058 -0.00485199  0.01221658  0.03462268\n",
      "  0.06738835 -0.02511714 -0.04173801 -0.03245237  0.03062108  0.01023531\n",
      " -0.03041581 -0.06778555 -0.01405793 -0.08452725  0.00483693 -0.07695816\n",
      " -0.03240358  0.02208224  0.04449043  0.01145777 -0.05898737 -0.02345025\n",
      " -0.07519184  0.01370414  0.01260608  0.17116839 -0.01376573 -0.012191\n",
      "  0.12162518  0.00058489 -0.02535884  0.11395386  0.01649224 -0.20419174\n",
      " -0.01425242 -0.0848485   0.07931477 -0.01267484 -0.0894843   0.0236135\n",
      " -0.03016485  0.01200177 -0.01325356  0.05095771 -0.04668101  0.07740297\n",
      " -0.00522887 -0.0696499   0.08021874  0.02302199  0.0355414   0.04521645\n",
      "  0.0101754  -0.02466182 -0.02945321  0.07914712  0.06935686 -0.03575341\n",
      " -0.08983486 -0.06437001  0.00659821 -0.03003204 -0.02740579  0.00375052\n",
      "  0.06679215 -0.07003569  0.00961167  0.03517946  0.05782656 -0.01520212\n",
      "  0.01280549  0.0531495  -0.08558392  0.00589459 -0.11527008 -0.05862311\n",
      "  0.13200928 -0.10551208  0.00430416 -0.02475    -0.02312304  0.02112626\n",
      " -0.07466825  0.0501762   0.0668588  -0.06790675 -0.08048128  0.01126131\n",
      " -0.06488825 -0.04993232  0.07857656 -0.04896729 -0.02753334  0.00321693\n",
      " -0.05046376 -0.03389836 -0.08534498  0.15077491  0.05596324 -0.0241507\n",
      "  0.04195362 -0.02059138  0.02963375 -0.05400512  0.04401207  0.03276505\n",
      "  0.09862395 -0.01624114 -0.01768163  0.03374233  0.05823794  0.02649927\n",
      " -0.00829344 -0.0366563  -0.11666939 -0.0105551   0.01755402  0.08339015\n",
      "  0.07783385  0.06181012  0.05646461  0.02812651 -0.04985781  0.11597438\n",
      " -0.04331338  0.03239337 -0.00676634 -0.09291515  0.02128869  0.03650277\n",
      " -0.06171671 -0.05775295  0.01394915 -0.0233342  -0.00475949 -0.03431731\n",
      "  0.1263204  -0.0172319   0.06206693  0.00662166  0.02025251  0.00710884\n",
      " -0.0034149   0.02070786 -0.02283316  0.0297769   0.0606655   0.07173578\n",
      " -0.01537969 -0.01379737 -0.06127214 -0.04773415  0.06666822 -0.15206124\n",
      "  0.14178863 -0.03967914 -0.03079641  0.01600972 -0.10349424 -0.07914659\n",
      " -0.0080855  -0.05013105  0.02137617  0.03520985 -0.05900185 -0.10377377\n",
      " -0.21168277 -0.00208568  0.02025155 -0.04398204  0.06430428  0.06772003\n",
      " -0.02360977 -0.03964564  0.09994629  0.06887719 -0.01487722  0.04512222\n",
      " -0.03097972  0.00784818 -0.05852522  0.09956601 -0.06874656 -0.02139762\n",
      "  0.06263729 -0.05340521 -0.05273791  0.01194863  0.01443686 -0.03640513\n",
      " -0.06658489 -0.02659368 -0.0333886   0.01386996 -0.04762264  0.06441243\n",
      "  0.05720306  0.0686902  -0.00521583 -0.14577839  0.06272233  0.04854079\n",
      "  0.00798977 -0.05390399 -0.00295427  0.00085756  0.04759822 -0.02821789\n",
      " -0.02446508  0.08341572 -0.05165319 -0.02632332  0.05096924 -0.05730248\n",
      "  0.03844697 -0.06398693 -0.03751934 -0.01845457  0.01296594 -0.0407648\n",
      "  0.02606016  0.00805702 -0.00104106  0.01096095 -0.00167954 -0.00570108\n",
      " -0.06480822  0.05571619  0.11224139  0.06976736  0.01680722 -0.01244639\n",
      "  0.03662103 -0.00680124 -0.07816625 -0.03085176  0.03263946 -0.01736704\n",
      "  0.0280546  -0.0434787   0.05116985 -0.00353728 -0.01785426  0.02054717\n",
      " -0.05077169 -0.00304107  0.12184868 -0.00647494  0.08871881 -0.00112816\n",
      "  0.01067323 -0.05361302  0.11427761 -0.03576298  0.092845   -0.01174419\n",
      " -0.0224885   0.11504749  0.02620466  0.04539512  0.00911717  0.05691147\n",
      " -0.02499888 -0.02501515 -0.07142554  0.03883912 -0.11630151 -0.01214329\n",
      " -0.08259338  0.06096926  0.00068792 -0.11181223 -0.01129614 -0.00749091\n",
      "  0.04430872  0.00873492 -0.02793345 -0.03463645  0.04791974 -0.04415647\n",
      " -0.01801207 -0.03025578 -0.01255197 -0.01158646 -0.08268739 -0.01102873\n",
      " -0.05780523  0.07883653 -0.05002907 -0.0069297   0.0171496   0.0480437 ]\n",
      "[-0.01345044  0.02927108 -0.06340598  0.02224748 -0.0332227  -0.0227285\n",
      " -0.04988962 -0.04931279 -0.04872254  0.41670188 -0.1121726   0.03685236\n",
      " -0.04199214 -0.02708256 -0.0581014   0.05258983  0.01029816  0.25537938\n",
      " -0.06508284  0.02538271 -0.0022397   0.05625015  0.03030594  0.07346901\n",
      "  0.06419554 -0.01804137  0.00485635  0.0072277  -0.00093848  0.06973011\n",
      "  0.00784421 -0.00980966 -0.02789702 -0.02889547 -0.05732142  0.02025251\n",
      " -0.08271563  0.04557772 -0.07825808  0.01284064 -0.06316644  0.03158418\n",
      " -0.11729897  0.02082168  0.09850676  0.01793711  0.00769185 -0.01447878\n",
      " -0.01181518  0.04618714  0.03950082  0.06814141 -0.05159905  0.02585606\n",
      " -0.05098197 -0.0082135  -0.0670414  -0.03716473 -0.02663795 -0.04731015\n",
      "  0.07322753  0.02950488  0.02159974  0.07517459  0.07140887 -0.00572448\n",
      " -0.01501461  0.02593463  0.03842955 -0.00785494  0.09919857 -0.0320422\n",
      "  0.02079102 -0.01269864  0.06427412 -0.03899681 -0.00116285 -0.04795023\n",
      " -0.02193702  0.01764927  0.01980599  0.03475582 -0.01583195  0.00299112\n",
      "  0.02610711  0.07167142  0.01635225 -0.01145738  0.09756006  0.08450937\n",
      " -0.02627383 -0.04014665 -0.03801753  0.03272252  0.00339356 -0.0116197\n",
      "  0.00331748 -0.01871843  0.02835696 -0.06207409  0.01362292  0.04525002\n",
      " -0.05020966 -0.02304662 -0.01497283 -0.01323906 -0.01006915  0.00514898\n",
      "  0.06441785 -0.06520548 -0.03636176 -0.08105219  0.04518103  0.01428235\n",
      "  0.07530683 -0.06931809  0.02356021 -0.04273379  0.07547738 -0.01594061\n",
      "  0.06921651  0.06995049  0.0100335  -0.0295183   0.02944931 -0.02604578\n",
      " -0.0996336   0.02779162  0.03642692 -0.11020254  0.07675946 -0.09306035\n",
      " -0.03229516 -0.04551257 -0.07645859 -0.00654163  0.07209494  0.06761248\n",
      " -0.01159632 -0.01028397 -0.17451307 -0.05670051  0.02504542 -0.00437246\n",
      " -0.00603378 -0.00361529  0.01585361 -0.02506267  0.01828111 -0.01697987\n",
      " -0.06293072  0.04461378  0.04074265 -0.09078559 -0.13339289 -0.00489142\n",
      "  0.05208965  0.08830768 -0.04917289  0.02807908 -0.05198808 -0.02214399\n",
      " -0.00822442 -0.01654217  0.03326678 -0.0179856  -0.03774732  0.0324044\n",
      "  0.09051729  0.02370011  0.02892422  0.00192541  0.00332361  0.02803884\n",
      "  0.00577871  0.0886718   0.02798326  0.00090755  0.01044189  0.02306961\n",
      " -0.0126674   0.06198018  0.03895465 -0.01851874  0.00227285 -0.02764406\n",
      "  0.06460948  0.00248193 -0.02261543 -0.03780864 -0.02623551  0.02272466\n",
      " -0.0407139  -0.01537144 -0.05860924  0.11633886 -0.01373483  0.09892836\n",
      " -0.07165034  0.06050648 -0.04073307 -0.01684841 -0.01586146  0.1842503\n",
      "  0.0802933  -0.02926533 -0.04928979 -0.08058267 -0.04132523  0.00944842\n",
      "  0.02784912 -0.00321246 -0.05236562 -0.02316735 -0.02278024  0.09482919\n",
      " -0.09407796  0.00526397 -0.04880877  0.00384736  0.02719754  0.00082992\n",
      " -0.1522541  -0.03574276  0.05427051 -0.13914017 -0.01461465 -0.01751244\n",
      "  0.1073222   0.06920118 -0.0182401   0.00145771  0.00638928  0.07014021\n",
      " -0.00203886 -0.07607339  0.00585939  0.00662921  0.02757507  0.00405357\n",
      "  0.0443244   0.06016152 -0.03748094 -0.05590712 -0.01763145 -0.13218747\n",
      " -0.01161166 -0.03354082 -0.04599167 -0.00299744 -0.03343734 -0.03733721\n",
      " -0.01618591 -0.05143616  0.00113863  0.04313815 -0.01245295 -0.00523867\n",
      "  0.00856151 -0.06715447  0.0492438   0.05687873  0.04299825  0.00571949\n",
      "  0.03399309 -0.01703181  0.00774724  0.01979449  0.02045373 -0.03035002\n",
      "  0.00305819 -0.04102436  0.01934988  0.00881678  0.00402041 -0.04634237\n",
      " -0.01150549  0.03218018 -0.00186318  0.11925944  0.02834738 -0.03105717\n",
      " -0.00179189 -0.04156287 -0.01765502  0.02058788  0.03577534 -0.00984684\n",
      " -0.07097001  0.01945529 -0.04974206 -0.0648452   0.06351522 -0.0654278\n",
      " -0.01323887 -0.01420684  0.07634169 -0.02632174  0.03018329  0.11796013]\n",
      "[ 5.77659346e-02 -1.31716682e-02 -4.00055200e-02  4.93167853e-03\n",
      " -3.85573367e-03  1.42677862e-03 -2.94669103e-02  3.76017913e-02\n",
      "  3.76039147e-02  5.49587548e-01 -7.47003332e-02 -3.67609113e-02\n",
      "  9.19128954e-02 -2.27377433e-02  3.18642706e-02 -4.24304828e-02\n",
      " -4.05427478e-02  2.52073020e-01 -3.44145149e-02 -4.99814190e-02\n",
      "  7.78026646e-04 -4.06765267e-02 -1.81897711e-02  8.32365360e-03\n",
      " -1.41100148e-02 -8.93753860e-03 -4.06043306e-02  2.47995998e-03\n",
      " -7.88601413e-02  4.64735031e-02  2.42559996e-04  9.17111635e-02\n",
      " -3.01633980e-02  8.08158219e-02  6.50917888e-02  4.28233203e-03\n",
      " -3.88928428e-02 -1.38418248e-03 -1.71040581e-03 -2.56149992e-02\n",
      "  5.84093342e-03  6.33611828e-02 -4.86181751e-02 -4.85884435e-02\n",
      "  3.11529171e-02 -1.62020233e-02 -2.69251596e-02 -1.41529075e-03\n",
      " -1.12106763e-02  3.02759409e-02  3.31468247e-02  1.17871892e-02\n",
      " -3.42913531e-02  2.04465576e-02 -1.62512865e-02 -1.06110182e-02\n",
      " -2.16484233e-03 -1.01162586e-02 -3.54167745e-02 -5.08350395e-02\n",
      "  1.06471172e-03 -1.04419934e-02  2.83223786e-03  8.90207812e-02\n",
      " -2.14551892e-02  3.20872315e-03 -1.65003669e-02 -2.86047962e-02\n",
      "  2.52688807e-02  2.29373481e-02  4.47216704e-02 -1.10214781e-02\n",
      "  3.93408835e-02  3.79160605e-02  8.76830053e-03 -3.05456156e-03\n",
      " -1.75325684e-02 -7.53458496e-03 -1.61748435e-02 -9.63338837e-03\n",
      "  1.89582426e-02  7.15003088e-02 -4.69257943e-02 -1.42854103e-03\n",
      "  5.09263463e-02 -4.91511561e-02 -1.88119367e-01  1.93863269e-02\n",
      " -2.57424056e-03  2.80994200e-03 -5.47825061e-02 -6.31084992e-03\n",
      "  3.55760334e-03  2.90698302e-03  6.87504634e-02  8.39733705e-03\n",
      "  8.94263573e-03 -1.87378302e-02  6.43783137e-02  1.86325070e-02\n",
      "  3.47096734e-02 -8.59672800e-02 -9.31020174e-03 -8.64174496e-03\n",
      "  4.44562398e-02 -1.65192649e-01  6.36393502e-02  4.95609790e-02\n",
      "  3.16200741e-02 -8.28925446e-02 -1.12724686e-02  1.33610796e-02\n",
      "  1.39431134e-02 -2.95284912e-02  2.00012736e-02  2.19648145e-02\n",
      " -5.93924858e-02  6.13778979e-02 -6.82917982e-02  4.39275056e-03\n",
      "  1.34315770e-02 -4.93847355e-02 -9.24119055e-02 -3.62024456e-03\n",
      " -6.95297644e-02 -9.99373570e-03 -1.59574039e-02 -3.98950987e-02\n",
      " -3.18876281e-03  6.23058341e-03 -7.48935565e-02 -9.40214656e-03\n",
      " -2.86812391e-02 -2.47252788e-02 -2.21474301e-02  2.95582190e-02\n",
      "  8.32365360e-04  7.98475370e-02  1.42730949e-02 -8.06735530e-02\n",
      " -2.38695353e-01 -1.21793868e-02 -3.57289203e-02  8.36845767e-03\n",
      "  5.52942529e-02 -5.06779039e-03  3.81432660e-02  2.87789162e-02\n",
      "  4.54202816e-02  1.11762760e-02 -5.31559549e-02 -2.40096822e-02\n",
      "  4.72124591e-02  1.41414413e-02 -2.36996617e-02  1.32583054e-02\n",
      " -5.93967326e-02  4.22096476e-02 -7.70000070e-02 -2.12470923e-06\n",
      " -3.66547406e-02  6.19321130e-02 -3.33867744e-02  1.15291914e-02\n",
      "  1.29550779e-02 -8.31643417e-02  5.87342195e-02  1.22768525e-02\n",
      "  8.43194872e-02  5.35721472e-03  5.23893945e-02 -1.89091917e-02\n",
      "  3.33018340e-02 -4.45072018e-02 -4.71317656e-02  1.11255264e-02\n",
      " -2.41222233e-03  1.07057234e-02 -2.97769327e-02 -9.09361150e-03\n",
      " -6.78034127e-03 -4.53056134e-02 -4.33223248e-02 -4.94165868e-02\n",
      "  1.58174690e-02  1.87291242e-02 -2.34915633e-02 -7.11902902e-02\n",
      " -2.97875493e-03 -6.24905787e-02 -1.84549876e-02 -2.80505791e-02\n",
      " -9.26157534e-02  4.35580276e-02  1.68520072e-03  1.02997229e-01\n",
      "  1.36403106e-02  3.02823093e-02 -9.28174779e-02  2.71438733e-02\n",
      " -2.78403591e-02  5.23915179e-02 -5.83859794e-02  3.37541252e-02\n",
      "  9.19744745e-02  1.91716477e-02  5.23681603e-02  1.41129876e-02\n",
      " -4.26789261e-02  2.33790223e-02  7.73779815e-03  3.68607119e-02\n",
      " -3.33145782e-02 -1.83311924e-02 -3.67694050e-02  7.85140172e-02\n",
      " -8.56105387e-02 -1.37628336e-02 -7.25492882e-03 -2.92460737e-03\n",
      "  1.33466395e-02 -3.64869870e-02 -2.62583997e-02 -7.36046350e-03\n",
      " -4.83994596e-02 -4.92042415e-02  5.07500991e-02  5.83371371e-02\n",
      "  3.25565077e-02  2.26379428e-02 -1.29491324e-02 -5.26718097e-03\n",
      " -2.86196619e-02  3.80774401e-02 -7.93612674e-02 -6.14309777e-03\n",
      " -2.36593150e-02 -1.78134982e-02 -1.18767982e-02  1.44476406e-02\n",
      " -2.28970032e-02  3.11083272e-02  2.00913083e-02 -1.79544948e-02\n",
      "  1.43181114e-02 -6.98822588e-02  7.23709166e-03 -3.55611704e-02\n",
      " -5.52029498e-02 -4.86627631e-02  4.28063329e-03 -5.85643435e-03\n",
      "  3.42637487e-02 -3.93642411e-02  7.99791887e-03  1.22316241e-01\n",
      "  4.39211316e-02  5.93309067e-02  3.49878445e-02 -3.98547575e-03\n",
      "  2.56128758e-02  1.47893010e-02  1.25329392e-02 -4.91660200e-02\n",
      "  5.11641726e-02 -7.37044364e-02  1.03071546e-02 -1.19978338e-02\n",
      "  8.82627070e-02 -9.17196572e-02  1.02413282e-01 -1.09906886e-02\n",
      " -5.79379313e-02 -5.49821071e-02  3.51534709e-02 -3.88800986e-02\n",
      " -1.42992130e-02  9.01546925e-02  2.19690613e-03  3.02313473e-02\n",
      "  5.50797842e-02  3.63595821e-02 -2.93479990e-02 -1.41943153e-02\n",
      "  3.39346193e-03 -6.41128793e-02  9.25371889e-03 -9.15243011e-03\n",
      "  7.43733197e-02 -4.17913310e-02 -9.09042582e-02  3.58839333e-02\n",
      "  4.78006490e-02 -6.06389381e-02 -2.18289141e-02 -3.85785731e-03\n",
      "  2.42220256e-02  2.76365113e-02 -3.88949662e-02  2.80930493e-02]\n",
      "[ 9.38158482e-02 -3.92131917e-02  1.48762479e-01 -2.63044871e-02\n",
      "  6.56607747e-02  8.80508125e-02  4.19539884e-02  4.21686284e-02\n",
      "  9.41240508e-03  9.79022756e-02 -5.16293291e-03  2.32664943e-02\n",
      " -7.05988780e-02 -5.74645288e-02 -7.56456926e-02 -2.36765128e-02\n",
      "  1.27801988e-02  2.38209829e-01 -4.64449301e-02  3.94415930e-02\n",
      " -7.87689816e-03 -3.88485789e-02  1.93960853e-02 -1.01161778e-01\n",
      "  3.50332037e-02 -5.24947681e-02 -8.43675286e-02  1.79362539e-02\n",
      " -4.41843271e-02 -6.31483793e-02  5.34579009e-02  3.95158939e-02\n",
      " -1.77683923e-02 -7.22692311e-02  3.33036967e-02  7.74852699e-03\n",
      "  1.36237647e-02  1.08565509e-01  6.04805052e-02  4.48254943e-02\n",
      " -3.24726515e-02  1.85870528e-02  8.73532370e-02 -2.33779419e-02\n",
      " -6.87620509e-03  5.11450097e-02  9.79834516e-03 -7.79902264e-02\n",
      " -5.36959339e-03  2.12136507e-02 -9.82022192e-03  5.29350601e-02\n",
      "  7.90414140e-02  3.35678719e-02 -4.12481502e-02 -6.67711273e-02\n",
      "  2.81880945e-02  9.48477723e-03  2.16057822e-02  1.31393090e-01\n",
      "  7.62084359e-03 -6.78443303e-03  3.89902964e-02  2.47758590e-02\n",
      "  4.54955585e-02 -1.14951067e-01 -5.46604395e-04  2.85458285e-02\n",
      "  5.02066463e-02 -9.82476212e-03  1.21563654e-02  4.52135019e-02\n",
      " -7.80067369e-02  4.32225689e-02 -5.03318524e-03  2.44704075e-02\n",
      "  2.08848082e-02 -6.09152913e-02 -4.20640633e-02 -1.97276771e-02\n",
      " -6.36904836e-02 -4.92710322e-02  2.41057947e-02  1.88966311e-04\n",
      " -5.39559778e-03  7.47995153e-02  1.27306670e-01  1.64213851e-01\n",
      "  5.17765468e-04  6.48820121e-03  1.46671105e-02 -1.46285847e-01\n",
      "  5.75402007e-02 -1.22524034e-02  1.24959378e-02 -6.66720569e-02\n",
      " -4.13128212e-02  5.84221520e-02  8.68138820e-02  4.71053645e-02\n",
      " -2.36737616e-02 -1.66773028e-03  7.68537372e-02 -7.40799159e-02\n",
      "  4.45516920e-03 -1.10431232e-01  1.69607386e-01  2.32582390e-02\n",
      "  3.93879339e-02 -8.57104082e-03  8.57062861e-02 -4.02010884e-03\n",
      " -6.35515142e-04 -4.57693636e-02  4.40150909e-02 -3.38678174e-02\n",
      "  7.46839345e-02  4.86835241e-02 -3.22428765e-03  2.05490906e-02\n",
      " -7.17821568e-02 -2.46286374e-02  2.46479008e-02 -3.84880938e-02\n",
      " -4.40426096e-02 -1.08005516e-01 -3.41182314e-02 -7.43950009e-02\n",
      " -3.17736939e-02 -3.28111239e-02 -2.04376429e-02 -7.46990666e-02\n",
      "  1.75207295e-03 -6.66789385e-03  1.97634497e-03 -4.21012118e-02\n",
      " -2.10801866e-02 -7.80204907e-02  1.82155613e-02 -5.75113073e-02\n",
      " -2.68053144e-01 -1.26248598e-02  1.01431467e-01  7.90180266e-02\n",
      " -3.30381468e-02 -4.01928350e-02 -3.29473391e-02  9.99771282e-02\n",
      "  5.83905093e-02  7.12455530e-03  1.10242737e-03 -7.80425146e-02\n",
      " -6.39491528e-03 -1.01476861e-02  5.02493009e-02  6.92147315e-02\n",
      "  2.27298923e-02  6.82089431e-03 -2.31440403e-02  7.49811307e-02\n",
      " -5.47347404e-02  2.83559542e-02 -1.07129076e-02 -6.08946532e-02\n",
      "  3.23240533e-02 -3.78964543e-02  9.04861614e-02  3.18356082e-02\n",
      "  1.84467118e-02 -9.59622487e-03  1.66442804e-02 -1.20973391e-02\n",
      " -3.14641162e-03 -8.08589756e-02 -7.45422170e-02 -3.08628450e-03\n",
      "  9.61163566e-02  4.87990975e-02  8.39010999e-02 -4.31001186e-03\n",
      " -1.01652980e-01 -2.69057546e-02 -5.15825488e-02 -8.92492309e-02\n",
      "  1.16511341e-03  5.52520808e-03 -2.39902195e-02 -4.39077690e-02\n",
      "  6.99604675e-03  2.67901793e-02 -3.71479653e-02  4.08477662e-03\n",
      " -7.68482238e-02 -4.92366329e-02 -6.83121383e-02  2.63320021e-02\n",
      " -4.67682723e-03  5.02424203e-02  7.41679687e-03  1.04055302e-02\n",
      " -4.25992869e-02  1.28334463e-02  6.14216216e-02  3.34027619e-03\n",
      "  7.42298886e-02  5.17283939e-02 -1.35735432e-02 -1.40231885e-02\n",
      "  5.63789420e-02  1.59824714e-02 -5.45847639e-02  8.08397159e-02\n",
      " -1.85361449e-02 -3.21850888e-02  3.43301184e-02  6.32144213e-02\n",
      "  3.60458679e-02 -2.69208886e-02 -6.47746921e-02  4.39669332e-03\n",
      " -2.60898452e-02  2.65851691e-02 -5.18756136e-02  3.06069292e-02\n",
      "  6.86038211e-02 -3.86022925e-02 -3.77684981e-02 -4.98667993e-02\n",
      " -1.36503195e-02 -3.04445717e-02 -1.09668985e-01  1.56302415e-02\n",
      " -9.72115714e-03  2.24423297e-02  1.44510940e-02 -1.46079464e-02\n",
      "  1.38608320e-02  1.63952436e-03  4.02286090e-02  3.10692340e-02\n",
      "  1.31171569e-01 -1.11152204e-02 -1.06357187e-02 -2.73295324e-02\n",
      " -8.26600343e-02  1.11536086e-02  6.15371973e-04 -3.19126621e-02\n",
      " -8.20422545e-02 -2.28798669e-02 -7.89382160e-02 -1.20663814e-01\n",
      "  1.56495045e-03 -1.66291464e-03  2.07045674e-02  1.14971705e-01\n",
      "  5.82212731e-02 -2.80298665e-02 -6.14670254e-02 -1.91841945e-02\n",
      "  5.93962939e-03 -3.01859044e-02 -6.49948418e-02 -8.25499594e-02\n",
      " -3.72016244e-02  5.88404313e-02 -7.89781287e-02  5.37908711e-02\n",
      " -1.73762605e-01  5.97815439e-02  7.04007521e-02 -3.79336067e-02\n",
      "  1.60402600e-02  5.52603342e-02 -1.02276262e-03 -8.47582880e-04\n",
      "  4.94609075e-03 -8.19019135e-03 -5.76874195e-03 -8.94528627e-02\n",
      "  3.60155962e-02  3.66815366e-02  8.29035696e-03  1.11031123e-02\n",
      " -3.70599069e-02  5.85363582e-02  6.19155690e-02  1.15355588e-01\n",
      " -4.69553918e-02  2.53757518e-02  2.61944141e-02 -5.01694977e-02\n",
      " -7.14092851e-02 -4.34014387e-03 -1.92942675e-02 -6.92518726e-02\n",
      "  7.84029951e-04 -5.19788079e-02  7.33837066e-03  3.17599364e-02]\n",
      "[ 0.00243347  0.04207732 -0.02550473 -0.12029478  0.02539725  0.0323929\n",
      "  0.02787716 -0.06723327 -0.02776767  0.3628208  -0.09549367  0.14282078\n",
      "  0.05408551 -0.01824162 -0.0368397   0.01363158  0.0108173   0.3162237\n",
      " -0.05152449  0.0077891  -0.00285706  0.01151221  0.00475177  0.00487506\n",
      "  0.06428497  0.03857747 -0.07604983  0.00721931  0.02394743  0.00243976\n",
      " -0.00761735 -0.10231899 -0.00998878  0.01872624  0.02236784 -0.01481496\n",
      "  0.06893048  0.05726092  0.02719788  0.01422003 -0.00448107 -0.05698515\n",
      "  0.10058935 -0.09873601 -0.018445   -0.03118641 -0.07707585 -0.00288505\n",
      " -0.03932164 -0.02244286 -0.00285666 -0.03630844  0.04969751 -0.03422394\n",
      " -0.03112761 -0.02799883  0.00436164  0.0277778   0.00138009 -0.03024352\n",
      " -0.07739623  0.02580686  0.08923409  0.06626199 -0.09351259  0.01392783\n",
      "  0.07045735  0.03817598 -0.06455668  0.09017293 -0.04248084 -0.05472222\n",
      "  0.099247    0.03120263  0.0107368  -0.01010436  0.02272471  0.03017457\n",
      " -0.07503191  0.06240729 -0.0686689   0.00915498 -0.03850041  0.05400642\n",
      " -0.05353397 -0.09643049  0.13865785 -0.06215585  0.0498942   0.06409841\n",
      " -0.01441672  0.00616773  0.01786811  0.00912983  0.04080797 -0.04383536\n",
      " -0.07375038 -0.05261541 -0.08597148 -0.02900661 -0.02069902  0.04359203\n",
      " -0.04445584 -0.03636725  0.04368936  0.02798463  0.04968737 -0.05188948\n",
      "  0.01111497  0.04320474  0.05199087 -0.05205778  0.03641997 -0.09659676\n",
      " -0.05106014 -0.00185533 -0.01102312 -0.04259642  0.02554325 -0.08272104\n",
      " -0.00429148  0.04174072  0.0383747  -0.00105231 -0.10421289  0.0585242\n",
      " -0.01576516 -0.05611932  0.09442507 -0.02884439 -0.03625369 -0.08834797\n",
      " -0.06586254  0.03048482 -0.01183522  0.1006806   0.04151158  0.00402828\n",
      "  0.02702146  0.02600152 -0.20636156  0.05881822  0.05879389  0.00608196\n",
      " -0.0218244   0.05812474 -0.04945013  0.04644504 -0.05322575 -0.01404585\n",
      " -0.03627397  0.04448017  0.03071192  0.00926062 -0.0102394   0.01449458\n",
      " -0.02082474 -0.01636476  0.06143196  0.00634719  0.05396384 -0.00123592\n",
      "  0.02091193 -0.08108264 -0.00891084 -0.01168477  0.01764526 -0.01990253\n",
      "  0.0463031  -0.00105665  0.00772056  0.00322611 -0.04181574  0.00443119\n",
      "  0.00081973 -0.00873199 -0.00046516 -0.05291754 -0.05231936 -0.05709668\n",
      " -0.04687694 -0.00210964 -0.06103858 -0.08196064  0.00297123 -0.02117959\n",
      "  0.0615962  -0.04249503  0.06324474  0.01384368  0.02043947  0.0021135\n",
      "  0.10951945  0.060558    0.0256568   0.00279035  0.04407869 -0.08013771\n",
      "  0.01351134  0.10204931  0.03023946 -0.02342833  0.00203624  0.01940492\n",
      "  0.03367443 -0.03813745  0.01115634  0.00541707 -0.06415722 -0.00944575\n",
      " -0.01046124  0.00476008 -0.02231917  0.01736584  0.05757522  0.00821168\n",
      "  0.01459678  0.0287065  -0.00429857  0.0906758   0.04073294 -0.02628743\n",
      " -0.01362287  0.0965481   0.02715935 -0.03505328 -0.0756828  -0.03504923\n",
      "  0.00544039 -0.02668486  0.01848474 -0.09426285  0.02583322 -0.01828177\n",
      " -0.02139655  0.01378975 -0.02713299  0.03458488  0.01814996 -0.04690736\n",
      " -0.05590843  0.0124774  -0.01047239  0.05754075  0.05127306 -0.04894725\n",
      " -0.04036186  0.02443206 -0.0205003   0.05554344  0.05645795  0.0536313\n",
      " -0.03709114 -0.00992794  0.03892826  0.03486065  0.06825119 -0.0409276\n",
      " -0.0695611  -0.04978673 -0.03122494  0.07999375  0.04631121 -0.05222\n",
      " -0.05206183 -0.07569903 -0.04843018 -0.00989854  0.1588175   0.03822464\n",
      " -0.05368807  0.01958093  0.01270532 -0.06218627 -0.08786944  0.02028942\n",
      "  0.04285799  0.0080012  -0.02246111  0.04951907  0.12357362 -0.09458525\n",
      "  0.0175165  -0.08050474 -0.04737374  0.00432047 -0.02185482 -0.04625241\n",
      "  0.10301451  0.02345469  0.03277817 -0.01353243 -0.05993144  0.00458509\n",
      " -0.05705004  0.01287605  0.02842668  0.02812657 -0.07309745 -0.00709704]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for b in mb:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False in ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NULL{null,ADJ}', 'two{two,NUM}', 'asian{asian,ADJ}', 'people{people,NOUN}', 'cooking{cook,VERB}', 'on{on,ADP}', 'a{a,DET}', 'grill{grill,NOUN}', 'in{in,ADP}', 'a{a,DET}', 'park{park,NOUN}', '.{.,PUNCT}']\n",
      "['NULL{null,ADJ}', 'two{two,NUM}', 'asian{asian,ADJ}', 'people{people,NOUN}', 'cooking{cook,VERB}', 'on{on,ADP}', 'a{a,DET}', 'grill{grill,NOUN}', 'in{in,ADP}', 'a{a,DET}', 'park{park,NOUN}', '.{.,PUNCT}']\n",
      "['NULL{null,ADJ}', 'two{two,NUM}', 'dogs{dog,NOUN}', 'make{make,VERB}', 'hamburgs{hamburg,NOUN}', 'on{on,ADP}', 'the{the,DET}', 'grill{grill,NOUN}', '.{.,PUNCT}']\n",
      "['NULL{null,ADJ}', 'two{two,NUM}', 'dogs{dog,NOUN}', 'make{make,VERB}', 'hamburgs{hamburg,NOUN}', 'on{on,ADP}', 'the{the,DET}', 'grill{grill,NOUN}', '.{.,PUNCT}']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8900\\2095203298.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "for i in range(len(a.columns)):\n",
    "    if(a.iloc[0][i]==b.iloc[0][i]):\n",
    "        print(a.iloc[0][i])\n",
    "        print(b.iloc[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main index</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hipotesis</th>\n",
       "      <th>R_Text</th>\n",
       "      <th>R_Hip</th>\n",
       "      <th>M_Align</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold_label</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Idx</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>ma_umbral</th>\n",
       "      <th>target_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[NULL{null,PROPN}, a{a,DET}, young{young,ADJ},...</td>\n",
       "      <td>[NULL{null,PROPN}, the{the,DET}, woman{woman,N...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.016082555, 0.077160776, -0.013421837, 0.00...</td>\n",
       "      <td>[[0.085589595, 0.004343943, 0.17077179, 0.0161...</td>\n",
       "      <td>[0.96325433, 0.034104887, 0.00264086]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>9119</td>\n",
       "      <td>entailment</td>\n",
       "      <td>entailment</td>\n",
       "      <td>NOUN...</td>\n",
       "      <td>entailment_entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Main index                                               Text  \\\n",
       "0           0  [NULL{null,PROPN}, a{a,DET}, young{young,ADJ},...   \n",
       "\n",
       "                                           Hipotesis  \\\n",
       "0  [NULL{null,PROPN}, the{the,DET}, woman{woman,N...   \n",
       "\n",
       "                                              R_Text  \\\n",
       "0  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                               R_Hip  \\\n",
       "0  [[0.016082555, 0.077160776, -0.013421837, 0.00...   \n",
       "\n",
       "                                             M_Align  \\\n",
       "0  [[0.085589595, 0.004343943, 0.17077179, 0.0161...   \n",
       "\n",
       "                              Prediction       Gold_label  Paraphrase   Idx  \\\n",
       "0  [0.96325433, 0.034104887, 0.00264086]  [1.0, 0.0, 0.0]           0  9119   \n",
       "\n",
       "  predicted_label  gold_label  \\\n",
       "0      entailment  entailment   \n",
       "\n",
       "                                           ma_umbral      target_prediction  \n",
       "0                                            NOUN...  entailment_entailment  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba_tokens=pd.read_pickle(\"data\\Only_training_hipotesis_salida\\pTEST_new_0.1_0.csv.pickle\")\n",
    "uno=prueba_tokens[prueba_tokens.index==0]\n",
    "uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "(42, 300)\n"
     ]
    }
   ],
   "source": [
    "print(uno.R_Text[0].shape)\n",
    "print(uno.R_Hip[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.25334620e-03,  4.66938363e-03, -3.94539274e-02,  9.37400609e-02,\n",
       "        6.78746253e-02, -7.06710964e-02, -9.81363934e-03, -1.14110552e-01,\n",
       "        6.92408206e-03,  4.16172296e-01, -4.40745056e-02, -1.28818387e-02,\n",
       "       -4.21260260e-02, -1.01737501e-02, -2.86392886e-02, -3.26361246e-02,\n",
       "        1.00542791e-02,  3.10645252e-01, -9.04348027e-03, -1.60761047e-02,\n",
       "       -2.96078771e-02, -1.21403217e-01, -7.50353858e-02,  5.23866452e-02,\n",
       "        2.89521012e-02,  5.96943917e-03,  1.04422793e-02,  3.00356373e-03,\n",
       "        6.00203983e-02, -1.11140721e-02,  7.27081439e-03,  2.02951133e-02,\n",
       "        1.96167249e-02, -1.45751704e-02,  7.04694614e-02, -4.04809304e-02,\n",
       "        7.22106546e-02, -5.22679277e-02, -3.45827229e-02, -1.57985300e-01,\n",
       "        6.43036664e-02,  1.09604925e-01,  3.49426456e-02, -5.84695265e-02,\n",
       "        3.32900174e-02, -1.30817750e-02, -6.48652241e-02, -2.57504862e-02,\n",
       "       -2.03949884e-02,  4.45418395e-02, -6.20404892e-02,  1.15604885e-01,\n",
       "        3.71605977e-02,  1.64175592e-02,  2.03233808e-02,  5.79079725e-02,\n",
       "        2.59238500e-02,  5.80568425e-02,  4.58496213e-02, -5.54431602e-02,\n",
       "       -1.85075612e-03,  1.04914621e-01, -9.21100471e-03,  1.87438671e-02,\n",
       "        5.75555861e-02, -7.08482265e-02, -3.67931388e-02,  8.71465076e-03,\n",
       "       -6.91107986e-03,  6.41133413e-02,  2.80871559e-02,  1.84295475e-02,\n",
       "       -5.02459556e-02,  1.07098660e-02, -8.14084709e-03, -4.39784005e-02,\n",
       "        2.47065220e-02, -6.73526451e-02, -6.79707304e-02,  5.84111102e-02,\n",
       "       -3.71737927e-02, -2.69847754e-02, -3.15582417e-02,  7.99650079e-05,\n",
       "       -2.84923036e-02,  1.27314618e-02, -7.28212073e-02,  4.77679539e-03,\n",
       "        4.69557717e-02, -4.51410823e-02, -2.94250883e-02,  9.39718410e-02,\n",
       "        1.55950151e-03, -3.60299535e-02, -2.80890409e-02,  9.18782577e-02,\n",
       "       -2.87956954e-03,  1.92134629e-03,  7.09330216e-02, -3.66706518e-03,\n",
       "       -5.24525978e-02,  3.08195539e-02, -4.54652011e-02, -4.03358303e-02,\n",
       "       -4.06316854e-02, -1.50181964e-01,  6.46748990e-02,  1.75644122e-02,\n",
       "        1.39403129e-02, -5.11561260e-02,  3.87039334e-02,  2.83811241e-02,\n",
       "        3.90713895e-03,  2.12316662e-02,  5.41089987e-03,  5.59104942e-02,\n",
       "       -4.00757827e-02,  8.14329684e-02,  2.40978580e-02,  5.51171601e-02,\n",
       "        3.59093510e-02, -5.48608787e-02, -2.14483738e-02, -7.20636733e-03,\n",
       "       -3.82347144e-02,  3.44866179e-02, -3.13961841e-02, -5.10977097e-02,\n",
       "        2.39037632e-04,  1.35119855e-02, -3.50180231e-02,  1.69314388e-02,\n",
       "       -7.51786074e-03,  7.43946880e-02,  1.00271427e-03, -1.15981777e-04,\n",
       "       -5.10336384e-02, -1.69186257e-02, -5.42522147e-02, -2.80117821e-02,\n",
       "       -2.59031236e-01,  3.11210603e-02,  3.88151146e-02,  2.87410468e-02,\n",
       "        6.54324237e-03, -7.26082698e-02, -1.78216342e-02, -3.74451429e-02,\n",
       "        9.46709663e-02, -5.40863834e-02, -1.67198200e-02,  1.07187219e-02,\n",
       "        2.56920699e-02,  3.58678922e-02, -3.64690199e-02,  7.63299763e-02,\n",
       "       -3.64011787e-02,  4.31681052e-02,  1.89477596e-02, -5.06812520e-02,\n",
       "       -6.54399628e-03, -1.58309415e-02,  1.08930301e-02,  2.08717445e-03,\n",
       "       -8.16873647e-03, -5.07227071e-02, -3.64313312e-02,  4.17981371e-02,\n",
       "        4.92264852e-02, -2.21625660e-02,  1.90174822e-02, -2.84131616e-02,\n",
       "        8.88556615e-02,  2.12052856e-02, -5.04061282e-02, -7.30869081e-03,\n",
       "       -6.88187173e-03, -1.68179981e-02, -4.60305251e-02, -7.79788429e-03,\n",
       "       -4.10519121e-03, -6.73451051e-02, -1.19488668e-02, -1.01726204e-01,\n",
       "       -1.90551707e-03,  7.77093737e-05, -1.82880275e-02,  8.03287029e-02,\n",
       "       -4.02303040e-02, -7.73645192e-02, -4.69972305e-02, -6.32615900e-03,\n",
       "       -9.33537558e-02,  2.93157939e-02,  3.74658741e-02,  1.97825544e-02,\n",
       "       -4.59268801e-02,  2.15369407e-02, -7.40178069e-03, -6.83249980e-02,\n",
       "        1.94433592e-02,  2.43089106e-02, -7.87401423e-02, -7.84047227e-03,\n",
       "        6.31692484e-02,  1.37912557e-02,  2.51795091e-02,  2.03742599e-03,\n",
       "        9.92048532e-03,  3.54288258e-02, -5.68809658e-02,  3.83157432e-02,\n",
       "       -6.07873537e-02, -4.64940891e-02,  3.98063101e-02,  1.49117276e-01,\n",
       "       -7.82765821e-02,  6.82533905e-02,  1.88162290e-02, -6.66667195e-03,\n",
       "       -7.89568573e-03, -2.61009876e-02, -1.19198458e-02,  2.56939549e-02,\n",
       "        1.71223301e-02, -7.52634034e-02,  1.86673608e-02,  6.06969036e-02,\n",
       "       -2.30953507e-02, -1.61882266e-02, -1.92549191e-02,  4.96542491e-02,\n",
       "       -3.52177732e-02, -3.49746794e-02, -8.27690139e-02, -6.12433776e-02,\n",
       "       -3.75186391e-02,  3.36009450e-02, -5.14124073e-02,  6.30769134e-02,\n",
       "        1.55241610e-02,  2.41675805e-02,  7.40102679e-02, -6.58206176e-03,\n",
       "        3.04294787e-02, -5.03382925e-03,  7.56195560e-02, -7.44399130e-02,\n",
       "       -1.22153228e-02, -1.69257857e-02, -1.25486748e-02, -6.50819242e-02,\n",
       "        8.72162264e-03,  6.94160759e-02, -4.63056471e-03,  6.07025549e-02,\n",
       "        5.77402636e-02, -5.29745817e-02,  1.25217275e-03,  1.65343937e-02,\n",
       "       -6.43903529e-03,  1.13767594e-01,  7.93714225e-02, -1.38219716e-02,\n",
       "        5.02798744e-02, -2.98867710e-02,  4.47830446e-02, -1.17971713e-03,\n",
       "        2.87108980e-02, -4.41121943e-02,  5.96114807e-02, -1.65564418e-02,\n",
       "       -2.96738315e-02, -4.70254943e-02, -3.53628695e-02, -1.82303656e-02,\n",
       "       -5.27522229e-02, -4.58552763e-02,  6.15128502e-02,  5.63552156e-02,\n",
       "        8.05831030e-02,  4.19583134e-02, -3.29093672e-02, -3.75299435e-03,\n",
       "       -5.88049516e-02, -6.40869588e-02, -2.82529853e-02, -5.43049760e-02,\n",
       "        2.77950708e-02, -7.63243251e-03, -1.94980074e-02,  6.33803022e-04,\n",
       "        4.10047993e-02, -3.84589583e-02,  1.74147896e-02,  1.51546272e-02,\n",
       "       -1.15412679e-02, -5.67189045e-02, -2.74822619e-02,  5.31177968e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uno.R_Text[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.3231783e-02,  8.1740832e-03, -7.1232677e-02,  1.3508617e-02,\n",
       "        2.1808768e-02, -6.0404815e-02,  3.0284990e-02, -1.8769207e-03,\n",
       "        4.5850988e-02,  4.7251067e-01, -2.1804223e-02,  4.3358430e-02,\n",
       "       -4.7601085e-02, -3.3069991e-02, -7.6117794e-05,  1.5119008e-02,\n",
       "       -1.2457802e-02,  5.1971022e-02,  4.2875069e-03,  5.3571105e-02,\n",
       "        3.1191099e-02, -1.3887122e-01, -4.2514447e-02,  2.0616278e-03,\n",
       "       -2.2264851e-02, -1.7011534e-02, -7.5682923e-03,  6.6236950e-02,\n",
       "        6.9176503e-02, -1.4249718e-02, -8.4495530e-02, -1.2432345e-02,\n",
       "        9.0671621e-02, -6.7502171e-02,  6.4611107e-02, -3.0241046e-05,\n",
       "        3.3179086e-02, -6.6726372e-02,  3.1107761e-02,  1.3755297e-03,\n",
       "       -9.5511274e-03, -1.9979879e-02, -2.0364748e-02, -9.1421656e-02,\n",
       "       -5.6903105e-02, -2.2173939e-02,  2.5527151e-02,  3.4624621e-02,\n",
       "        4.4109985e-02, -4.5926750e-02, -8.8662416e-02, -5.1686157e-02,\n",
       "       -5.2886222e-02, -5.9441127e-02, -4.3523591e-03,  8.5013740e-02,\n",
       "       -3.1494144e-03, -1.0146766e-02, -1.3306636e-02, -3.2500260e-02,\n",
       "       -1.6603937e-02, -8.8983653e-03,  3.8574833e-02, -6.3489832e-02,\n",
       "        2.6534783e-02, -2.8166691e-02, -2.8124263e-03,  1.3077229e-02,\n",
       "        2.8557621e-03,  8.1283234e-02, -2.3077019e-02, -5.9166871e-02,\n",
       "       -5.4752991e-02,  5.1937688e-02,  6.3701965e-02, -3.8096020e-03,\n",
       "       -2.3574015e-02,  3.7370224e-02,  4.1020423e-02, -1.8784359e-02,\n",
       "       -3.8817271e-03,  2.2163333e-02, -3.5779227e-02,  6.8000682e-02,\n",
       "        1.9205596e-02,  2.6531752e-02,  2.9221293e-02, -5.2528627e-02,\n",
       "       -6.7676425e-02,  2.7019659e-02, -5.7734970e-02, -8.8910917e-03,\n",
       "        4.1291650e-02, -4.2112906e-02, -5.7537992e-02, -8.9435190e-02,\n",
       "       -5.8303182e-03,  4.6441931e-04, -5.6690976e-02,  3.0880474e-02,\n",
       "        1.4099407e-02,  5.4759052e-02,  2.7086327e-03,  1.4747170e-02,\n",
       "       -4.4872146e-02, -1.0766800e-01, -6.2904947e-02, -1.4314872e-02,\n",
       "        8.7112330e-02,  2.8222755e-02,  5.7816796e-02, -8.2331769e-02,\n",
       "       -7.2558507e-02, -9.2474751e-02, -7.0981152e-04, -2.3119445e-03,\n",
       "       -4.7172275e-03,  4.1928049e-02, -5.9563860e-02,  5.7084933e-03,\n",
       "        1.5400842e-02, -3.8691506e-02, -1.9485913e-02, -4.9802721e-02,\n",
       "        4.1117400e-02,  5.2274067e-02,  5.0613370e-02, -2.0155646e-02,\n",
       "       -2.1916348e-02, -1.4193502e-02,  4.7967773e-02,  1.0783166e-02,\n",
       "        2.7472712e-02,  1.6637273e-02,  3.2989681e-02,  1.2045961e-02,\n",
       "       -1.0619974e-02, -8.4310668e-03,  9.1132253e-02,  8.9215478e-03,\n",
       "       -3.2788154e-01, -5.1351290e-02,  7.5979913e-03,  2.4925604e-02,\n",
       "       -7.6226890e-02, -7.8119412e-02,  5.4889362e-02, -1.7378222e-02,\n",
       "       -4.5375205e-03, -3.7299007e-02, -9.6412845e-02,  2.7406042e-02,\n",
       "       -1.3636503e-02, -4.2664450e-02,  7.8749759e-03,  6.0082071e-02,\n",
       "       -4.3146297e-02,  6.8508292e-04, -5.0477002e-02, -1.0954538e-01,\n",
       "        8.6362297e-03, -1.9541977e-02, -1.8813148e-03,  3.8873334e-03,\n",
       "        8.1778705e-02, -6.5315686e-02,  9.7635642e-02, -8.8465445e-02,\n",
       "        2.3672506e-02,  9.3117211e-04, -1.6281193e-02,  2.2777000e-02,\n",
       "        5.2074060e-02,  1.5340232e-02,  4.6273742e-02, -7.6185982e-03,\n",
       "       -6.1339714e-02,  4.9240571e-02, -1.2821004e-02,  2.5595337e-02,\n",
       "       -3.6626246e-02,  1.0842714e-01,  3.1759311e-02, -5.9694171e-02,\n",
       "       -4.4510007e-02,  7.1179643e-02, -5.5489399e-02,  6.1230619e-02,\n",
       "        1.5999358e-02, -1.0917567e-01,  7.1269046e-03,  4.6223737e-03,\n",
       "       -5.0414879e-02,  2.6913591e-02, -2.4958938e-02, -2.6559027e-02,\n",
       "        1.1810796e-02,  4.3669054e-03,  2.4821052e-02, -7.7013299e-02,\n",
       "        4.4691838e-02, -1.3831362e-02, -5.6889471e-02, -7.7437565e-02,\n",
       "       -3.8739998e-02,  1.3363609e-01, -4.7014691e-03, -3.3054836e-02,\n",
       "       -5.3028658e-02,  2.2019384e-02, -7.4881367e-02, -1.9069225e-02,\n",
       "       -4.0771928e-02, -5.0355781e-02,  3.7430834e-02,  2.2028478e-02,\n",
       "        3.2103270e-02, -8.9551862e-03,  8.7012328e-02, -1.0594367e-01,\n",
       "        3.1730521e-02, -4.1578028e-02,  7.5890510e-03,  3.4956455e-02,\n",
       "        2.8780362e-02,  2.9122803e-02,  4.4656985e-02, -1.3877879e-02,\n",
       "        8.5097075e-02,  3.6747463e-02, -2.1496629e-02, -5.2516506e-04,\n",
       "        2.8460645e-03,  1.5306897e-02, -3.4085196e-04, -1.3578620e-02,\n",
       "        1.4699742e-02,  5.0310325e-02,  3.5348900e-02, -2.5313504e-02,\n",
       "       -5.0114859e-02,  1.8220693e-02, -2.6659034e-02, -1.7493380e-02,\n",
       "        5.5696983e-02,  3.0172860e-02, -1.2869643e-01,  6.0294205e-03,\n",
       "       -8.7888138e-03,  4.6854071e-02, -6.0871509e-03,  9.0003408e-02,\n",
       "       -1.2394920e-02,  4.3226602e-03,  3.7098996e-02,  1.3187387e-02,\n",
       "       -2.1213281e-03, -4.3076593e-02,  1.5122948e-02,  4.5453999e-02,\n",
       "        8.9617018e-03,  4.7338951e-02, -3.1560816e-02,  6.0372997e-02,\n",
       "        1.6466051e-02, -3.2562386e-02,  3.0215288e-02,  9.0701925e-03,\n",
       "       -6.6683948e-02,  2.4725592e-02, -1.3309969e-01,  3.4720078e-02,\n",
       "       -2.0837503e-02, -3.0648645e-02, -3.6753524e-02, -1.8005529e-02,\n",
       "        5.4327209e-02,  2.4787718e-02, -1.3908032e-02,  1.1364863e-01,\n",
       "       -4.4850934e-02,  1.4026372e-01,  9.6243136e-03,  5.2958958e-02,\n",
       "        7.6684490e-02, -9.5358239e-03,  5.0187591e-02, -3.3223029e-02,\n",
       "       -2.3040652e-02, -1.7732788e-03, -3.5697404e-02, -5.2358922e-02,\n",
       "        1.0205254e-02, -2.1440566e-02,  1.3771358e-02,  4.2555355e-02,\n",
       "        2.1851193e-02, -2.6528722e-02, -6.9446214e-02, -4.7491990e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uno.R_Text[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a{a,DET}'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uno.Text[0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
